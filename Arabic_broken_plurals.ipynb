{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirezzati/Arabic-Broken-Plural-RNN/blob/main/Arabic_broken_plurals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgbi7F8b_x30"
      },
      "source": [
        "# **Libraries & Constants**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "lvARVj-B2jPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D2-wlVMZYEkZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Input, Softmax, BatchNormalization, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Flatten, LSTM, GRU, SimpleRNN, Concatenate, concatenate, RepeatVector, TimeDistributed, Bidirectional\n",
        "# from keras.layers.merge import concatenate\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax, Nadam, SGD\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers.schedules import InverseTimeDecay, ExponentialDecay\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import string\n",
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "from transformers import AutoTokenizer,BertTokenizer,TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srVvFhQrdymB"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')\n",
        "dataPath=\"/content/drive/MyDrive/AI Projects/Arabic Broken Plural/data\"\n",
        "# dataPath = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGFwazuJClaC"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding Schemes**"
      ],
      "metadata": {
        "id": "XOX50iU1Kha1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_schemes = pd.read_excel(dataPath+\"/Encoding Schemes.xlsx\")"
      ],
      "metadata": {
        "id": "ZDoScnOfGIiX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_bw = encoding_schemes[['Arabic', 'BW']]\n",
        "arabic_bw.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twMF1Mw5JXe_",
        "outputId": "cb0d4547-5f3d-40dd-aafb-c2cb7e70f3fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bw_to_arabic, arabic_to_bw = {}, {}\n",
        "for i in range(arabic_bw.shape[0]):\n",
        "  bw_to_arabic[arabic_bw['BW'][i]] = arabic_bw['Arabic'][i]\n",
        "  arabic_to_bw[arabic_bw['Arabic'][i]] = arabic_bw['BW'][i]"
      ],
      "metadata": {
        "id": "pvjYOWufI8-X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getArabicForm(bwForm):\n",
        "  arabicForm = []\n",
        "  for x in bwForm:\n",
        "    arabicForm.append(\"\".join([bw_to_arabic[char] for char in x]))\n",
        "  return arabicForm"
      ],
      "metadata": {
        "id": "NwhxwGI3LsSJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZQvZUkdGb9Z"
      },
      "source": [
        "## **Hugging face Arabic Bert Config**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWufMcZMHDgY"
      },
      "outputs": [],
      "source": [
        "#bert_tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9Vc8mS4CFfoe"
      },
      "outputs": [],
      "source": [
        "encoding = bert_tokenizer.encode_plus(\n",
        "      'علم',\n",
        "      max_length=18,\n",
        "      add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "      return_token_type_ids=True,\n",
        "      padding = 'max_length',  # Pad to longest in batch.\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='tf'  # Return PyTorch tensors\n",
        "    )\n",
        "#print(len(encoding['token_type_ids'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Q7hXWVrepQgl"
      },
      "outputs": [],
      "source": [
        "bert_test=bert_tokenizer(\"عِلمة\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ultG0eVNnUfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d824b3-f9d6-4f08-881d-826d9d1f0e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 2816, 1012, 3], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}\n"
          ]
        }
      ],
      "source": [
        "print(bert_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubE6nCh4ClaD"
      },
      "source": [
        "## **Get dataset files and Organizing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_uBC6rVkClaD",
        "outputId": "a0066926-0804-4e45-c718-075575a43210"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   lemma inflection NUM GEN RAT  lex_freq B/S SING_PATT    PL_PATT   ROOT  \\\n",
              "0  Eamal    >aEomAl  PL   m   i        49   B     1a2a3    >a1o2A3  E.m.l   \n",
              "1  hadaf    >ahodAf  PL   m   i        42   B     1a2a3    >a1o2A3  h.d.f   \n",
              "2  EuDow    >aEoDA'  PL   m   r        46   B     1u2ow    >a1o2A'  E.D.#   \n",
              "3  jihAz  >ajohizap  PL   m   i        41   B     1i2A3  >a1o2i3ap  j.h.z   \n",
              "4  Hukom    >aHokAm  PL   m   i        35   B     1u2o3    >a1o2A3  H.k.m   \n",
              "\n",
              "   FREQ  \n",
              "0    49  \n",
              "1    42  \n",
              "2    39  \n",
              "3    35  \n",
              "4    35  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dd94aeb-16bb-40a4-b5b4-a40bbe4ab0be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>NUM</th>\n",
              "      <th>GEN</th>\n",
              "      <th>RAT</th>\n",
              "      <th>lex_freq</th>\n",
              "      <th>B/S</th>\n",
              "      <th>SING_PATT</th>\n",
              "      <th>PL_PATT</th>\n",
              "      <th>ROOT</th>\n",
              "      <th>FREQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eamal</td>\n",
              "      <td>&gt;aEomAl</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>49</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>E.m.l</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hadaf</td>\n",
              "      <td>&gt;ahodAf</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>42</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>h.d.f</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EuDow</td>\n",
              "      <td>&gt;aEoDA'</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>46</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2ow</td>\n",
              "      <td>&gt;a1o2A'</td>\n",
              "      <td>E.D.#</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jihAz</td>\n",
              "      <td>&gt;ajohizap</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>41</td>\n",
              "      <td>B</td>\n",
              "      <td>1i2A3</td>\n",
              "      <td>&gt;a1o2i3ap</td>\n",
              "      <td>j.h.z</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hukom</td>\n",
              "      <td>&gt;aHokAm</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>35</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2o3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>H.k.m</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dd94aeb-16bb-40a4-b5b4-a40bbe4ab0be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dd94aeb-16bb-40a4-b5b4-a40bbe4ab0be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dd94aeb-16bb-40a4-b5b4-a40bbe4ab0be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_csv = pd.read_csv(dataPath+\"/train_pairs_all.csv\")\n",
        "dev_csv = pd.read_csv(dataPath+\"/dev_pairs_all.csv\")\n",
        "test_csv = pd.read_csv(dataPath+\"/test_pairs_all.csv\")\n",
        "\n",
        "train_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv"
      ],
      "metadata": {
        "id": "WhS3Mtp8LXLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SdFejowuClaD"
      },
      "outputs": [],
      "source": [
        "train_csv_filtered = train_csv[train_csv['ROOT'] != 'NTWS']\n",
        "dev_csv_filtered = dev_csv[dev_csv['ROOT'] != 'NTWS']\n",
        "test_csv_filtered = test_csv[test_csv['ROOT'] != 'NTWS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMrYNnyDClaD",
        "outputId": "a0463fe5-be95-4b12-f81f-692bd3bee9cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n",
            "38\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "print(train_csv.shape[0] - train_csv_filtered.shape[0])\n",
        "print(dev_csv.shape[0] - dev_csv_filtered.shape[0])\n",
        "print(test_csv.shape[0] - test_csv_filtered.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yD10TibJClaD",
        "outputId": "317f4b11-f816-4ab6-c577-4e143bb6daf5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        lemma  inflection NUM  GEN  RAT  lex_freq  B/S   SING_PATT  \\\n",
              "0       Eamal     >aEomAl  PL    1    0        23    0       1a2a3   \n",
              "1       hadaf     >ahodAf  PL    1    0        16    0       1a2a3   \n",
              "2     EalAqap     EalAqAt  PL    0    0        15    1     1a2A3ap   \n",
              "3  mu&as~asap  mu&as~asAt  PL    0    0        14    1  mu&a2~a3ap   \n",
              "4       EuDow     >aEoDA'  PL    1    1        15    0       1u2ow   \n",
              "\n",
              "      PL_PATT   ROOT  FREQ  \n",
              "0     >a1o2A3  E.m.l    23  \n",
              "1     >a1o2A3  h.d.f    16  \n",
              "2     1a2A3At  E.l.q    15  \n",
              "3  mu&a2~a3At  #.s.s    14  \n",
              "4     >a1o2A'  E.D.#    13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7d67c113-aea1-43bd-8a55-b238b7b4e12e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>NUM</th>\n",
              "      <th>GEN</th>\n",
              "      <th>RAT</th>\n",
              "      <th>lex_freq</th>\n",
              "      <th>B/S</th>\n",
              "      <th>SING_PATT</th>\n",
              "      <th>PL_PATT</th>\n",
              "      <th>ROOT</th>\n",
              "      <th>FREQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eamal</td>\n",
              "      <td>&gt;aEomAl</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>E.m.l</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hadaf</td>\n",
              "      <td>&gt;ahodAf</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>h.d.f</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EalAqap</td>\n",
              "      <td>EalAqAt</td>\n",
              "      <td>PL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1a2A3ap</td>\n",
              "      <td>1a2A3At</td>\n",
              "      <td>E.l.q</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mu&amp;as~asap</td>\n",
              "      <td>mu&amp;as~asAt</td>\n",
              "      <td>PL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>mu&amp;a2~a3ap</td>\n",
              "      <td>mu&amp;a2~a3At</td>\n",
              "      <td>#.s.s</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EuDow</td>\n",
              "      <td>&gt;aEoDA'</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1u2ow</td>\n",
              "      <td>&gt;a1o2A'</td>\n",
              "      <td>E.D.#</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d67c113-aea1-43bd-8a55-b238b7b4e12e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d67c113-aea1-43bd-8a55-b238b7b4e12e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d67c113-aea1-43bd-8a55-b238b7b4e12e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\n",
        "# Label encoder for encoding gender and rational features\n",
        "# 'B' class: 0      'S' class: 1\n",
        "categorical_attr = ['GEN', 'RAT', 'B/S']\n",
        "\n",
        "le = LabelEncoder()\n",
        "#train_csv_filtered[categorical_attr] = train_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "train_csv[categorical_attr] = train_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "le = LabelEncoder()\n",
        "#dev_csv_filtered[categorical_attr] = dev_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "dev_csv[categorical_attr] = dev_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "le = LabelEncoder()\n",
        "#test_csv_filtered[categorical_attr] = test_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "test_csv[categorical_attr] = test_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "#test_csv_filtered.head()\n",
        "test_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vx1uEiSrClaD"
      },
      "outputs": [],
      "source": [
        "def getListOfData(dataFrame):\n",
        "  '''\n",
        "  Output type->List : 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:freq | 9:nmberOfRoot | 10:Arabic Form |\n",
        "  '''\n",
        "  data = [] # 0:lemma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "  data.append(dataFrame['lemma'].tolist())\n",
        "  data.append(dataFrame['SING_PATT'].tolist())\n",
        "\n",
        "  root = dataFrame['ROOT'].tolist()\n",
        "  # delete dot sign(.) in root feature\n",
        "  for i in range(len(root)): \n",
        "    root[i] = root[i].replace(\".\",\"\")\n",
        "    root[i] = root[i].replace(\"#\",\"\")\n",
        "  data.append(root)\n",
        "\n",
        "  data.append(dataFrame['inflection'].tolist())\n",
        "  data.append(dataFrame['PL_PATT'].tolist())\n",
        "  data.append(dataFrame['B/S'].tolist())\n",
        "  data.append(dataFrame['GEN'].tolist())\n",
        "  data.append(dataFrame['RAT'].tolist())\n",
        "  data.append(dataFrame['FREQ'].tolist())\n",
        "\n",
        "  numOfRoot = [len(x) for x in root]\n",
        "  data.append(numOfRoot)\n",
        "\n",
        "  data.append(getArabicForm(dataFrame['lemma'].tolist()))\n",
        "\n",
        "  return data\n",
        "\n",
        "trainData = getListOfData(train_csv)\n",
        "devData = getListOfData(dev_csv)\n",
        "testData = getListOfData(test_csv)\n",
        "is_dataOrginal=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainData[1]"
      ],
      "metadata": {
        "id": "KrQhKscIPF_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis Model**"
      ],
      "metadata": {
        "id": "dU09qVXA9kp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install camel-tools"
      ],
      "metadata": {
        "id": "8jUsTC4b-00L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from camel_tools.sentiment import SentimentAnalyzer\n",
        "\n",
        "sa = SentimentAnalyzer(\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")"
      ],
      "metadata": {
        "id": "0Yxm0XdF9wML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainData[0][1])\n",
        "sentences = [trainData[10][0], trainData[0][1]]\n",
        "\n",
        "sa.predict(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmfgf_2bN08I",
        "outputId": "7cffbe72-60c3-4545-fbd3-5cc247ef4d39"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hadaf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral', 'neutral']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MFDQIHuClaE"
      },
      "source": [
        "## **Analyzing Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGoQfT1ClaE",
        "outputId": "b956b274-6d3c-4068-db06-75ab6773dc7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unseen data(lemma) in dev set:  85\n",
            "number of unseen data(lemma) in test set:  78\n",
            "\n",
            "number of unseen data((lemma, inflection) pair) in dev set:  108\n",
            "number of unseen data((lemma, inflection) pair) in test set:  88\n"
          ]
        }
      ],
      "source": [
        "# generate samples of dev/test set which are not in train set\n",
        "# compare with lemma\n",
        "devSetExistence = np.array([lemma in trainData[0] for lemma in devData[0]])\n",
        "testSetExistence = np.array([lemma in trainData[0] for lemma in testData[0]])\n",
        "\n",
        "unseenLemmaIndices_dev = np.where(devSetExistence==False)[0]\n",
        "unseenLemmaIndices_test = np.where(testSetExistence==False)[0]\n",
        "\n",
        "print('number of unseen data(lemma) in dev set: ', np.count_nonzero(devSetExistence==False))\n",
        "print('number of unseen data(lemma) in test set: ', np.count_nonzero(testSetExistence==False), end='\\n\\n')\n",
        "\n",
        "# compare with (lemma, inflection) pair\n",
        "  # first: generate (lemma, inflection) pair in sets\n",
        "trainLemmaInf = np.stack((trainData[0], trainData[3]), axis=-1).tolist()\n",
        "devLemmaInf = np.stack((devData[0], devData[3]), axis=-1).tolist()\n",
        "testLemmaInf = np.stack((testData[0], testData[3]), axis=-1).tolist()\n",
        "\n",
        "devSetExistence = np.array([lemInf in trainLemmaInf for lemInf in devLemmaInf])\n",
        "testSetExistence = np.array([lemInf in trainLemmaInf for lemInf in testLemmaInf])\n",
        "\n",
        "unseenLemInfIndices_dev = np.where(devSetExistence==False)[0]\n",
        "unseenLemInfIndices_test = np.where(testSetExistence==False)[0]\n",
        "\n",
        "print('number of unseen data((lemma, inflection) pair) in dev set: ', np.count_nonzero(devSetExistence==False))\n",
        "print('number of unseen data((lemma, inflection) pair) in test set: ', np.count_nonzero(testSetExistence==False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5OTbLa3QClaE"
      },
      "outputs": [],
      "source": [
        "# create dataframe for dev set's unseen data\n",
        "    # 0:lemma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "    \n",
        "data_analysis_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Datasets analysis/'\n",
        "os.makedirs(data_analysis_path, exist_ok=True)  \n",
        "\n",
        "unseenLemmaIndices_dev_df = pd.DataFrame({'index': unseenLemmaIndices_dev,\n",
        "                                           'lemma': np.array(devData[0])[unseenLemmaIndices_dev],\n",
        "                                           'inflection': np.array(devData[3])[unseenLemmaIndices_dev],\n",
        "                                           'pl pattern': np.array(devData[4])[unseenLemmaIndices_dev]})\n",
        "unseenLemmaIndices_dev_df.to_csv(data_analysis_path + 'unseenLemma_dev.csv')\n",
        "\n",
        "\n",
        "unseenLemInfIndices_dev_df = pd.DataFrame({'index': unseenLemInfIndices_dev,\n",
        "                                           'lemma': np.array(devData[0])[unseenLemInfIndices_dev],\n",
        "                                           'inflection': np.array(devData[3])[unseenLemInfIndices_dev],\n",
        "                                           'pl pattern': np.array(devData[4])[unseenLemInfIndices_dev]})\n",
        "unseenLemInfIndices_dev_df.to_csv(data_analysis_path + 'unseenLemInf_dev.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w0Fr3rOaClaE",
        "outputId": "3dc6163d-8976-4037-cbc4-8922f09943e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index      lemma   inflection   pl pattern\n",
              "0    224   muHaw~il   muHaw~ilAt   mu1aw~i3At\n",
              "1    234  mujawohar  mujawoharAt  mu1awo3a4At\n",
              "2    283      Haloy       Huliy~       1u2iy~\n",
              "3    298     tAriyx     tawAriyx     tawA2iy3\n",
              "4    325     $Aliyh     $AliyhAt       NTWSAt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94758066-9405-4073-ba80-e8c4e6f1d75f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>pl pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>224</td>\n",
              "      <td>muHaw~il</td>\n",
              "      <td>muHaw~ilAt</td>\n",
              "      <td>mu1aw~i3At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>234</td>\n",
              "      <td>mujawohar</td>\n",
              "      <td>mujawoharAt</td>\n",
              "      <td>mu1awo3a4At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>283</td>\n",
              "      <td>Haloy</td>\n",
              "      <td>Huliy~</td>\n",
              "      <td>1u2iy~</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298</td>\n",
              "      <td>tAriyx</td>\n",
              "      <td>tawAriyx</td>\n",
              "      <td>tawA2iy3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>325</td>\n",
              "      <td>$Aliyh</td>\n",
              "      <td>$AliyhAt</td>\n",
              "      <td>NTWSAt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94758066-9405-4073-ba80-e8c4e6f1d75f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94758066-9405-4073-ba80-e8c4e6f1d75f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94758066-9405-4073-ba80-e8c4e6f1d75f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "unseenLemInfIndices_dev_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZSIHXimcClaE"
      },
      "outputs": [],
      "source": [
        "# create dataframe for test set's unseen data\n",
        "unseenLemmaIndices_test_df = pd.DataFrame({'index': unseenLemmaIndices_test,\n",
        "                                           'lemma': np.array(testData[0])[unseenLemmaIndices_test],\n",
        "                                           'inflection': np.array(testData[3])[unseenLemmaIndices_test],\n",
        "                                           'pl pattern': np.array(testData[4])[unseenLemmaIndices_test]})\n",
        "unseenLemmaIndices_test_df.to_csv(data_analysis_path + 'unseenLemma_test.csv')\n",
        "\n",
        "\n",
        "unseenLemInfIndices_test_df = pd.DataFrame({'index': unseenLemInfIndices_test,\n",
        "                                           'lemma': np.array(testData[0])[unseenLemInfIndices_test],\n",
        "                                           'inflection': np.array(testData[3])[unseenLemInfIndices_test],\n",
        "                                           'pl pattern': np.array(testData[4])[unseenLemInfIndices_test]})\n",
        "unseenLemInfIndices_test_df.to_csv(data_analysis_path + 'unseenLemInf_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a12IILXmClaE",
        "outputId": "98002d18-0800-4006-d22b-025b37810e48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index     lemma  inflection  pl pattern\n",
              "0    179  minaS~ap    minaS~At    mi1a2~At\n",
              "1    274   muDorib  muDoribiyn  mu1o2i3iyn\n",
              "2    312  Eubuw~ap    Eubuw~At    1u2uw~At\n",
              "3    339  rafiyqap    rafiyqAt    1a2iy3At\n",
              "4    362   sAEidap     sawAEid     1awA2i3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41bdc39d-6de7-4d3c-867e-a4421d4ede30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>pl pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>179</td>\n",
              "      <td>minaS~ap</td>\n",
              "      <td>minaS~At</td>\n",
              "      <td>mi1a2~At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>274</td>\n",
              "      <td>muDorib</td>\n",
              "      <td>muDoribiyn</td>\n",
              "      <td>mu1o2i3iyn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>312</td>\n",
              "      <td>Eubuw~ap</td>\n",
              "      <td>Eubuw~At</td>\n",
              "      <td>1u2uw~At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>339</td>\n",
              "      <td>rafiyqap</td>\n",
              "      <td>rafiyqAt</td>\n",
              "      <td>1a2iy3At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>362</td>\n",
              "      <td>sAEidap</td>\n",
              "      <td>sawAEid</td>\n",
              "      <td>1awA2i3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41bdc39d-6de7-4d3c-867e-a4421d4ede30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41bdc39d-6de7-4d3c-867e-a4421d4ede30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41bdc39d-6de7-4d3c-867e-a4421d4ede30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "unseenLemInfIndices_test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_hpLQfwE5B2"
      },
      "source": [
        "## **Work On Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjehYdq8FCGg"
      },
      "outputs": [],
      "source": [
        "# find duplicates and create dictionaries\n",
        "\n",
        "def getDuplicateIndexes(data):\n",
        "  dupindex={}\n",
        "  f=False\n",
        "  for i in range(len(data[0])):\n",
        "    if f: break\n",
        "    lemma = data[0][i]\n",
        "    if dupindex.get(lemma)==None:\n",
        "      dupindex[lemma]=[]\n",
        "      dupindex[lemma].append(i)\n",
        "    else:\n",
        "      f=False\n",
        "      for k in range(len(dupindex[lemma])):\n",
        "        if data[8][i] > data[8][dupindex[lemma][k]]:\n",
        "          dupindex[lemma].insert(0,i)\n",
        "          f=True\n",
        "      if not f : dupindex[lemma].append(i)\n",
        "\n",
        "\n",
        "  return dupindex\n",
        "\n",
        "def reportErrorAnalysis_duplicates(dataframe,dicDup,path):\n",
        "  df=dataframe.loc[[]]\n",
        "  \n",
        "  indexes=[]\n",
        "  for key, value in dicDup.items():\n",
        "    if len(value)>1 :\n",
        "      for x in value:\n",
        "        n=len(df)\n",
        "        indexes.append(x)\n",
        "        df.loc[n]=dataframe.loc[x]\n",
        "  df.insert(0, \"index\", indexes, True)\n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "\n",
        "if is_dataOrginal:\n",
        "  #Save similar lemmas indexes in dictionary (key->lemma | value->list of indexes)\n",
        "  trainDupIndex=getDuplicateIndexes(trainData)\n",
        "  devDupIndex=getDuplicateIndexes(devData)\n",
        "  testDupIndex=getDuplicateIndexes(testData)\n",
        "  print(\"duplicate indexes has been updated\")\n",
        "  print(trainDupIndex)\n",
        "\n",
        "if is_dataOrginal:\n",
        "  #Save Duplicate report on data in csv\n",
        "  trainDuplicateCsv=reportErrorAnalysis_duplicates(train_csv,trainDupIndex,data_analysis_path+\"/duplicateAnalyssis_train.csv\")\n",
        "  devDuplicateCsv=reportErrorAnalysis_duplicates(dev_csv,devDupIndex,data_analysis_path+\"/duplicateAnalyssis_dev.csv\")\n",
        "  testDuplicateCsv=reportErrorAnalysis_duplicates(test_csv,testDupIndex,data_analysis_path+\"/duplicateAnalyssis_test.csv\")\n",
        "  print(\"Report Error Analysis on duplicates has been saved in /content/drive/MyDrive/AI Projects/Arabic Broken Plural/Datasets analysis path\")\n",
        "\n",
        "#Generate lemma-inflection refrence\n",
        "dic_lemmaInflection={}\n",
        "def updateDic_lemmaInflection(Data,dupIndex):\n",
        "  global dic_lemmaInflection\n",
        "  for key, value in dupIndex.items():\n",
        "    if dic_lemmaInflection.get(key)==None:\n",
        "      dic_lemmaInflection[key]=[]\n",
        "    for x in value : \n",
        "      if not Data[3][x] in dic_lemmaInflection[key]: dic_lemmaInflection[key].append(Data[3][x])\n",
        "\n",
        "if is_dataOrginal:\n",
        "  updateDic_lemmaInflection(trainData,trainDupIndex)\n",
        "  updateDic_lemmaInflection(testData,testDupIndex)\n",
        "  updateDic_lemmaInflection(devData,devDupIndex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TIS2Q8bFLHE",
        "outputId": "0c409a49-a611-4438-cb8e-a19fbf5080b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Lemmas before Dropping duplicates in Train Set:  2862\n",
            "Number Of Lemmas before Dropping duplicates in Test Set:  1103\n",
            "Number Of Lemmas before Dropping duplicates in Dev Set:  1151\n",
            "=============================================================\n",
            "Number Of Lemmas After Dropping duplicates in Train Set:  2475\n",
            "Number Of Lemmas After Dropping duplicates in Test Set:  1028\n",
            "Number Of Lemmas After Dropping duplicates in Dev Set:  1060\n"
          ]
        }
      ],
      "source": [
        "#Drop unnecessary duplicates\n",
        "def getUniqueData(data,dupIndex):\n",
        "  out=[]\n",
        "  #init nested lists\n",
        "  for x in data: out.append([])\n",
        "  #fill out with most frequent lemma-inflection pairs\n",
        "  for key, value in dupIndex.items():\n",
        "    for k in range(len(data)):\n",
        "      out[k].append(data[k][value[0]])\n",
        "  return out\n",
        "\n",
        "\n",
        "trainDataUnique=getUniqueData(trainData,trainDupIndex)\n",
        "devDataUnique=getUniqueData(devData,devDupIndex)\n",
        "testDataUnique=getUniqueData(testData,testDupIndex)\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Train Set: \", len(trainData[0]))\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Test Set: \",len(testData[0]))\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Dev Set: \",len(devData[0]))\n",
        "print(\"=============================================================\")\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Train Set: \", len(trainDataUnique[0]))\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Test Set: \",len(testDataUnique[0]))\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Dev Set: \",len(devDataUnique[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LodNC4wSsL0s"
      },
      "outputs": [],
      "source": [
        "#######Risky Implementation!!! Only Run This Once\n",
        "if is_dataOrginal:\n",
        "  trainData=trainDataUnique\n",
        "  devData=devDataUnique\n",
        "  testData=testDataUnique\n",
        "  is_dataOrginal=False\n",
        "else:\n",
        "  print(\"Warning!!! duplicate rows has already been dropped from data.(skipped this step)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRilqxawClaF"
      },
      "source": [
        "## **Encoding Datasets (Character-based)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UL3rofClaF",
        "outputId": "650c2eee-3de0-4d2f-9392-e3bf3aa21dde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "{'not available char': 0, 'E': 1, 'a': 2, 'm': 3, 'l': 4, '1': 5, '2': 6, '3': 7, '>': 8, 'o': 9, 'A': 10, 'h': 11, 'd': 12, 'f': 13, 'u': 14, 'D': 15, 'w': 16, \"'\": 17, 'j': 18, 'i': 19, 'z': 20, 'p': 21, 'H': 22, 'k': 23, 'n': 24, 'S': 25, 'r': 26, '4': 27, 'q': 28, '~': 29, 'y': 30, 't': 31, 's': 32, '<': 33, 'b': 34, 'v': 35, '|': 36, 'T': 37, '}': 38, 'Z': 39, '{': 40, '&': 41, '$': 42, 'x': 43, 'N': 44, 'W': 45, '*': 46, 'g': 47, 'Y': 48, 'F': 49}\n"
          ]
        }
      ],
      "source": [
        "# generate character encoding\n",
        "oov_token = 'not available char'\n",
        "char_index = {oov_token: 0}\n",
        "\n",
        "def updateCharIndex(data):\n",
        "  global char_index\n",
        "  # encode input with encoding character set\n",
        "  for i in range(len(data[0])):\n",
        "      chars = data[0][i] + data[1][i] + data[3][i] + data[4][i]\n",
        "      for c in chars:\n",
        "          if c not in char_index:\n",
        "              char_index[c] = len(char_index)\n",
        "\n",
        "updateCharIndex(trainData)\n",
        "print(len(char_index))\n",
        "print(char_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3aR6noZClaF",
        "outputId": "f3cc5eb8-3100-42d5-9f80-e47badf3bde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma shape train:  2475\n",
            "lemma shape dev:  1060\n",
            "lemma shape test:  1028\n",
            "max length in lemma elements:  17\n",
            "max length in root elements:  4\n",
            "max length in inflection elements:  18\n"
          ]
        }
      ],
      "source": [
        "# encode words with character encoder\n",
        "def encodeWord(word, dic=char_index, oov=oov_token):\n",
        "    return [dic[c] if c in dic else dic[oov] for c in list(word)]\n",
        "\n",
        "# encode data and get maximum length of features\n",
        "def getEncodedData(data):\n",
        "  '''\n",
        "  Output type->List : 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:number of root\n",
        "  '''\n",
        "\n",
        "  data_encoded = data.copy()\n",
        "  data_encoded[0] = [encodeWord(each) for each in data[0]]\n",
        "  data_encoded[1] = [encodeWord(each) for each in data[1]]\n",
        "  data_encoded[2] = [encodeWord(each) for each in data[2]]\n",
        "  data_encoded[3] = [encodeWord(each) for each in data[3]]\n",
        "  data_encoded[4] = [encodeWord(each) for each in data[4]]\n",
        "\n",
        "  lemma_max_len = max([len(each) for each in data_encoded[0]])\n",
        "  root_max_len = max([len(each) for each in data_encoded[2]])\n",
        "  inflection_max_len = max([len(each) for each in data_encoded[3]])\n",
        "\n",
        "  return data_encoded, lemma_max_len, root_max_len, inflection_max_len\n",
        "\n",
        "\n",
        "trainData_encoded, lemma_max_len, root_max_len, inflection_max_len = getEncodedData(trainData)\n",
        "devData_encoded, _, _, _  = getEncodedData(devData)\n",
        "testData_encoded, _, _, _ = getEncodedData(testData)\n",
        "\n",
        "print('lemma shape train: ', len(trainData_encoded[0]))\n",
        "print('lemma shape dev: ', len(devData_encoded[0]))\n",
        "print('lemma shape test: ', len(testData_encoded[0]))\n",
        "print('max length in lemma elements: ', lemma_max_len)\n",
        "print('max length in root elements: ', root_max_len)\n",
        "print('max length in inflection elements: ', inflection_max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDYp2LuClaF",
        "outputId": "33da88c3-49bd-4776-ba7c-9ad335d91bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma with pad shape train:  (2475, 17)\n",
            "lemma with pad shape dev:  (1060, 17)\n",
            "lemma with pad shape test:  (1028, 17)\n"
          ]
        }
      ],
      "source": [
        "# ADD padding to sample\n",
        "# 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "def getPaddedData(encodedData, lemma_max_len, root_max_len, inflection_max_len):\n",
        "  data_pad = []\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[0], maxlen=lemma_max_len, padding='post'))) \n",
        "  data_pad.append(np.array(pad_sequences(encodedData[1], maxlen=lemma_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[2], maxlen=root_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[3], maxlen=inflection_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[4], maxlen=inflection_max_len, padding='post')))\n",
        "  data_pad.append(np.array(encodedData[5]))\n",
        "  data_pad.append(np.array(encodedData[6]))\n",
        "  data_pad.append(np.array(encodedData[7]))\n",
        "  data_pad.append(np.array(encodedData[8]))\n",
        "\n",
        "  return data_pad\n",
        "\n",
        "trainData_pad = getPaddedData(trainData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "devData_pad = getPaddedData(devData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "testData_pad = getPaddedData(testData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "\n",
        "print('lemma with pad shape train: ', trainData_pad[0].shape)\n",
        "print('lemma with pad shape dev: ', devData_pad[0].shape)\n",
        "print('lemma with pad shape test: ', testData_pad[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O45BUvM0ClaF"
      },
      "source": [
        "### **Create inputs of neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm__BnNyClaF",
        "outputId": "07abd9a9-27ce-4b95-b5cf-6b93dde4f612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_lemma shape:  (2475, 17)\n",
            "X_train_singularPattern shape:  (2475, 17)\n",
            "X_train_root shape:  (2475, 4)\n",
            "X_train_genRat shape:  (2475, 2)\n",
            "X_train_numOfRoot shape:  (2475, 1)\n",
            "y_train_class shape:  (2475, 1)\n",
            "y_train_plPattern shape:  (2475, 18)\n",
            "y_train_unflection shape:  (2475, 18)\n"
          ]
        }
      ],
      "source": [
        "# 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:number of root\n",
        "# create train set\n",
        "X_train_lemma = trainData_pad[0]  # lemma feature\n",
        "X_train_singularPattern = trainData_pad[1]  # singular pattern feature\n",
        "X_train_root = trainData_pad[2]  # root feature\n",
        "X_train_genRat = np.stack((trainData_pad[6], trainData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_train_numOfRoot = trainData_pad[8].reshape((trainData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_train_class = trainData_pad[5].reshape((trainData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_train_plPattern = trainData_pad[4]  # plural pattern\n",
        "y_train_inflection = trainData_pad[3]  # inflection\n",
        "\n",
        "# create dev set\n",
        "X_dev_lemma = devData_pad[0]  # lemma feature\n",
        "X_dev_singularPattern = devData_pad[1]  # singular pattern feature\n",
        "X_dev_root = devData_pad[2]  # root feature\n",
        "X_dev_genRat = np.stack((devData_pad[6], devData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_dev_numOfRoot = devData_pad[8].reshape((devData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_dev_class = devData_pad[5].reshape((devData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_dev_plPattern = devData_pad[4]  # plural pattern\n",
        "y_dev_inflection = devData_pad[3]  # inflection\n",
        "\n",
        "# create test set\n",
        "X_test_lemma = testData_pad[0]  # lemma feature\n",
        "X_test_singularPattern = testData_pad[1]  # singular pattern feature\n",
        "X_test_root = testData_pad[2]  # root feature\n",
        "X_test_genRat = np.stack((testData_pad[6], testData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_test_numOfRoot = testData_pad[8].reshape((testData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_test_class = testData_pad[5].reshape((testData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_test_plPattern = testData_pad[4]  # plural pattern\n",
        "y_test_inflection = testData_pad[3]  # inflection\n",
        "\n",
        "print('X_train_lemma shape: ', X_train_lemma.shape)\n",
        "print('X_train_singularPattern shape: ', X_train_singularPattern.shape)\n",
        "print('X_train_root shape: ', X_train_root.shape)\n",
        "print('X_train_genRat shape: ', X_train_genRat.shape)\n",
        "print('X_train_numOfRoot shape: ', X_train_numOfRoot.shape)\n",
        "print('y_train_class shape: ', y_train_class.shape)\n",
        "print('y_train_plPattern shape: ', y_train_plPattern.shape)\n",
        "print('y_train_unflection shape: ', y_train_inflection.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5tEprqGClaG",
        "outputId": "8185477c-7708-4e7a-cc6d-f94ad094fb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2475, 17, 50)\n",
            "(2475, 17, 50)\n",
            "(2475, 4, 50)\n",
            "(2475, 18, 50)\n",
            "(2475, 18, 50)\n"
          ]
        }
      ],
      "source": [
        "# Convert to ONE-HOT encoding\n",
        "X_train_lemma_OH = to_categorical(X_train_lemma, len(char_index))\n",
        "X_train_singularPattern_OH = to_categorical(X_train_singularPattern, len(char_index))\n",
        "X_train_root_OH = to_categorical(X_train_root, len(char_index))\n",
        "\n",
        "X_dev_lemma_OH = to_categorical(X_dev_lemma, len(char_index))\n",
        "X_dev_singularPattern_OH = to_categorical(X_dev_singularPattern, len(char_index))\n",
        "X_dev_root_OH = to_categorical(X_dev_root, len(char_index))\n",
        "\n",
        "X_test_lemma_OH = to_categorical(X_test_lemma, len(char_index))\n",
        "X_test_singularPattern_OH = to_categorical(X_test_singularPattern, len(char_index))\n",
        "X_test_root_OH = to_categorical(X_test_root, len(char_index))\n",
        "\n",
        "y_train_plPattern_OH = to_categorical(y_train_plPattern, len(char_index))\n",
        "y_dev_plPattern_OH = to_categorical(y_dev_plPattern, len(char_index))\n",
        "y_test_plPattern_OH = to_categorical(y_test_plPattern, len(char_index))\n",
        "\n",
        "y_train_inflection_OH = to_categorical(y_train_inflection, len(char_index))\n",
        "y_dev_inflection_OH = to_categorical(y_dev_inflection, len(char_index))\n",
        "y_test_inflection_OH = to_categorical(y_test_inflection, len(char_index))\n",
        "\n",
        "print(X_train_lemma_OH.shape)\n",
        "print(X_train_singularPattern_OH.shape)\n",
        "print(X_train_root_OH.shape)\n",
        "print(y_train_plPattern_OH.shape)\n",
        "print(y_train_inflection_OH.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IxUhzb3nClaG"
      },
      "outputs": [],
      "source": [
        "# covern numerical inputs to int32\n",
        "X_train_genRat = np.asarray(X_train_genRat).astype('int32')\n",
        "X_train_numOfRoot = np.asarray(X_train_numOfRoot).astype('int32')\n",
        "X_dev_genRat = np.asarray(X_dev_genRat).astype('int32')\n",
        "X_dev_numOfRoot = np.asarray(X_dev_numOfRoot).astype('int32')\n",
        "X_test_genRat = np.asarray(X_test_genRat).astype('int32')\n",
        "X_test_numOfRoot = np.asarray(X_test_numOfRoot).astype('int32')\n",
        "\n",
        "y_train_class = np.asarray(y_train_class).astype('int32')\n",
        "y_dev_class = np.asarray(y_dev_class).astype('int32')\n",
        "y_test_class = np.asarray(y_test_class).astype('int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO43412TA77a"
      },
      "source": [
        "## **Encoding Bert Inputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4kA8ZNkBdTG"
      },
      "outputs": [],
      "source": [
        "max_len = 8\n",
        "\n",
        "def getBertInputs(data,max_len):\n",
        "  ids=[]\n",
        "  token_type_ids=[]\n",
        "  attention_mask=[]\n",
        "\n",
        "  for i in range(len(data[0])):\n",
        "    bert_tokenized = bert_tokenizer.encode_plus(\n",
        "        ''.join(getArabicForm(data[0][i])),\n",
        "        max_length=max_len,\n",
        "        add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "        return_token_type_ids=True,\n",
        "        padding='max_length',  # Pad to longest in batch.\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='tf'  # Return PyTorch tensors\n",
        "    )\n",
        "    ids.append(bert_tokenized['input_ids'])\n",
        "    token_type_ids.append(bert_tokenized['token_type_ids'])\n",
        "    attention_mask.append(bert_tokenized['attention_mask'])\n",
        "  \n",
        "  return ids,token_type_ids,attention_mask\n",
        "\n",
        "trainBert_ids, trainBert_token_type, trainBert_attention_mask = getBertInputs(trainData, max_len)\n",
        "devBert_ids, devBert_token_type, devBert_attention_mask = getBertInputs(devData, max_len)\n",
        "testBert_ids, testBert_token_type, testBert_attention_mask = getBertInputs(testData, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(min([np.count_nonzero(x==0) for x in trainBert_ids]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paZGfm7erG6K",
        "outputId": "df9419f2-567c-4b76-c791-ef5a86225337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY7JLXEEJCw8"
      },
      "outputs": [],
      "source": [
        "encoder = TFBertModel.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "def getEmbeding(ids,token_type,attention_mask,max_len):  \n",
        "  bert_embedding=[]\n",
        "  for i in range(len(ids)):\n",
        "    embedding_output = np.array(encoder(input_ids=ids[i], token_type_ids=token_type[i], attention_mask=attention_mask[i])[1])\n",
        "    embedding_output = embedding_output.reshape(embedding_output.shape[1])\n",
        "    bert_embedding.append(embedding_output)\n",
        "\n",
        "  bert_embedding = np.stack(bert_embedding, axis=0)\n",
        "  return bert_embedding\n",
        "\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "  trainBert_embedding = getEmbeding(trainBert_ids, trainBert_token_type, trainBert_attention_mask, max_len)\n",
        "  np.save(dataPath+'/train_bert_embedding.npy', trainBert_embedding)\n",
        "  print('train is done!')\n",
        "  devBert_embedding = getEmbeding(devBert_ids, devBert_token_type, devBert_attention_mask, max_len)\n",
        "  np.save(dataPath+'/dev_bert_embedding.npy', devBert_embedding)\n",
        "  print('dev is done!')\n",
        "  testBert_embedding = getEmbeding(testBert_ids, testBert_token_type, testBert_attention_mask, max_len)\n",
        "  np.save(dataPath+'/test_bert_embedding.npy', testBert_embedding)\n",
        "  print('test is done!')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read bert_embedding from google drive\n",
        "trainBert_embedding = np.load(dataPath+'/train_bert_embedding.npy')\n",
        "devBert_embedding = np.load(dataPath+'/dev_bert_embedding.npy')\n",
        "testBert_embedding = np.load(dataPath+'/test_bert_embedding.npy')"
      ],
      "metadata": {
        "id": "qQsAFwOtvFxt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "inNPOD5aMDvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82a2422-81cc-49fc-9f4d-15529d94c395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2475, 768)\n",
            "(1060, 768)\n",
            "(1028, 768)\n"
          ]
        }
      ],
      "source": [
        "print(trainBert_embedding.shape)\n",
        "print(devBert_embedding.shape)\n",
        "print(testBert_embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62hKeeV_2G77"
      },
      "source": [
        "### **Create inputs of neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936d29ad-6ddb-43c4-adbf-8e7f8b149893",
        "id": "929QNlk72G7_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_bert shape:  (2475, 768)\n",
            "X_train_lemma shape:  (2475, 17)\n",
            "X_train_singularPattern shape:  (2475, 17)\n",
            "X_train_root shape:  (2475, 4)\n",
            "X_train_genRat shape:  (2475, 2)\n",
            "X_train_numOfRoot shape:  (2475, 1)\n",
            "y_train_class shape:  (2475, 1)\n",
            "y_train_plPattern shape:  (2475, 18)\n",
            "y_train_unflection shape:  (2475, 18)\n"
          ]
        }
      ],
      "source": [
        "# 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:number of root\n",
        "# create train set\n",
        "X_train_bert = trainBert_embedding\n",
        "X_train_lemma = trainData_pad[0]  # lemma feature\n",
        "X_train_singularPattern = trainData_pad[1]  # singular pattern feature\n",
        "X_train_root = trainData_pad[2]  # root feature\n",
        "X_train_genRat = np.stack((trainData_pad[6], trainData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_train_numOfRoot = trainData_pad[8].reshape((trainData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_train_class = trainData_pad[5].reshape((trainData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_train_plPattern = trainData_pad[4]  # plural pattern\n",
        "y_train_inflection = trainData_pad[3]  # inflection\n",
        "\n",
        "# create dev set\n",
        "X_dev_bert = devBert_embedding\n",
        "X_dev_lemma = devData_pad[0]  # lemma feature\n",
        "X_dev_singularPattern = devData_pad[1]  # singular pattern feature\n",
        "X_dev_root = devData_pad[2]  # root feature\n",
        "X_dev_genRat = np.stack((devData_pad[6], devData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_dev_numOfRoot = devData_pad[8].reshape((devData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_dev_class = devData_pad[5].reshape((devData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_dev_plPattern = devData_pad[4]  # plural pattern\n",
        "y_dev_inflection = devData_pad[3]  # inflection\n",
        "\n",
        "# create test set\n",
        "X_test_bert = testBert_embedding\n",
        "X_test_lemma = testData_pad[0]  # lemma feature\n",
        "X_test_singularPattern = testData_pad[1]  # singular pattern feature\n",
        "X_test_root = testData_pad[2]  # root feature\n",
        "X_test_genRat = np.stack((testData_pad[6], testData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_test_numOfRoot = testData_pad[8].reshape((testData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_test_class = testData_pad[5].reshape((testData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_test_plPattern = testData_pad[4]  # plural pattern\n",
        "y_test_inflection = testData_pad[3]  # inflection\n",
        "\n",
        "print('X_train_bert shape: ', X_train_bert.shape)\n",
        "print('X_train_lemma shape: ', X_train_lemma.shape)\n",
        "print('X_train_singularPattern shape: ', X_train_singularPattern.shape)\n",
        "print('X_train_root shape: ', X_train_root.shape)\n",
        "print('X_train_genRat shape: ', X_train_genRat.shape)\n",
        "print('X_train_numOfRoot shape: ', X_train_numOfRoot.shape)\n",
        "print('y_train_class shape: ', y_train_class.shape)\n",
        "print('y_train_plPattern shape: ', y_train_plPattern.shape)\n",
        "print('y_train_unflection shape: ', y_train_inflection.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfa8e90-864b-43aa-e66e-71ec8ddb5727",
        "id": "s9p_i-u-2G8K"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2475, 17, 50)\n",
            "(2475, 17, 50)\n",
            "(2475, 4, 50)\n",
            "(2475, 18, 50)\n",
            "(2475, 18, 50)\n"
          ]
        }
      ],
      "source": [
        "# Convert to ONE-HOT encoding\n",
        "X_train_lemma_OH = to_categorical(X_train_lemma, len(char_index))\n",
        "X_train_singularPattern_OH = to_categorical(X_train_singularPattern, len(char_index))\n",
        "X_train_root_OH = to_categorical(X_train_root, len(char_index))\n",
        "\n",
        "X_dev_lemma_OH = to_categorical(X_dev_lemma, len(char_index))\n",
        "X_dev_singularPattern_OH = to_categorical(X_dev_singularPattern, len(char_index))\n",
        "X_dev_root_OH = to_categorical(X_dev_root, len(char_index))\n",
        "\n",
        "X_test_lemma_OH = to_categorical(X_test_lemma, len(char_index))\n",
        "X_test_singularPattern_OH = to_categorical(X_test_singularPattern, len(char_index))\n",
        "X_test_root_OH = to_categorical(X_test_root, len(char_index))\n",
        "\n",
        "y_train_plPattern_OH = to_categorical(y_train_plPattern, len(char_index))\n",
        "y_dev_plPattern_OH = to_categorical(y_dev_plPattern, len(char_index))\n",
        "y_test_plPattern_OH = to_categorical(y_test_plPattern, len(char_index))\n",
        "\n",
        "y_train_inflection_OH = to_categorical(y_train_inflection, len(char_index))\n",
        "y_dev_inflection_OH = to_categorical(y_dev_inflection, len(char_index))\n",
        "y_test_inflection_OH = to_categorical(y_test_inflection, len(char_index))\n",
        "\n",
        "print(X_train_lemma_OH.shape)\n",
        "print(X_train_singularPattern_OH.shape)\n",
        "print(X_train_root_OH.shape)\n",
        "print(y_train_plPattern_OH.shape)\n",
        "print(y_train_inflection_OH.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "4JFJCYFv2G8P"
      },
      "outputs": [],
      "source": [
        "# convert numerical inputs to int32\n",
        "X_train_genRat = np.asarray(X_train_genRat).astype('int32')\n",
        "X_train_numOfRoot = np.asarray(X_train_numOfRoot).astype('int32')\n",
        "X_dev_genRat = np.asarray(X_dev_genRat).astype('int32')\n",
        "X_dev_numOfRoot = np.asarray(X_dev_numOfRoot).astype('int32')\n",
        "X_test_genRat = np.asarray(X_test_genRat).astype('int32')\n",
        "X_test_numOfRoot = np.asarray(X_test_numOfRoot).astype('int32')\n",
        "\n",
        "y_train_class = np.asarray(y_train_class).astype('int32')\n",
        "y_dev_class = np.asarray(y_dev_class).astype('int32')\n",
        "y_test_class = np.asarray(y_test_class).astype('int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4MC1JT3TSec"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "PtI4-1PCuFcB"
      },
      "outputs": [],
      "source": [
        "def getDuplicateIndexes(data):\n",
        "  dupindex={}\n",
        "  for i in range(len(data[0])):\n",
        "    if dupindex.get(data[0][i])==None:\n",
        "      dupindex[data[0][i]]=[]\n",
        "    dupindex[data[0][i]].append(i)\n",
        "\n",
        "  return dupindex\n",
        "\n",
        "def reportErrorAnalysis_duplicates(dataframe,dicDup,path):\n",
        "  df=dataframe.loc[[]]\n",
        "  \n",
        "  indexes=[]\n",
        "  for key, value in dicDup.items():\n",
        "    for x in value:\n",
        "      n=len(df)\n",
        "      indexes.append(x)\n",
        "      df.loc[n]=dataframe.loc[x]\n",
        "  df.insert(0, \"index\", indexes, True)\n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "\n",
        "#Save similar lemmas indexes in dictionary (key->lemma | value->list of indexes)\n",
        "trainDupIndex=getDuplicateIndexes(trainData)\n",
        "devDupIndex=getDuplicateIndexes(devData)\n",
        "testDupIndex=getDuplicateIndexes(testData)\n",
        "\n",
        "\n",
        "#Save Duplicate report on data in csv\n",
        "trainDuplicateCsv=reportErrorAnalysis_duplicates(train_csv,trainDupIndex,dataPath+\"/duplicateAnalyssis_train.csv\")\n",
        "devDuplicateCsv=reportErrorAnalysis_duplicates(dev_csv,devDupIndex,dataPath+\"/duplicateAnalyssis_dev.csv\")\n",
        "testDuplicateCsv=reportErrorAnalysis_duplicates(test_csv,testDupIndex,dataPath+\"/duplicateAnalyssis_test.csv\")\n",
        "\n",
        "#Generate lemma-inflection refrence\n",
        "dic_lemmaInflection={}\n",
        "def updateDic_lemmaInflection(Data,dupIndex):\n",
        "  global dic_lemmaInflection\n",
        "  for key, value in dupIndex.items():\n",
        "    if dic_lemmaInflection.get(key)==None:\n",
        "      dic_lemmaInflection[key]=[]\n",
        "      for x in value : \n",
        "        if not Data[3][x] in dic_lemmaInflection[key]: dic_lemmaInflection[key].append(Data[3][x])\n",
        "\n",
        "updateDic_lemmaInflection(trainData,trainDupIndex)\n",
        "updateDic_lemmaInflection(testData,testDupIndex)\n",
        "updateDic_lemmaInflection(devData,devDupIndex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXiNUVV7zFqX",
        "outputId": "c6095718-a0f8-4bf2-b182-8b59a3c29e7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.updateDic_lemmaInflection(Data, dupIndex)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "updateDic_lemmaInflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PYqxULkbTSed"
      },
      "outputs": [],
      "source": [
        "def oneHot2D(arr):\n",
        "    tmp = np.zeros_like(arr)\n",
        "    tmp[np.arange(len(arr)), arr.argmax(1)] = 1\n",
        "    return tmp\n",
        "\n",
        "def oneHot3D(arr):\n",
        "    tmp = np.array([oneHot2D(x) for x in arr])\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "lR89g_k_7dYp"
      },
      "outputs": [],
      "source": [
        "char_index_key_list = list(char_index.keys())\n",
        "char_index_val_list = list(char_index.values())\n",
        "def getCharFromIdx(idx):\n",
        "  position = char_index_val_list.index(idx)\n",
        "  return char_index_key_list[position]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "M6wNFevTTSee"
      },
      "outputs": [],
      "source": [
        "def getWordFromOnehot(onehot):\n",
        "  encoded=np.argmax(onehot, axis=1)\n",
        "  word=[]\n",
        "  for x in encoded:\n",
        "    if x==0:break\n",
        "    word.append(getCharFromIdx(x))\n",
        "  return ''.join(word)\n",
        "\n",
        "def binaryConversion(arr, threshold=0.5):\n",
        "  tmp = np.zeros_like(arr)\n",
        "  tmp[arr > threshold] = 1\n",
        "  return tmp\n",
        "\n",
        "def reportResult(model, history, X_test, y_test):\n",
        "\n",
        "    # best models based on acc or loss in tarin set or test set\n",
        "    testHistory = list(\n",
        "        map(lambda x, y: [x, y], history['val_accuracy'], history['val_loss']))\n",
        "    print(\n",
        "        f\"best model based on min test set loss:  acc= {min(testHistory, key = lambda k: k[1])[0]}  loss= {min(testHistory, key = lambda k: k[1])[1]}\")\n",
        "    print(\n",
        "        f\"best model based on max test set accuracy:  acc= {max(testHistory, key = lambda k: k[0])[0]}  loss= {max(testHistory, key = lambda k: k[0])[1]}\")\n",
        "\n",
        "    print(\"\\nevaluate dataset with best model based on maximum test set accuracy\")\n",
        "    print(\"evaluate test set = \", model.evaluate(X_test, y_test, verbose=0))\n",
        "\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_test_pred = binaryConversion(y_test_pred)\n",
        "\n",
        "    # confusion matrix and precision, recall and f1 report\n",
        "    print('-'*30, 'metrics for test set', '-'*30)\n",
        "    print(\"confusion matrix: \\n\", metrics.confusion_matrix(y_test, y_test_pred))\n",
        "    print(metrics.classification_report(y_test,\n",
        "          y_test_pred, digits=3, target_names=['Broken', 'Sound']))\n",
        "    \n",
        "def argmaxKeepDimensions(arr):\n",
        "  tmp = np.zeros_like(arr)\n",
        "  tmp[np.arange(len(arr)), arr.argmax(1)] = 1\n",
        "  return tmp\n",
        "\n",
        "def checkAccuracy(pred, true):\n",
        "  size = pred.shape[0]\n",
        "  numOfTrue = 0\n",
        "  for (x, y) in zip(pred, true):\n",
        "    if np.array_equal(x, y):\n",
        "      numOfTrue += 1\n",
        "  \n",
        "  return size-numOfTrue, numOfTrue/size\n",
        "\n",
        "def checkAccuracy_anyAcceptableInflectionInDataset(lemma, pred, dic_refrence):\n",
        "  size = pred.shape[0]\n",
        "  numOfTrue = 0\n",
        "  for i in range (len(pred)):\n",
        "    w=getWordFromOnehot(pred[i])\n",
        "    if w in dic_refrence[lemma[i]]:\n",
        "      numOfTrue += 1\n",
        "  \n",
        "  return size-numOfTrue, numOfTrue/size\n",
        "\n",
        "def reportErrorAnalysis(lemma, bs, pred_OH, inflection_OH, path):\n",
        "  size = pred_OH.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'b/s':[], 'inflection':[], 'predict':[]}\n",
        "  i=0\n",
        "  for (x, y) in zip(pred_OH, inflection_OH):\n",
        "    if not np.array_equal(x, y):\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(bs[i])\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['predict'].append(getWordFromOnehot(pred_OH[i]))\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "def reportErrorAnalysis_inflectionWithBS(lemma, bs,bs_pred, pred_OH, inflection_OH, path):\n",
        "  size = pred_OH.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'b/s':[], 'b/s predict':[], 'inflection':[], 'predict':[]}\n",
        "  bs_pred = binaryConversion(bs_pred)\n",
        "  i=0\n",
        "  for (x, y) in zip(pred_OH, inflection_OH):\n",
        "    if not np.array_equal(x, y):\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(bs[i])\n",
        "      report['b/s predict'].append(bs_pred[i])\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['predict'].append(getWordFromOnehot(pred_OH[i]))\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "def reportErrorAnalysis_classification(lemma, inflection_OH, bs, bs_pred, path):\n",
        "  size = bs.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'inflection':[],'b/s':[], 'b/s predict':[] }\n",
        "  bs_pred = binaryConversion(bs_pred, 0.5)\n",
        "  i=0\n",
        "  for (x, y) in zip(bs, bs_pred):\n",
        "    if not x==y:\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(x)\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['b/s predict'].append(y)\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "jPbJ_pHqmsyV"
      },
      "outputs": [],
      "source": [
        "def reportPercentageOfBrokenSoundErrors(dataset_errorAnalysis):\n",
        "  total_errors_num = dataset_errorAnalysis.shape[0]\n",
        "  train_sound_error = np.sum(dataset_errorAnalysis['b/s'])\n",
        "  train_broken_error = total_errors_num - train_sound_error\n",
        "  return train_broken_error/total_errors_num * 100, train_sound_error/total_errors_num * 100\n",
        "\n",
        "def reportPercentageOfUnseenErrors(errorIndices, unseenIndices):\n",
        "  isInUnseen = np.array([index in unseenIndices for index in errorIndices])\n",
        "  return np.count_nonzero(isInUnseen==True) / len(errorIndices) * 100, np.count_nonzero(isInUnseen==True) / len(unseenIndices) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aRDIUaOvvJv"
      },
      "source": [
        "# **Classification Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2WmPwVwV7z-"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "# path = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/Results/Classification Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caFMHfjbiMQT"
      },
      "outputs": [],
      "source": [
        "lemma_length = X_train_lemma_OH.shape[1] #17\n",
        "encode_size = X_train_lemma_OH.shape[2] #50\n",
        "genRat_length = X_train_genRat.shape[1] #2\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYae4z1hhH4t"
      },
      "source": [
        "## **Model 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUCsnXkThH4z"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length,), name='Gender-Rational')\n",
        "\n",
        "\n",
        "lstm = Bidirectional(LSTM(256, name='Lstm'), name='Bidirectional')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm, input_genRat])\n",
        "\n",
        "d = Dense(256, activation='relu', name='Dense1')(c)\n",
        "d = Dense(64, activation='relu', name='Dense2')(d)\n",
        "\n",
        "output = Dense(1, activation='sigmoid', name='Class')(d)\n",
        "model = Model(inputs=[input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "model.save(path + \"/model 1/structure.h5\")\n",
        "\n",
        "checkpoint_filepath = path + '/model 1/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd9ygt4yhH4-"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  history = model.fit([X_train_lemma_OH, X_train_genRat], y_train_class, batch_size=batch_size, epochs=epochs, \n",
        "                      verbose=1, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], y_dev_class)).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB-ixvAghH5E"
      },
      "outputs": [],
      "source": [
        "print(model.summary())\n",
        "plot_model(model, to_file=path+'/model 1/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDj9zmJqhH5J"
      },
      "outputs": [],
      "source": [
        "model = load_model(checkpoint_filepath)\n",
        "model.evaluate([X_test_lemma_OH, X_test_genRat], y_test_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reportResult(model, history, [X_test_lemma_OH, X_test_genRat], y_test_class)"
      ],
      "metadata": {
        "id": "BPWyu0gjgiHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Error Analysis**"
      ],
      "metadata": {
        "id": "DBYWYsIYgR4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train set"
      ],
      "metadata": {
        "id": "2WMhXUKOgYzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_class_p=model.predict([X_train_lemma_OH, X_train_genRat])\n",
        "reportErrorAnalysis_classification(trainData[0], y_train_inflection_OH, y_train_class, train_class_p, path + \"/model 1/train_errorAnalysis.csv\")"
      ],
      "metadata": {
        "id": "WxnbG5hDtWlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dev set"
      ],
      "metadata": {
        "id": "YBgk1fKxgain"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_class_p=model.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "reportErrorAnalysis_classification(devData[0], y_dev_inflection_OH, y_dev_class, dev_class_p, path + \"/model 1/dev_errorAnalysis.csv\")"
      ],
      "metadata": {
        "id": "_nD8ybG73xFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test set"
      ],
      "metadata": {
        "id": "I7wyRP-agdO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IP3NKsfhH5N"
      },
      "outputs": [],
      "source": [
        "test_class_p=model.predict([X_test_lemma_OH, X_test_genRat])\n",
        "reportErrorAnalysis_classification(testData[0], y_test_inflection_OH, y_test_class, test_class_p, path + \"/model 1/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB0fawJa66PY"
      },
      "source": [
        "# **Machine Translation Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjirN8TtdNqu"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models'\n",
        "# path = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/Results/Machine Translation Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52n_VZ40dNqy"
      },
      "outputs": [],
      "source": [
        "bert_embedding_length = X_train_bert.shape[1] #768\n",
        "lemma_length = X_train_lemma_OH.shape[1] #17\n",
        "singularPattern_length = X_train_singularPattern_OH.shape[1] #17\n",
        "root_length = X_train_root_OH.shape[1] #4\n",
        "genRat_length = X_train_genRat.shape[1] #2\n",
        "numOfRoot_length = X_train_numOfRoot.shape[1] #1\n",
        "plPattern_length = y_train_plPattern_OH.shape[1] #18\n",
        "inflection_length = y_train_inflection_OH.shape[1] #18\n",
        "encode_size = X_train_lemma_OH.shape[2] #50\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87j_k_oEVh3"
      },
      "source": [
        "## **Model 1**\n",
        "lemma - inflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRB1n7PQknbY"
      },
      "outputs": [],
      "source": [
        "model1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Model 1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-3oRhRlEVh4"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat])\n",
        "\n",
        "d = Dense(256, activation='relu', name='Dense1')(c)\n",
        "\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "model1 = Model(inputs=[input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "checkpoint_filepath = model1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k64r76HEVh4"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  model1.fit([X_train_lemma_OH, X_train_genRat], y_train_inflection_OH, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], y_dev_inflection_OH))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF__oNPxEVh4"
      },
      "outputs": [],
      "source": [
        "model1 = load_model(checkpoint_filepath)\n",
        "model1.evaluate([X_test_lemma_OH, X_test_genRat], y_test_inflection_OH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_uAugdEVh4"
      },
      "outputs": [],
      "source": [
        "print(model1.summary())\n",
        "plot_model(model1, to_file=model1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAoL0KSoEVh4"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq30qNbbEVh5"
      },
      "outputs": [],
      "source": [
        "train_pred = model1.predict([X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lktzh8o5HNsn"
      },
      "outputs": [],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK3xq6x0EVh5"
      },
      "outputs": [],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, model1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzOAAD4jEVh5"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86i08EoppWIi"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybXFriUqEVh5"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s-l01ipEVh5"
      },
      "outputs": [],
      "source": [
        "dev_pred = model1.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPCOBCrEEVh5"
      },
      "outputs": [],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis(devData[0], devData[5], dev_pred_OH, y_dev_inflection_OH, model1_path + \"/dev_errorAnalysis.csv\")\n",
        "dev_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb3-t4ehEVh5"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q8CzzBqpMAR"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0],dev_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOswiP7Fqhdp"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7R3KZnxEVh5"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55GGksBBEVh6"
      },
      "outputs": [],
      "source": [
        "test_pred = model1.predict([X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i57C2rVDEVh6"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis(testData[0], testData[5], test_pred_OH, y_test_inflection_OH, model1_path + \"/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6v7_vY1EVh6"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2NUckr-pPAf"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0],test_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HL3bbXgzGck"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdCz16FjpUjU"
      },
      "source": [
        "## **Mix Model (2 Networks: Classification + Machine Translation)**\n",
        "**with Bert embedding input**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQR4WH4wnbPX"
      },
      "outputs": [],
      "source": [
        "mixModel1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Mix Model 1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU_KhzdDpTiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8768ffef-a75c-49e8-d8fd-8dc1c48ad99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "BSClassification_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "BSClassification_model_path = BSClassification_path + '/model 1/weights.hdf5'\n",
        "BSClassification_model_structure_path = BSClassification_path + \"/model 1/structure.h5\"\n",
        "\n",
        "BSC_model = load_model(BSClassification_model_path)\n",
        "BSC_model_struct = load_model(BSClassification_model_structure_path)\n",
        "\n",
        "BSC_model_struct.set_weights(BSC_model.get_weights())\n",
        "BSC_model_struct.trainable = False\n",
        "# print(BSC_model.layers[1].get_weights()[0][0])\n",
        "# print(BSC_model_struct.layers[1].get_weights()[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0ko_Jsbr3Gs"
      },
      "outputs": [],
      "source": [
        "imput_bert_embedding = Input(shape=(bert_embedding_length, ), name='Bert-Embedding')\n",
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "cls = BSC_model_struct([input_lemma, input_genRat])\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "d = Dense(256,  activation='relu', name='Dense1')(imput_bert_embedding)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat, cls, d])\n",
        "\n",
        "d = Dense(200, activation='relu', name='Dense2')(c)\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "mix_model = Model(inputs=[imput_bert_embedding, input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "checkpoint_filepath = mixModel1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "mix_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i56qrPBBVh4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec2698a-b62a-470c-bec7-d62f86c52957"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02294529, -0.10742611,  0.02736146, ..., -0.18890691,\n",
              "       -0.01805112, -0.01145793], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "mix_model.layers[4].layers[1].get_weights()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJjSxEPFUUx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2c15530-3b32-4e0d-be59-16e63d0d4681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "39/39 [==============================] - 12s 92ms/step - loss: 0.0477 - accuracy: 0.5686 - val_loss: 0.0391 - val_accuracy: 0.6088\n",
            "Epoch 2/100\n",
            "39/39 [==============================] - 1s 26ms/step - loss: 0.0384 - accuracy: 0.6188 - val_loss: 0.0368 - val_accuracy: 0.6297\n",
            "Epoch 3/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0366 - accuracy: 0.6412 - val_loss: 0.0361 - val_accuracy: 0.6310\n",
            "Epoch 4/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0352 - accuracy: 0.6576 - val_loss: 0.0346 - val_accuracy: 0.6562\n",
            "Epoch 5/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0338 - accuracy: 0.6759 - val_loss: 0.0329 - val_accuracy: 0.7026\n",
            "Epoch 6/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0328 - accuracy: 0.6890 - val_loss: 0.0315 - val_accuracy: 0.7120\n",
            "Epoch 7/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0313 - accuracy: 0.7112 - val_loss: 0.0312 - val_accuracy: 0.7070\n",
            "Epoch 8/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0298 - accuracy: 0.7253 - val_loss: 0.0289 - val_accuracy: 0.7364\n",
            "Epoch 9/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0286 - accuracy: 0.7360 - val_loss: 0.0280 - val_accuracy: 0.7427\n",
            "Epoch 10/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0282 - accuracy: 0.7327 - val_loss: 0.0270 - val_accuracy: 0.7473\n",
            "Epoch 11/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0257 - accuracy: 0.7600 - val_loss: 0.0248 - val_accuracy: 0.7699\n",
            "Epoch 12/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0243 - accuracy: 0.7694 - val_loss: 0.0244 - val_accuracy: 0.7649\n",
            "Epoch 13/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0229 - accuracy: 0.7805 - val_loss: 0.0219 - val_accuracy: 0.7940\n",
            "Epoch 14/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0218 - accuracy: 0.7899 - val_loss: 0.0224 - val_accuracy: 0.7799\n",
            "Epoch 15/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0212 - accuracy: 0.7930 - val_loss: 0.0202 - val_accuracy: 0.8057\n",
            "Epoch 16/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0192 - accuracy: 0.8133 - val_loss: 0.0191 - val_accuracy: 0.8174\n",
            "Epoch 17/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0182 - accuracy: 0.8216 - val_loss: 0.0178 - val_accuracy: 0.8296\n",
            "Epoch 18/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0173 - accuracy: 0.8311 - val_loss: 0.0171 - val_accuracy: 0.8382\n",
            "Epoch 19/100\n",
            "39/39 [==============================] - 1s 19ms/step - loss: 0.0165 - accuracy: 0.8367 - val_loss: 0.0169 - val_accuracy: 0.8344\n",
            "Epoch 20/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0157 - accuracy: 0.8436 - val_loss: 0.0161 - val_accuracy: 0.8432\n",
            "Epoch 21/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0152 - accuracy: 0.8493 - val_loss: 0.0155 - val_accuracy: 0.8505\n",
            "Epoch 22/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0146 - accuracy: 0.8539 - val_loss: 0.0150 - val_accuracy: 0.8520\n",
            "Epoch 23/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0161 - accuracy: 0.8379 - val_loss: 0.0156 - val_accuracy: 0.8453\n",
            "Epoch 24/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0140 - accuracy: 0.8607 - val_loss: 0.0138 - val_accuracy: 0.8667\n",
            "Epoch 25/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0125 - accuracy: 0.8743 - val_loss: 0.0133 - val_accuracy: 0.8684\n",
            "Epoch 26/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0123 - accuracy: 0.8765 - val_loss: 0.0123 - val_accuracy: 0.8815\n",
            "Epoch 27/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0113 - accuracy: 0.8863 - val_loss: 0.0129 - val_accuracy: 0.8753\n",
            "Epoch 28/100\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.0111 - accuracy: 0.8900 - val_loss: 0.0117 - val_accuracy: 0.8881\n",
            "Epoch 29/100\n",
            "39/39 [==============================] - 1s 19ms/step - loss: 0.0111 - accuracy: 0.8892 - val_loss: 0.0125 - val_accuracy: 0.8770\n",
            "Epoch 30/100\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.0104 - accuracy: 0.8968 - val_loss: 0.0107 - val_accuracy: 0.9004\n",
            "Epoch 31/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0094 - accuracy: 0.9080 - val_loss: 0.0105 - val_accuracy: 0.9028\n",
            "Epoch 32/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0088 - accuracy: 0.9147 - val_loss: 0.0101 - val_accuracy: 0.9084\n",
            "Epoch 33/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0087 - accuracy: 0.9154 - val_loss: 0.0104 - val_accuracy: 0.9052\n",
            "Epoch 34/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0084 - accuracy: 0.9181 - val_loss: 0.0109 - val_accuracy: 0.8987\n",
            "Epoch 35/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0086 - accuracy: 0.9173 - val_loss: 0.0097 - val_accuracy: 0.9147\n",
            "Epoch 36/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0076 - accuracy: 0.9281 - val_loss: 0.0097 - val_accuracy: 0.9144\n",
            "Epoch 37/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0077 - accuracy: 0.9276 - val_loss: 0.0099 - val_accuracy: 0.9133\n",
            "Epoch 38/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0077 - accuracy: 0.9268 - val_loss: 0.0091 - val_accuracy: 0.9216\n",
            "Epoch 39/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0069 - accuracy: 0.9374 - val_loss: 0.0083 - val_accuracy: 0.9321\n",
            "Epoch 40/100\n",
            "39/39 [==============================] - 1s 26ms/step - loss: 0.0061 - accuracy: 0.9460 - val_loss: 0.0081 - val_accuracy: 0.9353\n",
            "Epoch 41/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0056 - accuracy: 0.9526 - val_loss: 0.0085 - val_accuracy: 0.9276\n",
            "Epoch 42/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0061 - accuracy: 0.9457 - val_loss: 0.0086 - val_accuracy: 0.9296\n",
            "Epoch 43/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0055 - accuracy: 0.9529 - val_loss: 0.0075 - val_accuracy: 0.9440\n",
            "Epoch 44/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0048 - accuracy: 0.9609 - val_loss: 0.0069 - val_accuracy: 0.9519\n",
            "Epoch 45/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0042 - accuracy: 0.9680 - val_loss: 0.0067 - val_accuracy: 0.9541\n",
            "Epoch 46/100\n",
            "39/39 [==============================] - 1s 22ms/step - loss: 0.0057 - accuracy: 0.9513 - val_loss: 0.0074 - val_accuracy: 0.9440\n",
            "Epoch 47/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0044 - accuracy: 0.9659 - val_loss: 0.0064 - val_accuracy: 0.9572\n",
            "Epoch 48/100\n",
            "39/39 [==============================] - 1s 27ms/step - loss: 0.0037 - accuracy: 0.9736 - val_loss: 0.0063 - val_accuracy: 0.9588\n",
            "Epoch 49/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0031 - accuracy: 0.9806 - val_loss: 0.0057 - val_accuracy: 0.9673\n",
            "Epoch 50/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0033 - accuracy: 0.9777 - val_loss: 0.0059 - val_accuracy: 0.9636\n",
            "Epoch 51/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0027 - accuracy: 0.9838 - val_loss: 0.0056 - val_accuracy: 0.9681\n",
            "Epoch 52/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0024 - accuracy: 0.9865 - val_loss: 0.0059 - val_accuracy: 0.9653\n",
            "Epoch 53/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0026 - accuracy: 0.9836 - val_loss: 0.0054 - val_accuracy: 0.9686\n",
            "Epoch 54/100\n",
            "39/39 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9893 - val_loss: 0.0052 - val_accuracy: 0.9735\n",
            "Epoch 55/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0024 - accuracy: 0.9867 - val_loss: 0.0066 - val_accuracy: 0.9584\n",
            "Epoch 56/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0031 - accuracy: 0.9763 - val_loss: 0.0057 - val_accuracy: 0.9655\n",
            "Epoch 57/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0026 - accuracy: 0.9822 - val_loss: 0.0054 - val_accuracy: 0.9692\n",
            "Epoch 58/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0022 - accuracy: 0.9870 - val_loss: 0.0068 - val_accuracy: 0.9586\n",
            "Epoch 59/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 0.9784 - val_loss: 0.0057 - val_accuracy: 0.9683\n",
            "Epoch 60/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0032 - accuracy: 0.9760 - val_loss: 0.0066 - val_accuracy: 0.9549\n",
            "Epoch 61/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0043 - accuracy: 0.9628 - val_loss: 0.0067 - val_accuracy: 0.9530\n",
            "Epoch 62/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0030 - accuracy: 0.9759 - val_loss: 0.0054 - val_accuracy: 0.9697\n",
            "Epoch 63/100\n",
            "39/39 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 0.9889 - val_loss: 0.0048 - val_accuracy: 0.9756\n",
            "Epoch 64/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0018 - accuracy: 0.9903 - val_loss: 0.0051 - val_accuracy: 0.9723\n",
            "Epoch 65/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 0.9945 - val_loss: 0.0048 - val_accuracy: 0.9761\n",
            "Epoch 66/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 9.9665e-04 - accuracy: 0.9966 - val_loss: 0.0046 - val_accuracy: 0.9776\n",
            "Epoch 67/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 7.4997e-04 - accuracy: 0.9975 - val_loss: 0.0046 - val_accuracy: 0.9773\n",
            "Epoch 68/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 6.6423e-04 - accuracy: 0.9981 - val_loss: 0.0045 - val_accuracy: 0.9785\n",
            "Epoch 69/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 5.3737e-04 - accuracy: 0.9989 - val_loss: 0.0045 - val_accuracy: 0.9787\n",
            "Epoch 70/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 5.2572e-04 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9781\n",
            "Epoch 71/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 6.3695e-04 - accuracy: 0.9974 - val_loss: 0.0047 - val_accuracy: 0.9771\n",
            "Epoch 72/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 7.1700e-04 - accuracy: 0.9971 - val_loss: 0.0048 - val_accuracy: 0.9767\n",
            "Epoch 73/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 8.9201e-04 - accuracy: 0.9958 - val_loss: 0.0048 - val_accuracy: 0.9756\n",
            "Epoch 74/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0017 - accuracy: 0.9895 - val_loss: 0.0051 - val_accuracy: 0.9731\n",
            "Epoch 75/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0014 - accuracy: 0.9918 - val_loss: 0.0052 - val_accuracy: 0.9708\n",
            "Epoch 76/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0023 - accuracy: 0.9823 - val_loss: 0.0071 - val_accuracy: 0.9539\n",
            "Epoch 77/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0025 - accuracy: 0.9798 - val_loss: 0.0055 - val_accuracy: 0.9693\n",
            "Epoch 78/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0012 - accuracy: 0.9941 - val_loss: 0.0050 - val_accuracy: 0.9768\n",
            "Epoch 79/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 5.7465e-04 - accuracy: 0.9988 - val_loss: 0.0047 - val_accuracy: 0.9791\n",
            "Epoch 80/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 3.5334e-04 - accuracy: 0.9996 - val_loss: 0.0046 - val_accuracy: 0.9787\n",
            "Epoch 81/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 2.8028e-04 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9789\n",
            "Epoch 82/100\n",
            "39/39 [==============================] - 1s 24ms/step - loss: 2.3973e-04 - accuracy: 0.9998 - val_loss: 0.0047 - val_accuracy: 0.9794\n",
            "Epoch 83/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 2.1974e-04 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9791\n",
            "Epoch 84/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 2.0456e-04 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9789\n",
            "Epoch 85/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 1.9013e-04 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9791\n",
            "Epoch 86/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 1.8427e-04 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9792\n",
            "Epoch 87/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 1.7512e-04 - accuracy: 0.9998 - val_loss: 0.0049 - val_accuracy: 0.9791\n",
            "Epoch 88/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 1.5917e-04 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9789\n",
            "Epoch 89/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 1.4585e-04 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 90/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 1.3646e-04 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9790\n",
            "Epoch 91/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 1.3442e-04 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9792\n",
            "Epoch 92/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 1.3577e-04 - accuracy: 0.9999 - val_loss: 0.0050 - val_accuracy: 0.9789\n",
            "Epoch 93/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 3.0750e-04 - accuracy: 0.9982 - val_loss: 0.0063 - val_accuracy: 0.9673\n",
            "Epoch 94/100\n",
            "39/39 [==============================] - 1s 23ms/step - loss: 0.0048 - accuracy: 0.9582 - val_loss: 0.0085 - val_accuracy: 0.9381\n",
            "Epoch 95/100\n",
            "39/39 [==============================] - 1s 21ms/step - loss: 0.0061 - accuracy: 0.9420 - val_loss: 0.0075 - val_accuracy: 0.9454\n",
            "Epoch 96/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0035 - accuracy: 0.9679 - val_loss: 0.0055 - val_accuracy: 0.9671\n",
            "Epoch 97/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 0.0018 - accuracy: 0.9862 - val_loss: 0.0052 - val_accuracy: 0.9720\n",
            "Epoch 98/100\n",
            "39/39 [==============================] - 1s 19ms/step - loss: 0.0011 - accuracy: 0.9939 - val_loss: 0.0051 - val_accuracy: 0.9763\n",
            "Epoch 99/100\n",
            "39/39 [==============================] - 1s 20ms/step - loss: 6.3789e-04 - accuracy: 0.9975 - val_loss: 0.0047 - val_accuracy: 0.9786\n",
            "Epoch 100/100\n",
            "39/39 [==============================] - 1s 35ms/step - loss: 3.3462e-04 - accuracy: 0.9993 - val_loss: 0.0047 - val_accuracy: 0.9797\n"
          ]
        }
      ],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  mix_model.fit([X_train_bert, X_train_lemma_OH, X_train_genRat], y_train_inflection_OH, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_bert, X_dev_lemma_OH, X_dev_genRat], y_dev_inflection_OH))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2s1v375Um5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0248a53e-357d-4332-df06-87e5ee480b8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 2s 9ms/step - loss: 0.0037 - accuracy: 0.9843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.003724090987816453, 0.9843277335166931]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "mix_model = load_model(checkpoint_filepath)\n",
        "mix_model.evaluate([X_test_bert, X_test_lemma_OH, X_test_genRat], y_test_inflection_OH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIWe1psZ3dZ4"
      },
      "outputs": [],
      "source": [
        "print(mix_model.summary())\n",
        "plot_model(mix_model, to_file=mixModel1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgfj5lhjU6z3"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_IHpXM1U6z9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a122a436-7310-469b-a3f5-e0b29c76cc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78/78 [==============================] - 3s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 0.9959595959595959)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "train_pred = mix_model.predict([X_train_bert, X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYvcpoH7U60B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a321a09-3c6b-4bd7-e617-9cd7a776ed54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2475, 18, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niUWd_7tU60E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9dc8160a-958e-4685-bf4f-a890ff911058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index            lemma  b/s          inflection             predict\n",
              "0    863      tilofizyuwn    1       tilofizyuwnAt       tilofizzuwnAt\n",
              "1    939   fiyliyb~iyniy~    1   fiyliyb~iyniy~iyn    fiyliyb~iyiiyiyn\n",
              "2   1045     <isotuwdiyuw    1      <isotuwdiyuwAt       <isotuwdiywAt\n",
              "3   1315  frAnokuwfuwniy~    1  franokuwfuwniy~iyn  fannokuwfuwniy~iyn\n",
              "4   1340     >usoturAliy~    1    >uwsoturAliy~iyn    >uwsourrAliy~iyn"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-20527ba9-49fb-4c38-875d-e9fc4b388b79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>b/s</th>\n",
              "      <th>inflection</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>863</td>\n",
              "      <td>tilofizyuwn</td>\n",
              "      <td>1</td>\n",
              "      <td>tilofizyuwnAt</td>\n",
              "      <td>tilofizzuwnAt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>939</td>\n",
              "      <td>fiyliyb~iyniy~</td>\n",
              "      <td>1</td>\n",
              "      <td>fiyliyb~iyniy~iyn</td>\n",
              "      <td>fiyliyb~iyiiyiyn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1045</td>\n",
              "      <td>&lt;isotuwdiyuw</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;isotuwdiyuwAt</td>\n",
              "      <td>&lt;isotuwdiywAt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1315</td>\n",
              "      <td>frAnokuwfuwniy~</td>\n",
              "      <td>1</td>\n",
              "      <td>franokuwfuwniy~iyn</td>\n",
              "      <td>fannokuwfuwniy~iyn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1340</td>\n",
              "      <td>&gt;usoturAliy~</td>\n",
              "      <td>1</td>\n",
              "      <td>&gt;uwsoturAliy~iyn</td>\n",
              "      <td>&gt;uwsourrAliy~iyn</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20527ba9-49fb-4c38-875d-e9fc4b388b79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-20527ba9-49fb-4c38-875d-e9fc4b388b79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-20527ba9-49fb-4c38-875d-e9fc4b388b79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkGc9jELU60H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5d1b59-12fc-4ea8-9da3-b106662ec892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Broken error %, Sound error %):  (10.0, 90.0)\n"
          ]
        }
      ],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5l_gwk2U60K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c24a514-b63d-4031-ace2-0b9de8a0a708"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 0.9959595959595959)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHCsxDc9U60N"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA-xaxEZU60P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5665b898-f512-45a7-8376-654e0cfa84bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97, 0.9084905660377358)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "dev_pred = mix_model.predict([X_dev_bert, X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "758ZYt8YU60S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "765d10da-61fc-4982-af2a-17696140ef74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index        lemma  b/s      inflection         predict\n",
              "0     59        nAdiy    0       >anodiyap         nawAdiy\n",
              "1    193  >amoriykiy~    1  >amoriykiy~iyn  >amiyrokiy~iyn\n",
              "2    213        na$AT    0       >ano$iTap         na$ATAt\n",
              "3    229    mujawohar    1     mujawoharAt      muwahawrrt\n",
              "4    235      masoEaY    0           masAE         masAEiy"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59935ac8-d5b3-4ff2-8e1d-bfd485aee728\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>b/s</th>\n",
              "      <th>inflection</th>\n",
              "      <th>predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>nAdiy</td>\n",
              "      <td>0</td>\n",
              "      <td>&gt;anodiyap</td>\n",
              "      <td>nawAdiy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>193</td>\n",
              "      <td>&gt;amoriykiy~</td>\n",
              "      <td>1</td>\n",
              "      <td>&gt;amoriykiy~iyn</td>\n",
              "      <td>&gt;amiyrokiy~iyn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>213</td>\n",
              "      <td>na$AT</td>\n",
              "      <td>0</td>\n",
              "      <td>&gt;ano$iTap</td>\n",
              "      <td>na$ATAt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>229</td>\n",
              "      <td>mujawohar</td>\n",
              "      <td>1</td>\n",
              "      <td>mujawoharAt</td>\n",
              "      <td>muwahawrrt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>235</td>\n",
              "      <td>masoEaY</td>\n",
              "      <td>0</td>\n",
              "      <td>masAE</td>\n",
              "      <td>masAEiy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59935ac8-d5b3-4ff2-8e1d-bfd485aee728')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59935ac8-d5b3-4ff2-8e1d-bfd485aee728 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59935ac8-d5b3-4ff2-8e1d-bfd485aee728');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis(devData[0], devData[5], dev_pred_OH, y_dev_inflection_OH, mixModel1_path + \"/dev_errorAnalysis.csv\")\n",
        "dev_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Kn0v0qU60X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390d8bd6-fba2-4014-910b-3aff2a5b107a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Broken error %, Sound error %):  (51.546391752577314, 48.45360824742268)\n"
          ]
        }
      ],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2SBpLd4U60a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3788cb16-a280-4b30-c26b-ee15710b794c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 0.9339622641509434)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0], dev_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E1WV0QxU60c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42712412-a3f3-4605-a195-6ef3e5caf38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples\n",
            "(20.618556701030926, 18.51851851851852)\n"
          ]
        }
      ],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVg1pBydU60g"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqA9bxlFU60i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877355ca-30b8-417d-80ae-4cd4aed82151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 0s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 0.9153696498054474)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "test_pred = mix_model.predict([X_test_bert, X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEn_8FwpU60k"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis(testData[0], testData[5], test_pred_OH, y_test_inflection_OH, mixModel1_path + \"/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UuTiZ52U60m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf711ea-ee13-4bf7-83d2-7521f27d4232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Broken error %, Sound error %):  (45.97701149425287, 54.02298850574713)\n"
          ]
        }
      ],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CitdRhOKU60p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae03bdb4-e2f9-46db-97f8-a4454efaaf7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 0.9319066147859922)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0], test_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpR-Yp-rU60q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c391b7-2111-4278-a040-4be49490d956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples\n",
            "(17.24137931034483, 17.045454545454543)\n"
          ]
        }
      ],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_lrUYcHGakD"
      },
      "source": [
        "## **Mix Model (2 Networks: Classification + Machine Translation)**\n",
        "with 2 outputs(inflection + BS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsMLo7It11GR"
      },
      "outputs": [],
      "source": [
        "mixModel1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Mix Model 2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr7OxTgqGakD"
      },
      "outputs": [],
      "source": [
        "BSClassification_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "BSClassification_model_path = BSClassification_path + '/model 1/weights.hdf5'\n",
        "BSClassification_model_structure_path = BSClassification_path + \"/model 1/structure.h5\"\n",
        "\n",
        "BSC_model = load_model(BSClassification_model_path)\n",
        "BSC_model_struct = load_model(BSClassification_model_structure_path)\n",
        "\n",
        "BSC_model_struct.set_weights(BSC_model.get_weights())\n",
        "BSC_model_struct.trainable = False\n",
        "# print(BSC_model.layers[1].get_weights()[0][0])\n",
        "# print(BSC_model_struct.layers[1].get_weights()[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOmmQjYDGakE"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "cls = BSC_model_struct([input_lemma, input_genRat])\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat, cls])\n",
        "\n",
        "d = Dense(200, activation='relu', name='Dense1')(c)\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "mix_model = Model(inputs=[input_lemma, input_genRat], outputs=[output,cls])\n",
        "\n",
        "checkpoint_filepath = mixModel1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_Inflection_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "mix_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKPaRds2GakE"
      },
      "outputs": [],
      "source": [
        "mix_model.layers[3].layers[1].get_weights()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwpAW-QpGakE"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  mix_model.fit([X_train_lemma_OH, X_train_genRat], [y_train_inflection_OH, y_train_class], batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], [y_dev_inflection_OH,y_dev_class]))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO4Kj_1ZGakE"
      },
      "outputs": [],
      "source": [
        "mix_model = load_model(checkpoint_filepath)\n",
        "mix_model.evaluate([X_test_lemma_OH, X_test_genRat], [y_test_inflection_OH, y_test_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTslpQJQGakE"
      },
      "outputs": [],
      "source": [
        "print(mix_model.summary())\n",
        "plot_model(mix_model, to_file=mixModel1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED9U383gGakE"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f73zoNs4GakF"
      },
      "outputs": [],
      "source": [
        "train_pred,bs_pred = mix_model.predict([X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28tmraM3GakF"
      },
      "outputs": [],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gphy8bpaGakF"
      },
      "outputs": [],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reportErrorAnalysis_inflectionWithBS(trainData[0], trainData[5],bs_pred, train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis_with_bs.csv\")"
      ],
      "metadata": {
        "id": "W4mXyqHAHeT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMPj_yGSGakF"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhF3rJ8ZGakF"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQ5EblGGakF"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljzLZIbvGakF"
      },
      "outputs": [],
      "source": [
        "dev_pred,bs_pred = mix_model.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHXxon8XGakF"
      },
      "outputs": [],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis_inflectionWithBS(devData[0], devData[5],bs_pred, dev_pred_OH, y_dev_inflection_OH, mixModel1_path + \"/dev_errorAnalysis_with_bs.csv\")\n",
        "dev_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bstuple = [dev_errorAnalysis['b/s'], dev_errorAnalysis['b/s predict']]\n",
        "c = 0\n",
        "n = len(bstuple[0])\n",
        "for i in range(n):\n",
        "  if not bstuple[0][i] == bstuple[1][i]: c+=1\n",
        "\n",
        "c/n"
      ],
      "metadata": {
        "id": "CDY9PrfHcuR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lXonFHHGakG"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDrX1fdMGakG"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0], dev_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74SuAUc9GakG"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZl-0dRpGakG"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQAHhxJGakG"
      },
      "outputs": [],
      "source": [
        "test_pred,bs_pred = mix_model.predict([X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4ejjMmuGakG"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis_inflectionWithBS(testData[0], testData[5],bs_pred, test_pred_OH, y_test_inflection_OH, mixModel1_path + \"/test_errorAnalysis_with_bs.csv\")\n",
        "test_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bstuple = [test_errorAnalysis['b/s'], test_errorAnalysis['b/s predict']]\n",
        "c = 0\n",
        "n = len(bstuple[0])\n",
        "for i in range(n):\n",
        "  if not bstuple[0][i] == bstuple[1][i]: c+=1\n",
        "\n",
        "c/n"
      ],
      "metadata": {
        "id": "U80Tr2o3hLFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1aOEbV_GakG"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upu85AtSGakH"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0], test_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcIeOUM9GakH"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rgbi7F8b_x30",
        "XOX50iU1Kha1",
        "9ZQvZUkdGb9Z",
        "ubE6nCh4ClaD",
        "dU09qVXA9kp0",
        "4MFDQIHuClaE",
        "u_hpLQfwE5B2",
        "JRilqxawClaF",
        "62hKeeV_2G77",
        "g4MC1JT3TSec",
        "5aRDIUaOvvJv",
        "wYae4z1hhH4t",
        "DBYWYsIYgR4S",
        "K87j_k_oEVh3",
        "XAoL0KSoEVh4",
        "ybXFriUqEVh5",
        "i7R3KZnxEVh5",
        "fdCz16FjpUjU",
        "jgfj5lhjU6z3",
        "WHCsxDc9U60N",
        "gVg1pBydU60g",
        "s_lrUYcHGakD",
        "ED9U383gGakE",
        "RHQ5EblGGakF",
        "sZl-0dRpGakG"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}