{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirezzati/Arabic-Broken-Plural-RNN/blob/main/Arabic_broken_plurals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgbi7F8b_x30"
      },
      "source": [
        "# **Libraries & Constants**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D2-wlVMZYEkZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Input, Softmax, BatchNormalization, Dropout, Conv2D, MaxPool2D, Embedding, Reshape, Flatten, LSTM, GRU, SimpleRNN, Concatenate, concatenate, RepeatVector, TimeDistributed, Bidirectional\n",
        "# from keras.layers.merge import concatenate\n",
        "from keras.losses import CategoricalCrossentropy\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adamax, Nadam, SGD\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers.schedules import InverseTimeDecay, ExponentialDecay\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn import metrics\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import string\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srVvFhQrdymB",
        "outputId": "3bdc7ca1-f203-451a-d215-9bf669cb6316"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "dataPath=\"/content/drive/MyDrive/AI Projects/Arabic Broken Plural/data\"\n",
        "# dataPath = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGFwazuJClaC"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding Schemes**"
      ],
      "metadata": {
        "id": "XOX50iU1Kha1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_schemes = pd.read_excel(dataPath+\"/Encoding Schemes.xlsx\")"
      ],
      "metadata": {
        "id": "ZDoScnOfGIiX"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_bw = encoding_schemes[['Arabic', 'BW']]\n",
        "arabic_bw.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twMF1Mw5JXe_",
        "outputId": "d32d0281-24a0-4f5e-fb5e-911d1593933a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bw_to_arabic, arabic_to_bw = {}, {}\n",
        "for i in range(arabic_bw.shape[0]):\n",
        "  bw_to_arabic[arabic_bw['BW'][i]] = arabic_bw['Arabic'][i]\n",
        "  arabic_to_bw[arabic_bw['Arabic'][i]] = arabic_bw['BW'][i]"
      ],
      "metadata": {
        "id": "pvjYOWufI8-X"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getArabicForm(bwForm):\n",
        "  arabicForm = []\n",
        "  for x in bwForm:\n",
        "    arabicForm.append(\"\".join([bw_to_arabic[char] for char in x]))\n",
        "  return arabicForm"
      ],
      "metadata": {
        "id": "NwhxwGI3LsSJ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubE6nCh4ClaD"
      },
      "source": [
        "## **Get dataset files and Organizing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "_uBC6rVkClaD",
        "outputId": "747b02d5-78de-4415-a7be-239c7b5ce108"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   lemma inflection NUM GEN RAT  lex_freq B/S SING_PATT    PL_PATT   ROOT  \\\n",
              "0  Eamal    >aEomAl  PL   m   i        49   B     1a2a3    >a1o2A3  E.m.l   \n",
              "1  hadaf    >ahodAf  PL   m   i        42   B     1a2a3    >a1o2A3  h.d.f   \n",
              "2  EuDow    >aEoDA'  PL   m   r        46   B     1u2ow    >a1o2A'  E.D.#   \n",
              "3  jihAz  >ajohizap  PL   m   i        41   B     1i2A3  >a1o2i3ap  j.h.z   \n",
              "4  Hukom    >aHokAm  PL   m   i        35   B     1u2o3    >a1o2A3  H.k.m   \n",
              "\n",
              "   FREQ  \n",
              "0    49  \n",
              "1    42  \n",
              "2    39  \n",
              "3    35  \n",
              "4    35  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2efd407c-3056-4d18-8e74-64262d10c16a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>NUM</th>\n",
              "      <th>GEN</th>\n",
              "      <th>RAT</th>\n",
              "      <th>lex_freq</th>\n",
              "      <th>B/S</th>\n",
              "      <th>SING_PATT</th>\n",
              "      <th>PL_PATT</th>\n",
              "      <th>ROOT</th>\n",
              "      <th>FREQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eamal</td>\n",
              "      <td>&gt;aEomAl</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>49</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>E.m.l</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hadaf</td>\n",
              "      <td>&gt;ahodAf</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>42</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>h.d.f</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EuDow</td>\n",
              "      <td>&gt;aEoDA'</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>46</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2ow</td>\n",
              "      <td>&gt;a1o2A'</td>\n",
              "      <td>E.D.#</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jihAz</td>\n",
              "      <td>&gt;ajohizap</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>41</td>\n",
              "      <td>B</td>\n",
              "      <td>1i2A3</td>\n",
              "      <td>&gt;a1o2i3ap</td>\n",
              "      <td>j.h.z</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hukom</td>\n",
              "      <td>&gt;aHokAm</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>35</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2o3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>H.k.m</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2efd407c-3056-4d18-8e74-64262d10c16a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2efd407c-3056-4d18-8e74-64262d10c16a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2efd407c-3056-4d18-8e74-64262d10c16a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "train_csv = pd.read_csv(dataPath+\"/train_pairs_all.csv\")\n",
        "dev_csv = pd.read_csv(dataPath+\"/dev_pairs_all.csv\")\n",
        "test_csv = pd.read_csv(dataPath+\"/test_pairs_all.csv\")\n",
        "\n",
        "train_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "WhS3Mtp8LXLi",
        "outputId": "2928c7c0-3ba5-4031-8ca9-c1b8cd426d75"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           lemma  inflection NUM GEN RAT  lex_freq B/S   SING_PATT  \\\n",
              "0          Eamal     >aEomAl  PL   m   i        49   B       1a2a3   \n",
              "1          hadaf     >ahodAf  PL   m   i        42   B       1a2a3   \n",
              "2          EuDow     >aEoDA'  PL   m   r        46   B       1u2ow   \n",
              "3          jihAz   >ajohizap  PL   m   i        41   B       1i2A3   \n",
              "4          Hukom     >aHokAm  PL   m   i        35   B       1u2o3   \n",
              "...          ...         ...  ..  ..  ..       ...  ..         ...   \n",
              "2857     murAsil  murAsiliyn  PL   m   r         7   S     mu1A2i3   \n",
              "2858  Sayodaliy~   SayAdilap  PL   m   r         1   B  1ayo3a4iy~   \n",
              "2859     murAjiE  murAjiEiyn  PL   m   r         1   S     mu1A2i3   \n",
              "2860     murAhiq  murAhiqiyn  PL   m   r         1   S     mu1A2i3   \n",
              "2861   mibo$arap     mabA$ir  PL   f   i         1   B   mi1o2a3ap   \n",
              "\n",
              "         PL_PATT     ROOT  FREQ  \n",
              "0        >a1o2A3    E.m.l    49  \n",
              "1        >a1o2A3    h.d.f    42  \n",
              "2        >a1o2A'    E.D.#    39  \n",
              "3      >a1o2i3ap    j.h.z    35  \n",
              "4        >a1o2A3    H.k.m    35  \n",
              "...          ...      ...   ...  \n",
              "2857   mu1A2i3iy    r.s.l     1  \n",
              "2858   1ayA3i4ap  S.#.d.l     1  \n",
              "2859  mu1A2i3iyn    r.j.E     1  \n",
              "2860  mu1A2i3iyn    r.h.q     1  \n",
              "2861     ma1A2i3    b.$.r     1  \n",
              "\n",
              "[2862 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-774c34ce-7da9-4ac0-ae58-84eeb5a74377\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>NUM</th>\n",
              "      <th>GEN</th>\n",
              "      <th>RAT</th>\n",
              "      <th>lex_freq</th>\n",
              "      <th>B/S</th>\n",
              "      <th>SING_PATT</th>\n",
              "      <th>PL_PATT</th>\n",
              "      <th>ROOT</th>\n",
              "      <th>FREQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eamal</td>\n",
              "      <td>&gt;aEomAl</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>49</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>E.m.l</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hadaf</td>\n",
              "      <td>&gt;ahodAf</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>42</td>\n",
              "      <td>B</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>h.d.f</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EuDow</td>\n",
              "      <td>&gt;aEoDA'</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>46</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2ow</td>\n",
              "      <td>&gt;a1o2A'</td>\n",
              "      <td>E.D.#</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jihAz</td>\n",
              "      <td>&gt;ajohizap</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>41</td>\n",
              "      <td>B</td>\n",
              "      <td>1i2A3</td>\n",
              "      <td>&gt;a1o2i3ap</td>\n",
              "      <td>j.h.z</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hukom</td>\n",
              "      <td>&gt;aHokAm</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>i</td>\n",
              "      <td>35</td>\n",
              "      <td>B</td>\n",
              "      <td>1u2o3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>H.k.m</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2857</th>\n",
              "      <td>murAsil</td>\n",
              "      <td>murAsiliyn</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>7</td>\n",
              "      <td>S</td>\n",
              "      <td>mu1A2i3</td>\n",
              "      <td>mu1A2i3iy</td>\n",
              "      <td>r.s.l</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>Sayodaliy~</td>\n",
              "      <td>SayAdilap</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>1ayo3a4iy~</td>\n",
              "      <td>1ayA3i4ap</td>\n",
              "      <td>S.#.d.l</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2859</th>\n",
              "      <td>murAjiE</td>\n",
              "      <td>murAjiEiyn</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>1</td>\n",
              "      <td>S</td>\n",
              "      <td>mu1A2i3</td>\n",
              "      <td>mu1A2i3iyn</td>\n",
              "      <td>r.j.E</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2860</th>\n",
              "      <td>murAhiq</td>\n",
              "      <td>murAhiqiyn</td>\n",
              "      <td>PL</td>\n",
              "      <td>m</td>\n",
              "      <td>r</td>\n",
              "      <td>1</td>\n",
              "      <td>S</td>\n",
              "      <td>mu1A2i3</td>\n",
              "      <td>mu1A2i3iyn</td>\n",
              "      <td>r.h.q</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2861</th>\n",
              "      <td>mibo$arap</td>\n",
              "      <td>mabA$ir</td>\n",
              "      <td>PL</td>\n",
              "      <td>f</td>\n",
              "      <td>i</td>\n",
              "      <td>1</td>\n",
              "      <td>B</td>\n",
              "      <td>mi1o2a3ap</td>\n",
              "      <td>ma1A2i3</td>\n",
              "      <td>b.$.r</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2862 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-774c34ce-7da9-4ac0-ae58-84eeb5a74377')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-774c34ce-7da9-4ac0-ae58-84eeb5a74377 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-774c34ce-7da9-4ac0-ae58-84eeb5a74377');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "SdFejowuClaD"
      },
      "outputs": [],
      "source": [
        "train_csv_filtered = train_csv[train_csv['ROOT'] != 'NTWS']\n",
        "dev_csv_filtered = dev_csv[dev_csv['ROOT'] != 'NTWS']\n",
        "test_csv_filtered = test_csv[test_csv['ROOT'] != 'NTWS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMrYNnyDClaD",
        "outputId": "7e0e51f2-990e-4988-ed8a-8f8993852edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "114\n",
            "38\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "print(train_csv.shape[0] - train_csv_filtered.shape[0])\n",
        "print(dev_csv.shape[0] - dev_csv_filtered.shape[0])\n",
        "print(test_csv.shape[0] - test_csv_filtered.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "yD10TibJClaD",
        "outputId": "5f6dc925-53b5-4486-94d6-2a88840e295d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        lemma  inflection NUM  GEN  RAT  lex_freq  B/S   SING_PATT  \\\n",
              "0       Eamal     >aEomAl  PL    1    0        23    0       1a2a3   \n",
              "1       hadaf     >ahodAf  PL    1    0        16    0       1a2a3   \n",
              "2     EalAqap     EalAqAt  PL    0    0        15    1     1a2A3ap   \n",
              "3  mu&as~asap  mu&as~asAt  PL    0    0        14    1  mu&a2~a3ap   \n",
              "4       EuDow     >aEoDA'  PL    1    1        15    0       1u2ow   \n",
              "\n",
              "      PL_PATT   ROOT  FREQ  \n",
              "0     >a1o2A3  E.m.l    23  \n",
              "1     >a1o2A3  h.d.f    16  \n",
              "2     1a2A3At  E.l.q    15  \n",
              "3  mu&a2~a3At  #.s.s    14  \n",
              "4     >a1o2A'  E.D.#    13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f40a48a-90c2-46d1-91f3-805d2d8db906\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>NUM</th>\n",
              "      <th>GEN</th>\n",
              "      <th>RAT</th>\n",
              "      <th>lex_freq</th>\n",
              "      <th>B/S</th>\n",
              "      <th>SING_PATT</th>\n",
              "      <th>PL_PATT</th>\n",
              "      <th>ROOT</th>\n",
              "      <th>FREQ</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eamal</td>\n",
              "      <td>&gt;aEomAl</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>E.m.l</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hadaf</td>\n",
              "      <td>&gt;ahodAf</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>1a2a3</td>\n",
              "      <td>&gt;a1o2A3</td>\n",
              "      <td>h.d.f</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EalAqap</td>\n",
              "      <td>EalAqAt</td>\n",
              "      <td>PL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1a2A3ap</td>\n",
              "      <td>1a2A3At</td>\n",
              "      <td>E.l.q</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mu&amp;as~asap</td>\n",
              "      <td>mu&amp;as~asAt</td>\n",
              "      <td>PL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>mu&amp;a2~a3ap</td>\n",
              "      <td>mu&amp;a2~a3At</td>\n",
              "      <td>#.s.s</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EuDow</td>\n",
              "      <td>&gt;aEoDA'</td>\n",
              "      <td>PL</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>1u2ow</td>\n",
              "      <td>&gt;a1o2A'</td>\n",
              "      <td>E.D.#</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f40a48a-90c2-46d1-91f3-805d2d8db906')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f40a48a-90c2-46d1-91f3-805d2d8db906 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f40a48a-90c2-46d1-91f3-805d2d8db906');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "\n",
        "# Label encoder for encoding gender and rational features\n",
        "# 'B' class: 0      'S' class: 1\n",
        "categorical_attr = ['GEN', 'RAT', 'B/S']\n",
        "\n",
        "le = LabelEncoder()\n",
        "#train_csv_filtered[categorical_attr] = train_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "train_csv[categorical_attr] = train_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "le = LabelEncoder()\n",
        "#dev_csv_filtered[categorical_attr] = dev_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "dev_csv[categorical_attr] = dev_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "le = LabelEncoder()\n",
        "#test_csv_filtered[categorical_attr] = test_csv_filtered[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "test_csv[categorical_attr] = test_csv[categorical_attr].apply(le.fit_transform, axis=0)\n",
        "\n",
        "#test_csv_filtered.head()\n",
        "test_csv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "vx1uEiSrClaD"
      },
      "outputs": [],
      "source": [
        "def getListOfData(dataFrame):\n",
        "  '''\n",
        "  Output type->List : 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:freq | 9:nmberOfRoot | 10:Arabic Form |\n",
        "  '''\n",
        "  data = [] # 0:lemma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "  data.append(dataFrame['lemma'].tolist())\n",
        "  data.append(dataFrame['SING_PATT'].tolist())\n",
        "\n",
        "  root = dataFrame['ROOT'].tolist()\n",
        "  # delete dot sign(.) in root feature\n",
        "  for i in range(len(root)): \n",
        "    root[i] = root[i].replace(\".\",\"\")\n",
        "    root[i] = root[i].replace(\"#\",\"\")\n",
        "  data.append(root)\n",
        "\n",
        "  data.append(dataFrame['inflection'].tolist())\n",
        "  data.append(dataFrame['PL_PATT'].tolist())\n",
        "  data.append(dataFrame['B/S'].tolist())\n",
        "  data.append(dataFrame['GEN'].tolist())\n",
        "  data.append(dataFrame['RAT'].tolist())\n",
        "  data.append(dataFrame['FREQ'].tolist())\n",
        "\n",
        "  numOfRoot = [len(x) for x in root]\n",
        "  data.append(numOfRoot)\n",
        "\n",
        "  data.append(getArabicForm(dataFrame['lemma'].tolist()))\n",
        "\n",
        "  return data\n",
        "\n",
        "trainData = getListOfData(train_csv)\n",
        "devData = getListOfData(dev_csv)\n",
        "testData = getListOfData(test_csv)\n",
        "is_dataOrginal=True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainData[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrQhKscIPF_l",
        "outputId": "a8cb49fa-7fb1-4364-ce3b-7414c1d62e4f"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1a2a3',\n",
              " '1a2a3',\n",
              " '1u2ow',\n",
              " '1i2A3',\n",
              " '1u2o3',\n",
              " '1u2o3u4',\n",
              " '1a2~',\n",
              " 'ma1o2a3ap',\n",
              " '1a2a3iy~ap',\n",
              " '1a2o3',\n",
              " '1i2o3',\n",
              " '<i1o2A3',\n",
              " \"<i1o2A'\",\n",
              " 'mawo2i3',\n",
              " '1a2o3',\n",
              " '1uw~ap',\n",
              " '1a2A3ap',\n",
              " '1a2a3',\n",
              " '1awo3',\n",
              " '1a2A3',\n",
              " '1i2A3',\n",
              " '>a2a3',\n",
              " '1i2o3',\n",
              " '1a2a3',\n",
              " '1a2a3',\n",
              " '1a2iy3ap',\n",
              " '1a2o3',\n",
              " '{it~i2A3',\n",
              " 'wa2o3',\n",
              " 'mu&a2~a3ap',\n",
              " '1A2i3',\n",
              " '1i2o3',\n",
              " '1i2A3',\n",
              " 'ta1o2iy3',\n",
              " '>a2o3',\n",
              " 'ta1o2iy3',\n",
              " '1awo3ap',\n",
              " 'wa2a3',\n",
              " '1A3',\n",
              " '1a2onA3a4',\n",
              " 'yawo3',\n",
              " 'ma1o2uw3',\n",
              " '1a2~',\n",
              " '1a2a3',\n",
              " '1A2~ap',\n",
              " '1A2i3',\n",
              " '{i1oti2A3',\n",
              " '1a2o3',\n",
              " '1aw~',\n",
              " 'ma1o2a3',\n",
              " '1A}i3ap',\n",
              " '1u2uw3',\n",
              " 'mi1o2a3ap',\n",
              " '>a2',\n",
              " '>u1o2uw3',\n",
              " '1iyA3ap',\n",
              " '1a2o3',\n",
              " '1a2iy3ap',\n",
              " '1a2i3ap',\n",
              " '1a2o3ap',\n",
              " \"1A'\",\n",
              " '1A}i3',\n",
              " '1A2i3ap',\n",
              " '1A3ap',\n",
              " '>a2o3',\n",
              " '1uw3ap',\n",
              " 'wa2a3',\n",
              " '1i2o3ap',\n",
              " '1iy3ap',\n",
              " '{i1o2',\n",
              " 'mu1A2a3ap',\n",
              " '1a2o3',\n",
              " '|3iy~ap',\n",
              " 'mu1o2a>ap',\n",
              " '1ay~A3ap',\n",
              " 'ma1o2a3',\n",
              " 'wa2iy3',\n",
              " '1a2iy~ap',\n",
              " '1a2A3ap',\n",
              " '1uw3',\n",
              " '1a2A3',\n",
              " 'NTWS',\n",
              " 'ma1o2uw3',\n",
              " 'ta1o2iy3',\n",
              " '1a2u3',\n",
              " '1A2i3',\n",
              " 'mu1o2i3ap',\n",
              " '1u2o3',\n",
              " '1A}i3ap',\n",
              " '1u2o3ap',\n",
              " '1i2A3',\n",
              " '1A2uw3',\n",
              " 'ta1a2~u3',\n",
              " '>a2a3',\n",
              " '1A2i3',\n",
              " '1i2o3iy~',\n",
              " '1i2o3',\n",
              " '1ayA3',\n",
              " '>a1o2A3',\n",
              " 'wa2a3',\n",
              " 'wi2Ayap',\n",
              " 'NTWS',\n",
              " '1a2a3',\n",
              " '1A2i3',\n",
              " '1a2i3ap',\n",
              " '{isoti1o2A3',\n",
              " 'mu1A2A',\n",
              " '1i2A3ap',\n",
              " '1A2uw3',\n",
              " '1a2o3',\n",
              " '{it~i2A3',\n",
              " 'ma1o&uw3',\n",
              " '1a2a3iy~',\n",
              " '1a2a>',\n",
              " '{i1oti2A3',\n",
              " \"1i2A'\",\n",
              " 'wa2o3',\n",
              " 'mu1Awa3ap',\n",
              " '1a2~',\n",
              " '1a>o3',\n",
              " '{i1o2',\n",
              " '>u2o3A4',\n",
              " '>a2o3',\n",
              " 'ma1o2a3',\n",
              " '1u2o3ap',\n",
              " 'wa2iy3ap',\n",
              " 'mu1i2~ap',\n",
              " '1u2uw3ap',\n",
              " '<i1o2A3iy~',\n",
              " 'NTWS',\n",
              " 'mu1a2~a3ap',\n",
              " '1a2o3',\n",
              " '1a2o3',\n",
              " '1A2i3',\n",
              " 'ta1A2u3ap',\n",
              " '1a2iy3',\n",
              " 'ma1A3ap',\n",
              " 'ta1aw~u3',\n",
              " '1a2iy3',\n",
              " '1a2a3',\n",
              " '1a}iy3',\n",
              " 'mawo2uw3',\n",
              " '1u2o3ap',\n",
              " '1a2o3iy~ap',\n",
              " '1A2i3',\n",
              " '1a2o3',\n",
              " '2i3ap',\n",
              " '1i2A3',\n",
              " '1u2o3iy~',\n",
              " '1awo3',\n",
              " '1i2A3',\n",
              " 'ta1o2iy3',\n",
              " '1ayo}ap',\n",
              " '1A}i3',\n",
              " 'ta1o2i3ap',\n",
              " 'tawo2iyap',\n",
              " '1a2o3',\n",
              " 'ma1o2a>',\n",
              " \"{i1oti2A'\",\n",
              " 'ma1a2~ap',\n",
              " '1a2',\n",
              " 'ma1A2i3',\n",
              " '1a2owap',\n",
              " '1a2iy3ap',\n",
              " '1a2owap',\n",
              " 'ma1o2i3',\n",
              " 'mu1Awa3ap',\n",
              " 'mu1a2~',\n",
              " '1a2a3',\n",
              " 'ma1o2a3ap',\n",
              " 'ya2uw3iy~',\n",
              " '1a2iy3',\n",
              " '1i2A3',\n",
              " '1a2iy3',\n",
              " 'wa2o3ap',\n",
              " \"1i2o'\",\n",
              " '1a2a3ap',\n",
              " '1a2o3',\n",
              " '<i1o2A3',\n",
              " 'ta1a2~u3',\n",
              " '1a2o3',\n",
              " '1i2A3',\n",
              " 'mi1oyA3',\n",
              " 'mu1o2i3ap',\n",
              " '>u2~ap',\n",
              " '1a2A3',\n",
              " '1a2~',\n",
              " '1A3',\n",
              " '1a2iy3',\n",
              " '1a>oy',\n",
              " '1a2iy3',\n",
              " '1A2i3',\n",
              " '1a2iy3iy~',\n",
              " 'mu1o2i3',\n",
              " '1a2o3',\n",
              " '1a2o3a4',\n",
              " 'ma1o2a3',\n",
              " 'muwA2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1a2A3ap',\n",
              " '1A3ap',\n",
              " '1u2uw3ap',\n",
              " '1i2o3ap',\n",
              " 'ta1o2iy3',\n",
              " 'mu1A2a3ap',\n",
              " '1a2iy3ap',\n",
              " '1a>o3',\n",
              " 'ma1o&uw3iy~ap',\n",
              " 'ya2',\n",
              " '1a2o3',\n",
              " 'ta1o2iyap',\n",
              " '>a2o3ap',\n",
              " '1A2i3',\n",
              " '>a2A3',\n",
              " '1u2~ap',\n",
              " '{it~i2A3',\n",
              " '1i2o3ap',\n",
              " '1i2o3',\n",
              " '1a2iy3',\n",
              " \"1i2A'\",\n",
              " '1a2a>',\n",
              " '1a2o3ap',\n",
              " '1a2o3',\n",
              " '1awo3',\n",
              " '1A2i3',\n",
              " '1a2o3ap',\n",
              " 'mu1ota2a3',\n",
              " '1a2a3ap',\n",
              " '1a2o3',\n",
              " \"1awA'\",\n",
              " 'mu1A2a3ap',\n",
              " '1A2i3',\n",
              " 'mu1o2a3',\n",
              " 'muwA2a3ap',\n",
              " '1A}i3',\n",
              " '1umA2a3ap',\n",
              " '1a2o3',\n",
              " '1a2a3',\n",
              " 'musotawo2a3ap',\n",
              " '1utama2~i3',\n",
              " '1a2iy3',\n",
              " '<i1o2A3iy~',\n",
              " '{i1oti2A3',\n",
              " '1A2i3iy~ap',\n",
              " 'ma1o2a3',\n",
              " '1a2iy3ap',\n",
              " '<iy2A3',\n",
              " 'ta1A2u3',\n",
              " '>awo3awiy~ap',\n",
              " '1iyA3ap',\n",
              " '<i1o2A3',\n",
              " '1A2i3',\n",
              " 'mi1a2~ap',\n",
              " '1A2iy',\n",
              " '>a2o3iy4iy~',\n",
              " '1u2o3ap',\n",
              " '1a2a3',\n",
              " '1a2a3ap',\n",
              " '1A2i}',\n",
              " 'mu1A2iy',\n",
              " '1a2iy3ap',\n",
              " '1a2~',\n",
              " 'mawo2i3',\n",
              " '1A3',\n",
              " 'ma1A3',\n",
              " 'wa2iy3ap',\n",
              " 'ta1o2iy3',\n",
              " 'ma1o2a3ap',\n",
              " '1a2o3ap',\n",
              " '1i2o3',\n",
              " 'ma1o2uw3ap',\n",
              " '1a2ap',\n",
              " 'NTWS',\n",
              " 'ma1o2a3',\n",
              " '1ayo3',\n",
              " 'musota1o2i3',\n",
              " '1u2o3',\n",
              " '1a2a3ap',\n",
              " 'muwA2a3ap',\n",
              " 'mu1ay~a3',\n",
              " 'mu1o2aY',\n",
              " '1a2iy3ap',\n",
              " '1A3ap',\n",
              " '1ayo3',\n",
              " '1a2~iy~ap',\n",
              " '1i2o3',\n",
              " 'mawo2i3',\n",
              " 'mawo2i3',\n",
              " '1a2o3',\n",
              " 'mawo2uw3',\n",
              " '1ayo3',\n",
              " '1a2~A3ap',\n",
              " '1uw~ap',\n",
              " '1iy3',\n",
              " '1A2i3ap',\n",
              " '1a2a3',\n",
              " 'NTWS',\n",
              " '1a2~',\n",
              " 'ta1o2iy3',\n",
              " \"<i1o2A'\",\n",
              " 'wa2o3',\n",
              " '>u1o2uw3',\n",
              " '>a2o3',\n",
              " '{i1oti2A3',\n",
              " 'ta1o2iy3',\n",
              " '1a2iy3',\n",
              " 'ta1o2iy3',\n",
              " 'ta1owiy3',\n",
              " '1u2o3ap',\n",
              " '1i2o3iy4',\n",
              " '1ay~A3',\n",
              " '{i1oti2A3',\n",
              " 'ma1o2a3ap',\n",
              " '1A}i3ap',\n",
              " '1A3',\n",
              " '1a2o3',\n",
              " '1i2o3ap',\n",
              " '1a2o3a4iy~',\n",
              " 'ma1A3',\n",
              " '1iyA3',\n",
              " '1a2o3iy~ap',\n",
              " 'ma1o2a3ap',\n",
              " 'ma1A3',\n",
              " '{i1oti2A3',\n",
              " '>u2u3',\n",
              " '{i1oti2A3',\n",
              " '>u2~',\n",
              " '1u2o3',\n",
              " '1a2iy~ap',\n",
              " 'ta1a2~u3',\n",
              " '1u2uw3ap',\n",
              " 'tawa2~u3',\n",
              " '1ay~',\n",
              " '1a2A3iy~',\n",
              " '1a2A',\n",
              " 'mu1a2~a3',\n",
              " '1a2owap',\n",
              " 'mu1a2~a3',\n",
              " 'mu1ota2a3',\n",
              " 'mu1Awa3ap',\n",
              " 'mu&a2~i3',\n",
              " '1a2a3',\n",
              " '1A}i3ap',\n",
              " 'wa2o3',\n",
              " '<i2o3',\n",
              " 'wa2iy3ap',\n",
              " 'wi2A3ap',\n",
              " 'ma1o2awiy~',\n",
              " '2u&otama3',\n",
              " '1i2A3ap',\n",
              " 'ma1o2aY',\n",
              " 'ma1o2a3',\n",
              " \"1u2o'\",\n",
              " '1u2o3u4',\n",
              " '1A}i3',\n",
              " '{isoti1o2A3',\n",
              " '{i1oti2A3',\n",
              " '{isoti1o2A3',\n",
              " '1A2i3',\n",
              " '|3ap',\n",
              " '1i2o3aY',\n",
              " '1i2o3ap',\n",
              " '1u2o3ap',\n",
              " '<i2A3ap',\n",
              " '>a2o3a4iy~',\n",
              " '1A2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1u2uw3',\n",
              " '1a2a3ap',\n",
              " '1A2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1a2A',\n",
              " '<i1o2a3',\n",
              " 'mu1A2i3',\n",
              " '<i1A3ap',\n",
              " 'mu1a2~a3',\n",
              " '1i2A3ap',\n",
              " '1a2iy3',\n",
              " '1a2a3iy~ap',\n",
              " '1a2o3ap',\n",
              " 'ta1A2iy',\n",
              " '1A2i3',\n",
              " '1a2owap',\n",
              " '>a2o3',\n",
              " 'mu1Awa3ap',\n",
              " 'mu1a2o3i4',\n",
              " '1ay~i3ap',\n",
              " '1A2i3',\n",
              " '1A3',\n",
              " 'muwA2i3',\n",
              " 'muwa2~a3',\n",
              " '1i2o3ap',\n",
              " 'mu1a2~a3',\n",
              " 'muta1A2i3',\n",
              " '1i2A3',\n",
              " '1A3',\n",
              " '1a2iy3ap',\n",
              " 'mu1otawaY',\n",
              " '1A2i3ap',\n",
              " '1a2o3iy~ap',\n",
              " '1a2~',\n",
              " '1u&A3',\n",
              " '1a2iy3ap',\n",
              " '1A}i3ap',\n",
              " '1i2A3ap',\n",
              " '1i2~ap',\n",
              " 'wA2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1a2a3',\n",
              " '1i2A3ap',\n",
              " '1umota2a3',\n",
              " '1uma2~i3',\n",
              " '1uma2~i3',\n",
              " '<i1o2A3',\n",
              " '1A3',\n",
              " '1u2owA3',\n",
              " '1ayo3',\n",
              " '1iyA3ap',\n",
              " 'ta1aw~u3',\n",
              " '1i2o3',\n",
              " '1iy3',\n",
              " '1ayo3',\n",
              " 'ma1o2i3',\n",
              " 'ma1o2a3',\n",
              " '1a2a3',\n",
              " '1A2i3ap',\n",
              " 'ma1o2uw3',\n",
              " '>u1o2u3ap',\n",
              " '1a2A3',\n",
              " '1a2a3iy~',\n",
              " 'ma1o2a3',\n",
              " 'ma1iy3',\n",
              " 'ma1o2a3',\n",
              " '1i}ap',\n",
              " '{i1oti2A3',\n",
              " 'ma>o2A',\n",
              " '1a2iy3ap',\n",
              " '{i1o2',\n",
              " 'ma1o2i3',\n",
              " 'ta1o2iy3',\n",
              " '1a2uw~',\n",
              " 'ma1o2a3ap',\n",
              " '1uw3',\n",
              " 'ta1a2~iy',\n",
              " '1i2o3ap',\n",
              " '1Ayap',\n",
              " 'ta1o2iy3',\n",
              " 'ta1owiyap',\n",
              " '1A}i3',\n",
              " 'ma1o>a3ap',\n",
              " '1a2o3',\n",
              " 'ma1iy3ap',\n",
              " '1a2iy3ap',\n",
              " '1awo3ap',\n",
              " '1A2i3',\n",
              " '1A2i3',\n",
              " '{i1otiyA3iy~',\n",
              " '1a2iy3',\n",
              " '1a2o3',\n",
              " '1a2iy3',\n",
              " 'ma1o2a3',\n",
              " 'mu1A2i3',\n",
              " '{i1oti2A3',\n",
              " '1a2o3',\n",
              " '1i2A3',\n",
              " 'mu1a2~a3',\n",
              " '1a2iy3',\n",
              " '1a2iy3ap',\n",
              " '1a2o3ap',\n",
              " '1u2o3uw4',\n",
              " 'musotawo2i3',\n",
              " '{i1oti2A3',\n",
              " '1iy3',\n",
              " 'tawo2iy3',\n",
              " \"{i1oti2A'\",\n",
              " '1A',\n",
              " 'mu1a2~a3',\n",
              " 'mut~a2a3',\n",
              " '1u2~iy~ap',\n",
              " 'muta1a2~i3',\n",
              " '1A2~',\n",
              " 'mawo2i3',\n",
              " '1a2o3ap',\n",
              " 'muta1a2~a3',\n",
              " '1A2i3ap',\n",
              " '1i2o3ap',\n",
              " '1A3',\n",
              " 'NTWS',\n",
              " '1u2o3uw4',\n",
              " 'ma1o2a3',\n",
              " '1a2o3',\n",
              " 'mu1a2~i3',\n",
              " '{ino1i2A3',\n",
              " '<i1A3ap',\n",
              " '<i2A3',\n",
              " '1a2iy3',\n",
              " '{i1oTi2A3',\n",
              " 'mu1ota2a3',\n",
              " '1a2a3',\n",
              " '1A2i3',\n",
              " '1a2o3',\n",
              " 'mu1aw~i3',\n",
              " 'NTWS',\n",
              " 'mu1A2a3ap',\n",
              " 'mu1A2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1a2~',\n",
              " '1awo3',\n",
              " '1a2~A3iy~ap',\n",
              " '1u2~iy~ap',\n",
              " '1a2~A3',\n",
              " '1i2A3ap',\n",
              " '<i1A3ap',\n",
              " '1a2iy3',\n",
              " '1A3ap',\n",
              " 'mu1aw~i3',\n",
              " '1a2a3',\n",
              " 'ma1o2i3',\n",
              " 'wa2iy3ap',\n",
              " '1i2o3',\n",
              " '1A}i3ap',\n",
              " '<i1A3ap',\n",
              " '1i2~',\n",
              " 'mi1o2a3',\n",
              " '1a2a3',\n",
              " '1i2o3',\n",
              " 'ta1o2iy3',\n",
              " 'ta1o2iy3',\n",
              " 'ta1a2~iy',\n",
              " 'ta1o2iyap',\n",
              " 'ta1a2~u3',\n",
              " '1u2o3u4ap',\n",
              " '>a2',\n",
              " '>a2a3',\n",
              " 'NTWS',\n",
              " '>a2a3',\n",
              " '1A}i3ap',\n",
              " '1a2iy3',\n",
              " '1A2iy',\n",
              " '>a2o3iy4iy~',\n",
              " '1i2A3ap',\n",
              " 'ta1o2iy3',\n",
              " '1i2o3',\n",
              " '1i2A3ap',\n",
              " '1a2o3',\n",
              " '>a2A',\n",
              " '1a2a3',\n",
              " '1a2iy3',\n",
              " '>a1o2a3',\n",
              " 'ta1o2iy3',\n",
              " 'ta>o2iy3',\n",
              " '1iy~ap',\n",
              " 'ta1o2iy3',\n",
              " '1A2i3',\n",
              " 'ta1A&u3',\n",
              " '1a2iy3',\n",
              " '1a2iy3',\n",
              " '>u1o2iyap',\n",
              " '>a1o2a3iy~',\n",
              " '1A2i3',\n",
              " '1a2iy3',\n",
              " 'ta1o2iy3',\n",
              " 'muwa2~a3',\n",
              " '1ayo3',\n",
              " '1iyA3iy~',\n",
              " 'ta1oyiy3',\n",
              " '1u2o3',\n",
              " '<i1A3ap',\n",
              " 'ta1a2~u3',\n",
              " 'mu1a2~i3',\n",
              " '1u2ap',\n",
              " 'NTWS',\n",
              " '1A2i3ap',\n",
              " '1i2A3ap',\n",
              " '1u2o3',\n",
              " 'mu1aw~i3',\n",
              " '1u2o3',\n",
              " '1a2iy3',\n",
              " 'mu1a2~i3',\n",
              " '>a2iy3',\n",
              " 'mu1ota2~',\n",
              " '1A2i3ap',\n",
              " '1a2iy3ap',\n",
              " 'mu1A2i3',\n",
              " '1a2iy3',\n",
              " '1a2o3',\n",
              " '1u2o3ap',\n",
              " 'ta1Awu3',\n",
              " '1A2i3',\n",
              " 'wa2iy3',\n",
              " '1A2i3ap',\n",
              " 'mu1a2~i3',\n",
              " 'mu1a2~i3ap',\n",
              " \"{i1~i2A'\",\n",
              " 'wi2A3ap',\n",
              " '1a2A3ap',\n",
              " '1u2o3',\n",
              " '1A3',\n",
              " '1i2o3iy~',\n",
              " '1A3ap',\n",
              " '1u2o3ap',\n",
              " '1i2~iy3',\n",
              " '1A}i3',\n",
              " 'ma1o2a3',\n",
              " 'ma1o2a3',\n",
              " 'ma1o2a3',\n",
              " '1a2i3',\n",
              " 'ma1o2a3',\n",
              " '1A2i3ap',\n",
              " '1A2i3ap',\n",
              " '{i1oti2A3',\n",
              " 'ta1o2iyap',\n",
              " '>u1o2uw3',\n",
              " 'ma1o2uw3',\n",
              " '{i1oti2A3',\n",
              " '1A}i3',\n",
              " '1a2~',\n",
              " 'ta1oyiy3',\n",
              " 'ta1A2u3',\n",
              " '1a2a3',\n",
              " '1a2a3',\n",
              " '1iwAyap',\n",
              " '1a2aY',\n",
              " '1A3ap',\n",
              " 'NTWS',\n",
              " '1iyA3ap',\n",
              " '1a2A3ap',\n",
              " '1a2a3',\n",
              " '1a2oyap',\n",
              " '1awo3',\n",
              " '>u2o3ap',\n",
              " '>u2o3u4',\n",
              " 'ma1A2i3',\n",
              " '1i2A3iy~',\n",
              " '1A}i3ap',\n",
              " '1a2o3',\n",
              " '1a2a3ap',\n",
              " '1ayo3',\n",
              " '1a2o3',\n",
              " '1a2iy3',\n",
              " '1a2~A3',\n",
              " '1awo3ap',\n",
              " '1a2A3ap',\n",
              " 'NTWS',\n",
              " '1a2~ap',\n",
              " '{i1oti2A3',\n",
              " '1A2i3',\n",
              " 'mu1oTA3',\n",
              " '1A}i3',\n",
              " '1A2i3',\n",
              " '1a2A3iy~ap',\n",
              " '{it~i2A3',\n",
              " 'wa2o3',\n",
              " '1a2a3',\n",
              " '1uw3ap',\n",
              " '{isoti1o2A3',\n",
              " 'ta1o2iy3',\n",
              " '1ayo3',\n",
              " 'mu1o2i3',\n",
              " 'muta1aw~i3',\n",
              " '1ayo3',\n",
              " '1A2iy',\n",
              " 'muta1A2i3',\n",
              " 'muta1a2~i3',\n",
              " '1a2iy3',\n",
              " '1A2i}ap',\n",
              " '1u2o3ap',\n",
              " 'ta1o2iy3',\n",
              " 'NTWSap',\n",
              " '1a2o3ap',\n",
              " '1a2o3',\n",
              " '1a2o3ap',\n",
              " '<iy2A3',\n",
              " '1a2a3',\n",
              " '1A2i3',\n",
              " '1u2A3',\n",
              " '1a2a3',\n",
              " 'musota1o2aY',\n",
              " '1i2A3',\n",
              " '1a2a3ap',\n",
              " 'mu1A2i3',\n",
              " '1u2o3',\n",
              " 'mu1A2i3',\n",
              " '<iy2A3iy~',\n",
              " '1a2o3',\n",
              " 'tawA2u3',\n",
              " '1A2i3',\n",
              " '1awA3',\n",
              " '1awo3ap',\n",
              " '1i2A3',\n",
              " 'NTWS',\n",
              " '1A2i3',\n",
              " '1a2A3',\n",
              " '1a2A3ap',\n",
              " '1u2~ap',\n",
              " '1a2iy3',\n",
              " '1i2A}iy~',\n",
              " '1a2o3',\n",
              " '{it~i2A3',\n",
              " '1a2uw3iy~',\n",
              " 'mu1A2i3',\n",
              " '1a2o3',\n",
              " 'NTWS',\n",
              " 'ma1o2a3',\n",
              " 'ta1o2iy3',\n",
              " '1awo3',\n",
              " '1u2o3',\n",
              " '1a2o3',\n",
              " '>a2',\n",
              " '1awo3ap',\n",
              " 'ta1o2iy3',\n",
              " '1i2o3',\n",
              " 'mu1ota2i3',\n",
              " 'mu1a2~a3',\n",
              " '1A2i3ap',\n",
              " 'ma1o2i3',\n",
              " '1a2o3',\n",
              " '>awo2u3',\n",
              " '1a2a3',\n",
              " 'mu1A2a3ap',\n",
              " 'ma1o2a3',\n",
              " '1i2A3ap',\n",
              " 'mu1A2a3ap',\n",
              " '1a2iy3ap',\n",
              " 'musota1o2a3',\n",
              " 'NTWS',\n",
              " '1a2iy3ap',\n",
              " '1a2o3',\n",
              " '{i1oti2A3',\n",
              " '1a2iy3',\n",
              " 'mu1ota2a3',\n",
              " 'ma1o2uw3',\n",
              " 'mu1A2a3ap',\n",
              " 'ta1o2iy3',\n",
              " '1a2A3ap',\n",
              " '{i1o2',\n",
              " '1a2A',\n",
              " '1ayo3iy~ap',\n",
              " 'ta1o2iy3',\n",
              " 'ma1a2~',\n",
              " 'ta1o2iy3',\n",
              " 'ma1o2i3ap',\n",
              " 'ta1a2~u3',\n",
              " '1aya3An',\n",
              " 'ma1o2iy~',\n",
              " 'ma1o2aY',\n",
              " '{i1oti2A3',\n",
              " '>u2uw3iy~',\n",
              " '1a2o3',\n",
              " '1a2A3',\n",
              " 'NTWS',\n",
              " 'ma1o2uw3',\n",
              " '1a2o3a4ap',\n",
              " '1a2iy3',\n",
              " 'mu1ota2a3',\n",
              " 'ta1o2iy3',\n",
              " '1u2o3iy~',\n",
              " '1A3ap',\n",
              " '1A2uw3ap',\n",
              " 'muta1a2~i3',\n",
              " '1a2a3',\n",
              " 'musotawo2i3',\n",
              " 'musota1o2a3',\n",
              " '{i1oti2A3',\n",
              " '>u2u3',\n",
              " 'NTWS',\n",
              " 'ma1A2~',\n",
              " '1a2o3',\n",
              " '>a2iy3',\n",
              " '1a2o3',\n",
              " '{i1oti2A3',\n",
              " \"<i1o2A'\",\n",
              " 'ta1ay~u3',\n",
              " 'wi2A3',\n",
              " '1A2i3',\n",
              " '<i1o2A3',\n",
              " '1a2o3',\n",
              " '1uw3iy~',\n",
              " '1A2i3ap',\n",
              " '{i1oti2A3iy~',\n",
              " '2u&omi3',\n",
              " 'mu1A2a3ap',\n",
              " 'mu&a2~a3',\n",
              " 'wa2iy3ap',\n",
              " '1a2o3ap',\n",
              " '1i2~ap',\n",
              " '1u2o3',\n",
              " '1u2uw3',\n",
              " '1i2A3ap',\n",
              " '1a2A3',\n",
              " '1a2ap',\n",
              " '1a2~',\n",
              " '1i2o3ap',\n",
              " '1a2~A3ap',\n",
              " \"1i2A'\",\n",
              " 'mu1a2~iy',\n",
              " 'mu1a2~i3',\n",
              " '1i2~',\n",
              " 'mu1A2i3',\n",
              " '1i2o3ap',\n",
              " 'mu1a2~i3',\n",
              " '1ayo2a3',\n",
              " 'mu1A2i3',\n",
              " 'mu1A2a3ap',\n",
              " '1A2i3',\n",
              " 'mu1A2i3',\n",
              " '1a2o3',\n",
              " '1i2A3',\n",
              " '1u2Ayap',\n",
              " 'mu1ota2a3',\n",
              " '>a2iy3',\n",
              " 'mu1A2i3',\n",
              " '2u&Ama3ap',\n",
              " 'NTWSap',\n",
              " '1a2iy3ap',\n",
              " '1u2ow',\n",
              " '1u2A3',\n",
              " 'NTWS',\n",
              " 'mawo2uw3',\n",
              " 'ta1A2u3',\n",
              " '<i1A3ap',\n",
              " '1i2~iy3',\n",
              " '1a2a3',\n",
              " 'mi1owa3',\n",
              " '1a2o3iy~',\n",
              " 'ta1o2iy3',\n",
              " 'mu1A2i3',\n",
              " '1i2A3',\n",
              " 'ma1o2a3',\n",
              " 'mu1A2i3',\n",
              " '1i2o3',\n",
              " \"1awo'\",\n",
              " '1a2iy~ap',\n",
              " '1a2o3ap',\n",
              " 'mu1iy3',\n",
              " '1i2o3',\n",
              " 'wA2i3',\n",
              " '1u2o3ap',\n",
              " '1a2iy3',\n",
              " '1i2o3',\n",
              " '1a2uw3ap',\n",
              " '1i}o3',\n",
              " '1i2o3',\n",
              " '1a2iy3',\n",
              " 'mi1o2A3',\n",
              " 'mi1o2a3',\n",
              " '1u2o3A4',\n",
              " 'mu1a2~i3',\n",
              " '1u2uw3ap',\n",
              " '1a2o3',\n",
              " 'ma1o2a3',\n",
              " '{isoti1o2A3',\n",
              " '1a2~A3ap',\n",
              " '1a2a3',\n",
              " '1ay~i3',\n",
              " '{i1otiyA3',\n",
              " \"{i1oti2A'\",\n",
              " '{i1oti2A3',\n",
              " '1u2a3o4A',\n",
              " 'ma>o2a3',\n",
              " '1u2o3uw4iy~',\n",
              " '1u2owap',\n",
              " '1u2o3u4',\n",
              " 'ma1o2a3ap',\n",
              " '{ino1i2A3',\n",
              " '1u2o3',\n",
              " '{isoti1A3ap',\n",
              " 'ma1o2a3',\n",
              " 'ta1o2iy3',\n",
              " 'ma1A2i3',\n",
              " '{isoti1o2A3',\n",
              " '{isoti1o2A3iy~',\n",
              " '1uwayo3iy~',\n",
              " '1uw3iy~',\n",
              " '1ayo3',\n",
              " 'muwA2a3ap',\n",
              " '1i2A3',\n",
              " 'wA2i3',\n",
              " '1a2o3',\n",
              " 'wa2o3',\n",
              " 'mu1A2a3ap',\n",
              " 'mu1a2~i3',\n",
              " 'ta1o2iy3',\n",
              " 'mu1a2~a3',\n",
              " 'mu1a2~i3',\n",
              " 'mu1Awi3',\n",
              " 'ta1o2iy3',\n",
              " 'wa2iy3',\n",
              " '1i2A3',\n",
              " 'mu1Awa3ap',\n",
              " 'wa2o3',\n",
              " 'wa2o3',\n",
              " '1iy~ap',\n",
              " 'mu1A2a3ap',\n",
              " 'wi2o3ap',\n",
              " 'mu1a2o3a4',\n",
              " 'mu1a2~i3',\n",
              " '1A2~ap',\n",
              " 'mu1A2a3ap',\n",
              " '1a2owap',\n",
              " '1a2a3iy~ap',\n",
              " 'mu1A2~',\n",
              " 'mu1A2a3ap',\n",
              " 'tawa2~u3',\n",
              " 'muw2i3',\n",
              " '2awat~u3',\n",
              " 'mu1A2a3ap',\n",
              " 'mu1otA3',\n",
              " 'NTWS',\n",
              " 'muta1ay~i3',\n",
              " 'muta1a2~i3',\n",
              " '1A2i3iy~',\n",
              " '1i2o3iy4',\n",
              " '1i2o3iy4',\n",
              " '1A2i3',\n",
              " '1a2A3iyn',\n",
              " 'mu1A2i3',\n",
              " '1a2A3ap',\n",
              " 'mu1ota2a3',\n",
              " 'ta1a2~u3',\n",
              " 'mu1a2~a3',\n",
              " 'mu1a2~i3ap',\n",
              " 'mu1Awi3',\n",
              " 'mu1A2i3ap',\n",
              " 'mu1A2a3ap',\n",
              " '2u&otami3',\n",
              " 'ma1a2~',\n",
              " 'ma1o2a3ap',\n",
              " '{i1oti2A3',\n",
              " '1a2iy3',\n",
              " 'ma1o2aY',\n",
              " 'ma1o2uw3ap',\n",
              " 'ma1a2~',\n",
              " '1uw~ap',\n",
              " '{i1oti2A3',\n",
              " 'ma1o2uw3',\n",
              " 'ma1o2uw3',\n",
              " 'ta1A2u3',\n",
              " '{i1oti2A3',\n",
              " 'ma1o2aY',\n",
              " 'ma1o2aY',\n",
              " '1A2i3',\n",
              " '{i1oti2A3',\n",
              " '1a2~A3ap',\n",
              " '1a2iy~ap',\n",
              " '1a2~',\n",
              " '{i1otiyA3',\n",
              " '1a2o3ap',\n",
              " 'ma1o2a3',\n",
              " '1u2o3',\n",
              " 'ma1A3',\n",
              " 'mu1ota2i3',\n",
              " '1a2iy3iy~',\n",
              " '1a2iy3ap',\n",
              " 'ta1a2~u3',\n",
              " 'miy2A3',\n",
              " '1a2a3',\n",
              " '1a2a3',\n",
              " '1a2o3iy~ap',\n",
              " '1awo3ap',\n",
              " 'mawo2i3ap',\n",
              " 'ta1owiy3',\n",
              " 'ma1o2a3',\n",
              " '1ay~i3',\n",
              " 'ta1o2iy3',\n",
              " 'ma1o2a3',\n",
              " 'ma1o2a3',\n",
              " 'ma1o2i3',\n",
              " '1a2uw3',\n",
              " 'ma1o&uw3',\n",
              " '1i2A3',\n",
              " 'ma1o&uw3',\n",
              " '1i2o3',\n",
              " '1u2A3ap',\n",
              " '1a2oyap',\n",
              " '|yap',\n",
              " '1a2uw~',\n",
              " '>u2~',\n",
              " '1a2iy3',\n",
              " '1a2o3',\n",
              " '1a2~A3ap',\n",
              " '>a1a2~iy~ap',\n",
              " '1i2Ayap',\n",
              " '<i1o2A3iy~',\n",
              " 'NTWS',\n",
              " '<i2o3iy4',\n",
              " 'NTWS',\n",
              " '1A2iy',\n",
              " '1i2~ap',\n",
              " '1a2owaY',\n",
              " '<i2o3',\n",
              " '2i3ap',\n",
              " \"1ayo'\",\n",
              " '1i2o3ap',\n",
              " '1a2a3',\n",
              " 'NTWS',\n",
              " '1a2iy3',\n",
              " '1a2o3ap',\n",
              " '1a2o3',\n",
              " '1A2i3',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Sentiment Analysis Model**"
      ],
      "metadata": {
        "id": "dU09qVXA9kp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install camel-tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUsTC4b-00L",
        "outputId": "b18f1f0f-2446-4bff-ed48-11d54b6cca70"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: camel-tools in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.6.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.3.5)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.5.3)\n",
            "Requirement already satisfied: pyrsistent in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.19.2)\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from camel-tools) (4.24.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (from camel-tools) (2.2.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.8.10)\n",
            "Requirement already satisfied: camel-kenlm in /usr/local/lib/python3.7/dist-packages (from camel-tools) (2021.12.27)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from camel-tools) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.0.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from camel-tools) (5.2.0)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from camel-tools) (1.12.1+cu113)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from camel-tools) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from camel-tools) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->camel-tools) (4.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (0.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel-tools) (4.13.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.2->camel-tools) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.2->camel-tools) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel-tools) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel-tools) (2.8.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->camel-tools) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->camel-tools) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->camel-tools) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from camel_tools.sentiment import SentimentAnalyzer\n",
        "\n",
        "sa = SentimentAnalyzer(\"CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment\")\n",
        "print(trainData[0][1])\n",
        "sentences = [trainData[10][0], trainData[0][1]]\n",
        "\n",
        "sa.predict(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yxm0XdF9wML",
        "outputId": "3bf27c8d-5689-48b7-c845-9c0d7eb2cf05"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hadaf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neutral', 'neutral']"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MFDQIHuClaE"
      },
      "source": [
        "## **Analyzing Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGoQfT1ClaE",
        "outputId": "f1300043-d401-4c00-fc3e-31150093ca55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unseen data(lemma) in dev set:  85\n",
            "number of unseen data(lemma) in test set:  78\n",
            "\n",
            "number of unseen data((lemma, inflection) pair) in dev set:  108\n",
            "number of unseen data((lemma, inflection) pair) in test set:  88\n"
          ]
        }
      ],
      "source": [
        "# generate samples of dev/test set which are not in train set\n",
        "# compare with lemma\n",
        "devSetExistence = np.array([lemma in trainData[0] for lemma in devData[0]])\n",
        "testSetExistence = np.array([lemma in trainData[0] for lemma in testData[0]])\n",
        "\n",
        "unseenLemmaIndices_dev = np.where(devSetExistence==False)[0]\n",
        "unseenLemmaIndices_test = np.where(testSetExistence==False)[0]\n",
        "\n",
        "print('number of unseen data(lemma) in dev set: ', np.count_nonzero(devSetExistence==False))\n",
        "print('number of unseen data(lemma) in test set: ', np.count_nonzero(testSetExistence==False), end='\\n\\n')\n",
        "\n",
        "# compare with (lemma, inflection) pair\n",
        "  # first: generate (lemma, inflection) pair in sets\n",
        "trainLemmaInf = np.stack((trainData[0], trainData[3]), axis=-1).tolist()\n",
        "devLemmaInf = np.stack((devData[0], devData[3]), axis=-1).tolist()\n",
        "testLemmaInf = np.stack((testData[0], testData[3]), axis=-1).tolist()\n",
        "\n",
        "devSetExistence = np.array([lemInf in trainLemmaInf for lemInf in devLemmaInf])\n",
        "testSetExistence = np.array([lemInf in trainLemmaInf for lemInf in testLemmaInf])\n",
        "\n",
        "unseenLemInfIndices_dev = np.where(devSetExistence==False)[0]\n",
        "unseenLemInfIndices_test = np.where(testSetExistence==False)[0]\n",
        "\n",
        "print('number of unseen data((lemma, inflection) pair) in dev set: ', np.count_nonzero(devSetExistence==False))\n",
        "print('number of unseen data((lemma, inflection) pair) in test set: ', np.count_nonzero(testSetExistence==False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "5OTbLa3QClaE"
      },
      "outputs": [],
      "source": [
        "# create dataframe for dev set's unseen data\n",
        "    # 0:lemma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "    \n",
        "data_analysis_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Datasets analysis/'\n",
        "os.makedirs(data_analysis_path, exist_ok=True)  \n",
        "\n",
        "unseenLemmaIndices_dev_df = pd.DataFrame({'index': unseenLemmaIndices_dev,\n",
        "                                           'lemma': np.array(devData[0])[unseenLemmaIndices_dev],\n",
        "                                           'inflection': np.array(devData[3])[unseenLemmaIndices_dev],\n",
        "                                           'pl pattern': np.array(devData[4])[unseenLemmaIndices_dev]})\n",
        "unseenLemmaIndices_dev_df.to_csv(data_analysis_path + 'unseenLemma_dev.csv')\n",
        "\n",
        "\n",
        "unseenLemInfIndices_dev_df = pd.DataFrame({'index': unseenLemInfIndices_dev,\n",
        "                                           'lemma': np.array(devData[0])[unseenLemInfIndices_dev],\n",
        "                                           'inflection': np.array(devData[3])[unseenLemInfIndices_dev],\n",
        "                                           'pl pattern': np.array(devData[4])[unseenLemInfIndices_dev]})\n",
        "unseenLemInfIndices_dev_df.to_csv(data_analysis_path + 'unseenLemInf_dev.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "w0Fr3rOaClaE",
        "outputId": "88ead232-ff04-4747-943d-12c8f475b6d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index      lemma   inflection   pl pattern\n",
              "0    224   muHaw~il   muHaw~ilAt   mu1aw~i3At\n",
              "1    234  mujawohar  mujawoharAt  mu1awo3a4At\n",
              "2    283      Haloy       Huliy~       1u2iy~\n",
              "3    298     tAriyx     tawAriyx     tawA2iy3\n",
              "4    325     $Aliyh     $AliyhAt       NTWSAt"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d0de3c6-c0a7-423a-b307-ff1ab28c078f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>pl pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>224</td>\n",
              "      <td>muHaw~il</td>\n",
              "      <td>muHaw~ilAt</td>\n",
              "      <td>mu1aw~i3At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>234</td>\n",
              "      <td>mujawohar</td>\n",
              "      <td>mujawoharAt</td>\n",
              "      <td>mu1awo3a4At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>283</td>\n",
              "      <td>Haloy</td>\n",
              "      <td>Huliy~</td>\n",
              "      <td>1u2iy~</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298</td>\n",
              "      <td>tAriyx</td>\n",
              "      <td>tawAriyx</td>\n",
              "      <td>tawA2iy3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>325</td>\n",
              "      <td>$Aliyh</td>\n",
              "      <td>$AliyhAt</td>\n",
              "      <td>NTWSAt</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d0de3c6-c0a7-423a-b307-ff1ab28c078f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5d0de3c6-c0a7-423a-b307-ff1ab28c078f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5d0de3c6-c0a7-423a-b307-ff1ab28c078f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "unseenLemInfIndices_dev_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "ZSIHXimcClaE"
      },
      "outputs": [],
      "source": [
        "# create dataframe for test set's unseen data\n",
        "unseenLemmaIndices_test_df = pd.DataFrame({'index': unseenLemmaIndices_test,\n",
        "                                           'lemma': np.array(testData[0])[unseenLemmaIndices_test],\n",
        "                                           'inflection': np.array(testData[3])[unseenLemmaIndices_test],\n",
        "                                           'pl pattern': np.array(testData[4])[unseenLemmaIndices_test]})\n",
        "unseenLemmaIndices_test_df.to_csv(data_analysis_path + 'unseenLemma_test.csv')\n",
        "\n",
        "\n",
        "unseenLemInfIndices_test_df = pd.DataFrame({'index': unseenLemInfIndices_test,\n",
        "                                           'lemma': np.array(testData[0])[unseenLemInfIndices_test],\n",
        "                                           'inflection': np.array(testData[3])[unseenLemInfIndices_test],\n",
        "                                           'pl pattern': np.array(testData[4])[unseenLemInfIndices_test]})\n",
        "unseenLemInfIndices_test_df.to_csv(data_analysis_path + 'unseenLemInf_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "a12IILXmClaE",
        "outputId": "57eb2b3a-1d4e-46dd-ee47-79ba7484e7d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index     lemma  inflection  pl pattern\n",
              "0    179  minaS~ap    minaS~At    mi1a2~At\n",
              "1    274   muDorib  muDoribiyn  mu1o2i3iyn\n",
              "2    312  Eubuw~ap    Eubuw~At    1u2uw~At\n",
              "3    339  rafiyqap    rafiyqAt    1a2iy3At\n",
              "4    362   sAEidap     sawAEid     1awA2i3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae7b0176-8a77-4b6b-ab71-04673bbf8148\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>lemma</th>\n",
              "      <th>inflection</th>\n",
              "      <th>pl pattern</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>179</td>\n",
              "      <td>minaS~ap</td>\n",
              "      <td>minaS~At</td>\n",
              "      <td>mi1a2~At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>274</td>\n",
              "      <td>muDorib</td>\n",
              "      <td>muDoribiyn</td>\n",
              "      <td>mu1o2i3iyn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>312</td>\n",
              "      <td>Eubuw~ap</td>\n",
              "      <td>Eubuw~At</td>\n",
              "      <td>1u2uw~At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>339</td>\n",
              "      <td>rafiyqap</td>\n",
              "      <td>rafiyqAt</td>\n",
              "      <td>1a2iy3At</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>362</td>\n",
              "      <td>sAEidap</td>\n",
              "      <td>sawAEid</td>\n",
              "      <td>1awA2i3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae7b0176-8a77-4b6b-ab71-04673bbf8148')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae7b0176-8a77-4b6b-ab71-04673bbf8148 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae7b0176-8a77-4b6b-ab71-04673bbf8148');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "unseenLemInfIndices_test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_hpLQfwE5B2"
      },
      "source": [
        "## **Work On Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjehYdq8FCGg",
        "outputId": "7cc20fed-1525-4412-cb3c-88f75cc73c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "duplicate indexes has been updated\n",
            "{'Eamal': [0], 'hadaf': [1], 'EuDow': [2, 815, 1619], 'jihAz': [3, 689], 'Hukom': [4], 'EunoSur': [5], 'Haq~': [6], 'maSolaHap': [7], 'Eamaliy~ap': [8], 'farod': [9], 'siEor': [10], '<imokAn': [11], \"<ijorA'\": [12], 'mawoqif': [13], 'jahod': [14], 'quw~ap': [15, 292, 933, 1650, 1827, 1835, 1845], 'EalAqap': [16], 'sabab': [17], 'Sawot': [18], 'qarAr': [19], 'silAH': [20, 394], '>avar': [21], 'Tifol': [22], 'Hadav': [23], 'balad': [24, 102], 'natiyjap': [25], 'Zarof': [26], '{it~iSAl': [27], 'waDoE': [28], 'mu&as~asap': [29], 'TAlib': [30, 674, 1119, 1345, 2715, 2716], 'fikor': [31], 'niZAm': [32, 888, 1138], 'taSoriyH': [33, 1208], '>aroD': [34, 1204], 'tahodiyd': [35], 'dawolap': [36, 453], 'walad': [37], 'mAl': [38], 'baronAmaj': [39], 'yawom': [40], 'ma$oruwE': [41, 1375], 'Had~': [42], 'Taraf': [43], 'mAd~ap': [44], 'SAHib': [45, 2573], '{inotixAb': [46], '$aEob': [47], 'jaw~': [48, 2405], 'maTolab': [49], 'TA}irap': [50], 'HuDuwr': [51], 'minoTaqap': [52], '>ax': [53, 532, 1199], '>usoluwb': [54], 'siyAsap': [55], '$aroT': [56], 'jariymap': [57], '$arikap': [58], 'hajomap': [59], \"mA'\": [60, 1359], 'nA}ib': [61], 'qAEidap': [62], 'HAjap': [63], '>amor': [64, 383], 'Suwrap': [65, 654], 'waraq': [66], 'xidomap': [67], 'qiymap': [68], '{ibon': [69, 437, 735], 'muHAdavap': [70], '$axoS': [71, 1298], '|liy~ap': [72], 'muno$a>ap': [73], 'say~Arap': [74], 'maSodar': [75], 'waziyr': [76, 2040], 'qaDiy~ap': [77], 'xasArap': [78], 'suwq': [79], 'na$AT': [80, 185, 2561], '<isorA}iyliy~': [81], 'maEoluwm': [82], 'tafoSiyl': [83], 'rajul': [84, 1756], 'DAbiT': [85, 553], 'mu$okilap': [86, 183], 'rukon': [87], 'EA}ilap': [88], 'suloTap': [89], 'kitAb': [90], 'qAnuwn': [91], 'taHar~uk': [92], '>amal': [93], 'HAdiv': [94], 'qiboTiy~': [95, 2629], 'Hizob': [96], 'bayAn': [97], '>anoSAr': [98], 'wasaT': [99], 'wilAyap': [100], 'fiylom': [101], 'sAkin': [103], 'kalimap': [104], '{isotivomAr': [105], 'mubArAp': [106], 'dirAsap': [107], 'SAruwx': [108], 'raqom': [109], '{it~ifAq': [110], 'maso&uwl': [111, 969, 971, 1085], 'Earabiy~': [112], 'naba>': [113], '{ijotimAE': [114], \"liqA'\": [115], 'wajoh': [116], 'mufAwaDap': [117], '$ab~': [118], '$a>on': [119, 1350], '{isom': [120, 1260, 1893], '>usotA*': [121, 1463], '>aSol': [122], 'ma$oEar': [123], 'furoSap': [124], 'wasiylap': [125, 1080], 'muhim~ap': [126], 'Hukuwmap': [127], '<irohAbiy~': [128, 1920], 'filasoTiyniy~': [129, 1761, 2503], 'munaZ~amap': [130], 'baHov': [131, 500], 'Eaqod': [132], 'HAkim': [133], 'taZAhurap': [134], 'xabiyr': [135, 1707], 'maxAfap': [136], 'taTaw~ur': [137], 'sabiyl': [138], 'Eadad': [139], 'ra}iys': [140, 1819], 'mawoDuwE': [141, 289], 'qudorap': [142], 'jamoEiy~ap': [143], 'EAmil': [144, 454, 646, 1901, 1904], 'rasom': [145], 'jihap': [146], 'HisAb': [147], 'junodiy~': [148], 'nawoE': [149], 'qiTAE': [150], 'taHoqiyq': [151], 'hayo}ap': [152], 'qA}id': [153, 648, 2676], 'tajoribap': [154], 'tawoSiyap': [155], 'DagoT': [156, 1242], 'maboda>': [157], \"{iEotidA'\": [158], 'maHaT~ap': [159], 'dam': [160, 1606, 2187], 'maxATir': [161], 'xaTowap': [162, 382, 1702], 'madiynap': [163, 2464], 'daEowap': [164], 'manozil': [165], 'muHAwalap': [166, 1781], 'muEad~': [167], 'xabar': [168], 'madorasap': [169], 'yahuwdiy~': [170], 'faSiyl': [171], '$iEAr': [172], 'Tariyq': [173, 1066], 'waHodap': [174, 1932], \"Eibo'\": [175], 'Harakap': [176], '$akol': [177], '<iSolAH': [178], 'taSar~uf': [179], 'sahom': [180], 'xilAf': [181], 'miEoyAr': [182], '>um~ap': [184], 'xaT~': [186], 'nAs': [187], 'daliyl': [188, 838], 'ra>oy': [189, 1623], '$ahiyd': [190, 2093, 2097], 'rAkib': [191], 'masiyHiy~': [192, 952, 2190], 'musolim': [193, 1254], 'ramoz': [194], 'maSoraf': [195], 'marokaz': [196], 'muwATin': [197, 389, 2594], 'mulAHaZap': [198], 'jamAEap': [199], 'sAEap': [200], 'Euquwbap': [201], 'riHolap': [202], 'tadobiyr': [203], 'munAqa$ap': [204], 'qaSiydap': [205], 'ra>os': [206], 'maso&uwliy~ap': [207, 2188], 'yad': [208, 1658, 1706, 2000], 'qalob': [209], 'taSofiyap': [210], '>azomap': [211], 'EAlim': [212], '>asAs': [213], 'xuT~ap': [214], '{it~ihAm': [215], 'firoqap': [216], 'riboH': [217], 'Haliyf': [218, 996, 1398], \"nisA'\": [219, 2653, 2655], 'xaTa>': [220], 'lajonap': [221], 'Harob': [222], 'lawon': [223], 'SAdir': [224], 'Hamolap': [225], 'mujotamaE': [226], '$ajarap': [227], 'banod': [228], \"dawA'\": [229], 'musAEadap': [230], 'dAfiE': [231], 'munotaj': [232], 'muwAjahap': [233], 'EA}id': [234], 'mumArasap': [235], 'EaroD': [236], 'Darar': [237], 'musotawoTanap': [238], 'mutamar~id': [239, 2567], 'Sadiyq': [240, 457, 753], '<isolAmiy~': [241, 1949], '{inotihAk': [242], 'fAEiliy~ap': [243], 'manohaj': [244], 'SaHiyfap': [245], '<iyrAd': [246], 'taZAhur': [247], '>awolawiy~ap': [248, 2070], 'qiyAdap': [249], '<iEolAn': [250], 'tAjir': [251], 'milaf~ap': [252], 'qADiy': [253], '>amoriykiy~': [254, 539, 1505, 1506, 2150], 'nuqoTap': [255], 'baTal': [256, 2304], '$abakap': [257, 368], 'lAji}': [258, 2389], 'muHAmiy': [259, 1040], 'Haqiyqap': [260], 'naS~': [261], 'mawoqiE': [262], 'bAb': [263], 'makAn': [264, 1649], 'waqiyEap': [265], 'taqoriyr': [266], 'maHokamap': [267], 'Darobap': [268], 'ji*or': [269], 'majomuwEap': [270], 'sanap': [271, 790], 'lubonAniy~': [272], 'maqoEad': [273], 'dayon': [274], 'musotavomir': [275, 2808], 'Hulom': [276], 'Tabaqap': [277], 'muwASafap': [278], 'muxay~am': [279], 'muEoTaY': [280], 'katiybap': [281], 'HAlap': [282], 'bayot': [283, 1116, 2335], 'kam~iy~ap': [284], 'mivol': [285], 'maworid': [286], 'mawoEid': [287], 'qaroD': [288], 'Eayon': [290, 637, 2635], 'dab~Abap': [291], 'jiyl': [293], 'jAmiEap': [294], 'Ealam': [295], 'faranosiy~': [296], 'Hal~': [297], 'tadoriyb': [298], \"<iHoSA'\": [299], 'waEod': [300], '>usobuwE': [301], '>ahol': [302, 2165, 2166], '{iqotirAH': [303], 'tanoZiym': [304], 'zaEiym': [305, 1615], 'ta$oriyE': [306], 'taEowiyD': [307], 'tuhomap': [308], 'tilomiy*': [309, 912, 913, 1971], 'tay~Ar': [310], '{ihotimAm': [311], 'maroHalap': [312], 'dA}irap': [313], 'dAr': [314, 388], 'damoE': [315], 'qiToEap': [316], 'Easokariy~': [317, 1815], 'maqAl': [318], 'xiyAr': [319], '$axoSiy~ap': [320], 'majozarap': [321], 'majAl': [322], '{iHotifAl': [323], '>ufuq': [324], '{iHotimAl': [325], '>um~': [326, 2059], '$ugol': [327], 'DaHiy~ap': [328], 'taTal~uE': [329], 'SuEuwbap': [330], 'tawaq~uE': [331, 1954], 'Hay~': [332], 'SaHAfiy~': [333, 2802], 'SalAp': [334], 'mura$~aH': [335, 337, 2852, 2854], 'varowap': [336], 'munotaxab': [338], 'munAwarap': [339], 'mu&a$~ir': [340], 'namaT': [341], 'TA}ifap': [342], 'wafod': [343], '<ilof': [344], 'waviyqap': [345, 2037], 'wikAlap': [346, 1584], 'maEonawiy~': [347], 'mu&otamar': [348], 'risAlap': [349], 'masoEaY': [350, 1084], 'maEolam': [351], \"juzo'\": [352, 1373], 'funoduq': [353], 'sA}iH': [354, 1879], '{isotiTolAE': [355], '{imotiHAn': [356], '{isotiEodAd': [357], '$Ahid': [358], '|lap': [359], '*ikoraY': [360], 'minoHap': [361], 'xuTobap': [362], '<imArap': [363], '>aromaniy~': [364], 'kAtib': [365], 'mubAdarap': [366], 'TumuwH': [367], 'bAHiv': [369], 'muHADarap': [370], 'qanAp': [371, 2622], '<iSobaE': [372], 'mu$Arik': [373, 2346], '<iSAbap': [374], 'muEad~al': [375], 'kitAbap': [376], 'Tabiyb': [377], 'baladiy~ap': [378], 'balodap': [379], 'tadAEiy': [380], 'lAEib': [381, 499, 1299, 1454], 'mu$Awarap': [384], 'muhanodis': [385, 2757], 'say~idap': [386], 'kAhin': [387], 'muwaZ~af': [390, 562, 1443, 1449, 1466], 'siloEap': [391], 'muxaT~aT': [392], 'mutaZAhir': [393], 'nAr': [395], 'jaziyrap': [396], 'musotawaY': [397], 'vAbitap': [398], 'taqoniy~ap': [399], 'Saf~': [400], 'su&Al': [401, 2103], 'Dariybap': [402], 'jA}izap': [403], 'SinAEap': [404, 2828], 'sik~ap': [405], 'wAjib': [406], 'munAsabap': [407], 'nafas': [408], 'sifArap': [409], 'mumotalak': [410], 'mumav~il': [411, 412, 1348], '<inojAz': [413], 'EAm': [414], 'EunowAn': [415], 'qayod': [416], 'ziyArap': [417], 'taHaw~ul': [418], 'diroE': [419], 'diyn': [420], '$ayox': [421, 1394], 'manoSib': [422], 'makotab': [423], 'garaD': [424], 'rAbiTap': [425, 608], 'mafohuwm': [426], '>unomulap': [427], 'EaqAr': [428], 'madaniy~': [429], 'mabolag': [430], 'mabiyE': [431], 'maZohar': [432], 'fi}ap': [433], '{ilotizAm': [434], 'ma>osAp': [435], 'rahiynap': [436], 'maEoriD': [438], 'taEobiyr': [439], 'Eaduw~': [440, 976, 1390], 'maEorakap': [441], 'ruwH': [442], 'taEad~iy': [443], 'rifoqap': [444], 'gAyap': [445], 'taEoziyz': [446], 'tasowiyap': [447], 'zA}ir': [448, 1641], 'maso>alap': [449], '$ahor': [450, 1029], 'masiyrap': [451], 'daqiyqap': [452], '$AEir': [455], '{iHotiyATiy~': [456], 'Sador': [458], '$ariyT': [459, 1420, 2135], 'maSonaE': [460], 'murAqib': [461, 1565], '{iHotikAr': [462], 'faroE': [463], 'SidAm': [464], 'muqad~as': [465], 'faqiyr': [466], '*axiyrap': [467], 'fatorap': [468], 'jumohuwr': [469], 'musotawoTin': [470, 2804, 2805, 2806], '{inotiqAd': [471], 'Hiyn': [472], 'tawojiyh': [473, 1961], \"{inotimA'\": [474], '*A': [475, 1672, 1673], 'muvaq~af': [476, 2596], 'mut~aham': [477], 'Hur~iy~ap': [478], 'mutafaj~ir': [479], '$Ab~': [480], 'mawoTin': [481], 'jalosap': [482], 'mutaTal~ab': [483], 'lAfitap': [484], 'xiborap': [485], 'jAr': [486], 'dibluwmAsiy~': [487, 1010, 2198], 'Sunoduwq': [488], 'maToEam': [489], 'xaSom': [490, 1688], 'muSad~ir': [491], '{inoEikAs': [492], '<idArap': [493], '<iTAr': [494, 1642], 'kabiyr': [495], '{iDoTirAb': [496], 'muEotaqal': [497, 2296, 2297], 'maraD': [498], 'muEaw~iq': [501], 'kurodiy~': [502], 'muDAEafap': [503], 'muEAriD': [504, 583, 2271], 'mubAHavap': [505], '$ak~': [506], 'dawor': [507], 'faE~Aliy~ap': [508], 'kul~iy~ap': [509], 'fan~An': [510, 1684, 2468], 'biDAEap': [511], '<i$Arap': [512], 'zamiyl': [513, 639, 1780], 'TAqap': [514], 'mukaw~in': [515], 'xaTar': [516], 'majolis': [517], 'wadiyEap': [518, 1939], 'fiEol': [519], 'fA}idap': [520], '<i*AEap': [521], 'sir~': [522], 'mirofaq': [523], 'TamaE': [524], 'Eilom': [525], 'taHo*iyr': [526], 'takoliyf': [527, 882], 'taHad~iy': [528], 'taDoHiyap': [529], 'taHaf~uZ': [530], 'qunobulap': [531], '>alam': [533], 'namuw*aj': [534], '>adab': [535], 'qA}imap': [536], 'safiyr': [537], 'nAdiy': [538, 661], 'EibArap': [540], 'taHoDiyr': [541], 'sijon': [542], 'niqAbap': [543], 'nafos': [544, 1419], '>adAp': [545], 'sanad': [546], 'sajiyn': [547], '>aqorab': [548], 'tarotiyb': [549], 'ta>oviyr': [550], 'niy~ap': [551, 892], 'taEoliyq': [552], 'tasA&ul': [554], 'rafiyq': [555], 'raSiyd': [556], '>ugoniyap': [557, 1542, 2063, 2065], '>ajonabiy~': [558], 'rAtib': [559], 'Eamiyl': [560, 1186], 'taEodiyl': [561], 'Dayof': [563], 'siyAsiy~': [564, 1491], 'tagoyiyr': [565], 'Eumor': [566], '<ifAdap': [567], 'tajam~uE': [568], 'muEal~im': [569, 896, 1766], 'kurap': [570], 'miyliy$iyA': [571], 'EASimap': [572], 'misAHap': [573], 'Eumoq': [574], 'muSaw~ir': [575, 2740], 'buEod': [576], 'qadiym': [577], 'muHar~ik': [578], '>amiyr': [579], 'mu$otaq~': [580], 'bArijap': [581], 'kaniysap': [582], 'badiyl': [584], 'kasor': [585], 'gurofap': [586], 'tajAwuz': [587], 'HAjiz': [588], 'wasiyT': [589], 'EASifap': [590], 'muHaq~iq': [591], 'mu*ak~irap': [592], \"{id~iEA'\": [593], 'wizArap': [594], 'HaDArap': [595], 'Eurof': [596], 'HAl': [597], 'miSoriy~': [598, 2327], '$A$ap': [599], 'kutolap': [600], 'xir~iyj': [601, 821], 'sA}iq': [602, 1157, 1915], 'ma$ohad': [603], 'malomaH': [604], 'malobas': [605], 'malik': [606], 'makosab': [607], 'rAhibap': [609], '{iEotiqAl': [610], 'taEoziyap': [611], '>unobuwb': [612], 'madoxuwl': [613], '{iEotirAf': [614], 'rA}id': [615, 1856], 'fan~': [616], 'taEoyiyn': [617], 'taEAmul': [618], 'maTar': [619], 'faraH': [620], 'riwAyap': [621], 'fataY': [622], 'gArap': [623], 'diymuqrATiy~': [624], 'diyAnap': [625], 'dalAlap': [626], 'qamar': [627], 'qaroyap': [628, 974, 2609], 'qawol': [629, 1582], '>usorap': [630], '>usoquf': [631], 'matAEib': [632], 'EirAqiy~': [633], 'lA}iHap': [634], 'lagom': [635], 'darajap': [636], 'daros': [638], 'zar~AE': [640], 'daworap': [641], '$ahAdap': [642], 'liybirAliy~': [643], 'mar~ap': [644], '{i$otibAk': [645], 'muSoTAf': [647], '$AriE': [649], 'SalAHiy~ap': [650], '{it~iHAd': [651], 'wahom': [652], 'Talab': [653], '{isotixobAr': [655], 'tamoriyn': [656], 'jayo$': [657], 'mujorim': [658, 2707], 'mutaTaw~iE': [659], 'jayob': [660], 'mutaEAmil': [662], 'muta$ad~id': [663], 'Hadiyv': [664], 'TAri}ap': [665], 'vugorap': [666, 1923], 'taqoliyd': [667], 'huwiy~ap': [668], 'Safoqap': [669], 'najom': [670], 'SafoHap': [671], '<iyqAE': [672], 'vamar': [673], 'hutAf': [675], 'Hakam': [676], 'musota$ofaY': [677], 'jidAr': [678], 'nafaqap': [679], 'muhAjir': [680], 'juroH': [681, 1302], 'muhAjim': [682, 2760], '<iyjAbiy~': [683], 'TaroH': [684], 'tawAzun': [685], 'nA$iT': [686, 1161], 'jawAb': [687], 'jawolap': [688], '>uwlA}ika': [690], 'jAnib': [691], 'DamAn': [692], 'DamAnap': [693], 'juv~ap': [694], 'Hariyq': [695], 'nihA}iy~': [696], 'Taqos': [697], '{it~ijAh': [698], 'saEuwdiy~': [699, 1861], 'murAsil': [700, 2855, 2857], 'Haqol': [701], 'mAruwniy~': [702], 'maqoTaE': [703], 'taqodiymAt': [704], 'lawoH': [705], 'quTor': [706], 'darob': [707], '>ab': [708, 1407, 2126], 'lawoHap': [709], 'taqodiyr': [710], 'qisoT': [711], 'murotakib': [712, 1545, 2820], 'musal~aH': [713], 'EAqibap': [714], 'marojiE': [715], 'Saqor': [716], '>awojuh': [717], 'jabal': [718], 'musAhamap': [719], 'marosam': [720], 'EiSAbap': [721], 'musAbaqap': [722], 'safiynap': [723], 'musotalozam': [724], '>uwrub~iy~': [725, 1438, 2106], 'naSiyHap': [726], 'faroq': [727], '{ixotibAr': [728], '$ariyk': [729, 1276, 2137], 'muxotabar': [730], 'maSoruwf': [731], 'muxAlafap': [732], 'taEoqiyd': [733], 'EalAmap': [734], 'fatAp': [736], 'Hayoviy~ap': [737], 'taEoliym': [738, 740], 'maHal~': [739, 926], 'maEorifap': [741], 'taEah~ud': [742], 'fayaDAn': [743], 'maEoniy~': [744], 'maEonaY': [745], '{iHotijAj': [746], '>uSuwliy~': [747, 2066], 'Harof': [748, 1155], 'zamAn': [749, 1938], 'duwlAr': [750], 'manoduwb': [751, 935, 2260], 'Earoqalap': [752], 'musotanad': [754], 'taro$iyH': [755], 'turokiy~': [756, 1979], 'sAHap': [757], 'fAtuwrap': [758], 'mutaTar~if': [759, 1484], 'EaSab': [760], 'musotaworid': [761, 1465, 2803], 'musotaxodam': [762, 2778], '{ikoti$Af': [763], '>u*un': [764], 'mahorajAn': [765], 'maham~ap': [766], 'faHoS': [767], '>asiyr': [768, 1567], 'EaZom': [769], '{iqotiSAd': [770], \"<ino$A'\": [771], 'tagay~ur': [772], 'wisAm': [773], 'qAtil': [774, 2679], '<iDorAb': [775], 'banok': [776], 'suwriy~': [777], 'HAfilap': [778], '{iqotiSAdiy~': [779, 2085, 2088], 'mu&omin': [780], 'munAfasap': [781], 'mu&al~af': [782], 'waZiyfap': [783], 'Hafolap': [784], 'qim~ap': [785], 'Euqob': [786], 'Eumuwm': [787], 'biTAqap': [788], 'najAH': [789], 'ham~': [791], 'niEomap': [792], 'baH~Arap': [793], \"nidA'\": [794], 'muSal~iy': [795], 'mubar~ir': [796], 'Zil~': [797], 'mudAfiE': [798], 'nisobap': [799], 'muHal~il': [800], 'hayokal': [801], 'muHAfiZ': [802], 'muHAfaZap': [803], 'kAdir': [804], 'muHADir': [805], 'ba*or': [806], 'nizAE': [807], 'nufAyap': [808], 'muEotaqad': [809], '>ajiyr': [810], 'mu$Ahid': [811, 2348], 'mu&Amarap': [812], 'miydAliyap': [813], 'Haqiybap': [814], '$uEAE': [816], '*At': [817], 'mawoquwf': [818], 'tanAzul': [819], '<i$AEap': [820], 'naZar': [822], 'miHowar': [823], 'salobiy~': [824], 'tasohiyl': [825], 'muqAtil': [826, 829, 2832], 'SirAE': [827], 'matoHaf': [828], 'jisor': [830], \"Dawo'\": [831], 'maziy~ap': [832], 'laHoZap': [833], 'muqiym': [834], 'mitor': [835, 2312], 'wArid': [836, 1929], 'Eumolap': [837], 'milok': [839], 'Daruwrap': [840], 'bi}or': [841], '*ihon': [842], 'jariyH': [843], 'mifotAH': [844], 'midofaE': [845], 'muTorAn': [846], 'munaf~i*': [847, 1523], 'buTuwlap': [848], 'kalob': [849], 'maEomal': [850], '{isotiHoqAq': [851], 'jar~Afap': [852], 'laqab': [853], 'say~id': [854, 1235], '{igotiyAl': [855], \"{ifotirA'\": [856], '{ixotiSAS': [857], 'sulaHofAp': [858], 'ma>orab': [859], 'jumohuwriy~': [860], 'kulowap': [861, 2360], 'jumoruk': [862], 'ma*obaHap': [863], '{inoqisAm': [864], 'junod': [865], '{isoti$Arap': [866], 'maEohad': [867], 'ta$okiyl': [868], 'maEAbid': [869], '{isotinotAj': [870], '{isoti$ohAdiy~': [871], 'kuwayotiy~': [872], 'kuwbiy~': [873], 'sayof': [874], 'muwAzanap': [875], 'rihAn': [876], 'wAfid': [877], 'nagom': [878], 'waHol': [879], 'mulAbasap': [880], 'mukab~ir': [881], 'mujam~aE': [883], 'mufat~i$': [884, 1413], 'mufAwiD': [885, 1416], 'tajohiyz': [886], 'wakiyl': [887, 1982], 'mudAwalap': [889], 'waqof': [890], 'waqot': [891], 'muHAkamap': [893], 'wijohap': [894], 'muEasokar': [895], 'qAr~ap': [897], 'muEAmalap': [898], 'nadowap': [899], 'naZariy~ap': [900], 'muDAd~': [901], 'muqATaEap': [902], 'tawaj~uh': [903], 'muwjib': [904], 'tawat~ur': [905], 'muxAbarap': [906], 'muxotAr': [907, 2535], 'tilofizyuwn': [908], 'mutagay~ir': [909], 'mutafar~ij': [910], 'nASiriy~': [911], 'nAxib': [914, 1410, 1429], 'valAviyn': [915], 'musAhim': [916, 2793], 'vaqAfap': [917], 'muqotaraH': [918], 'taqal~ub': [919], 'muqar~ar': [920], 'muqad~imap': [921], 'muqAwil': [922], 'muqAtilap': [923], 'muEAlajap': [924], 'mu&otamir': [925], 'marokabap': [927], '{i$otirAk': [928], 'mariyD': [929], 'maqohaY': [930, 1686], 'maqoTuwEap': [931], 'maqar~': [932, 2251], '{iEotibAr': [934], 'mano$uwr': [936, 2247], 'taHAluf': [937], '{iEotimAd': [938], 'majoraY': [939, 940, 1662], 'rAqiS': [941, 1177], '{iEotirAD': [942], 'ra$~A$ap': [943], 'raEiy~ap': [944], 'rad~': [945, 1853], '{iHotiyAT': [946, 1417], 'ragobap': [947], 'maHoDar': [948], 'quTob': [949], 'masAr': [950], 'mu$otarik': [951, 2334], 'qa*iyfap': [953], 'tabar~uE': [954], 'miyvAq': [955], 'qadam': [956], 'qalam': [957], 'xalofiy~ap': [958], 'mawojap': [959], 'mawohibap': [960], 'taHowiyl': [961], 'matojar': [962], 'qay~im': [963], 'taHoliyl': [964, 2073], 'masolak': [965], 'masokan': [966], 'masojid': [967], 'zabuwn': [968], 'qinAE': [970, 2648], 'qisom': [972], 'zujAjap': [973], '|yap': [975], '>us~': [977], 'Eamiyd': [978], 'Eahod': [979], 'dar~Ajap': [980], '>aqal~iy~ap': [981], 'bidAyap': [982], '<iSolAHiy~': [983], 'HAxAm': [984], '<iqoliym': [985], 'hinoduwsiy~': [986], 'dAEiy': [987, 1588, 1590], 'HiS~ap': [988], '$akowaY': [989], '<inos': [990], 'Sifap': [991], \"$ayo'\": [992], 'diEomap': [993], 'Hajar': [994, 1143], 'fiyliyb~iyniy~': [995], 'Haloqap': [997], 'EaSor': [998], 'EAzif': [999], '<ijAbap': [1000], '<ijAzap': [1001], 'bunoduqiy~ap': [1002], 'bu&orap': [1003], 'Tariyqap': [1004], 'briyTAniy~': [1005], '<iyrAniy~': [1006], '$atiymap': [1007], '$awoT': [1008], '$ubohap': [1009], 'Hur~': [1011], 'Tabol': [1012], 'fAn': [1013], '>amiyn': [1014, 2152], '$aqiyq': [1015, 1021], 'Eiborap': [1016], 'DiEof': [1017], '$ATi}': [1018], '>uxot': [1019], 'bAqiy': [1020, 1774], '$AHinap': [1022], 'faSol': [1023], '*akar': [1024], 'Eayob': [1025], 'Eaqabap': [1026], 'EA}iq': [1027], '$Ab~ap': [1028], 'HAfiz': [1030], 'HiwAr': [1031], 'bAS': [1032], 'bAkistAniy~': [1033], 'Talaq': [1034], '$Ahidap': [1035], 'Eamuwd': [1036], 'badal': [1037], 'jadowal': [1038], '*ariyEap': [1039], 'muHotarif': [1041, 1388, 1574], 'ZAhirap': [1042], 'tawoZiyf': [1043], 'muHotAj': [1044], 'tasojiyl': [1045], 'taroxiyS': [1046], '<iyTAliy~': [1047], '<iyDAH': [1048], 'Turobiyd': [1049], 'muforadAt': [1050], 'takah~un': [1051], 'mukotasab': [1052], 'mujotamiE': [1053, 2705], 'TaEon': [1054], 'tamoriyrap': [1055], 'mujAhid': [1056, 2734, 2735], 'tanAquD': [1057], 'muhar~ib': [1058], 'Talaqap': [1059], 'mugotarib': [1060, 2762], 'taqodiym': [1061], 'TaloEap': [1062], 'muTAlib': [1063], 'mufak~ir': [1064], '>aEolAm': [1065], 'mufAja>ap': [1067], 'muEotaSim': [1068], 'mud~aEiy': [1069], 'mudiyr': [1070, 1422, 1423, 2772], 'mudar~is': [1071], 'mudar~ib': [1072, 2774], 'mudar~aEap': [1073], 'mudAxalap': [1074], 'tawoqiyf': [1075], \"binA'\": [1076], 'tayosiyr': [1077], 'baSomap': [1078], 'buwroSap': [1079], 'mawokib': [1081], 'buwsoniy~': [1082, 1610], 'watar': [1083], 'marosuwm': [1086], 'marofa>': [1087], 'xA}in': [1088], 'dufoEap': [1089], 'maqoSuwrap': [1090], 'xaTiyb': [1091], 'xaTiy}ap': [1092], 'manosuwj': [1093], '<i$oEAE': [1094], 'manofa*': [1095], 'malomas': [1096], 'xariyTap': [1097], 'maloEab': [1098], 'xaroq': [1099], 'fA}iD': [1100], 'fa>or': [1101], 'xayorap': [1102], 'majod': [1103], 'buwq': [1104], 'buwayoD': [1105], 'mawosim': [1106], \"miynA'\": [1107], '<itoniy~ap': [1108], 'muEal~iq': [1109], '<isotuwdiyuw': [1110], 'timovAl': [1111], 'baqar': [1112], 'muDArabap': [1113], 'variy~': [1114], 'vaworap': [1115], 'biloyuwn': [1117], 'miyzAn': [1118], 'waro$ap': [1120, 2026], 'binot': [1121], 'mivAl': [1122], '<ino*Ar': [1123], 'binoyap': [1124, 1128, 1784, 2315], 'mirowaHiy~ap': [1125, 2314], 'miqoyAs': [1126], 'minobar': [1127], 'wajobap': [1129], 'mazoEamap': [1130], '<ihAnap': [1131], '>afogAniy~': [1132], 'muqAwalap': [1133], 'tajA*ub': [1134], 'Ead~Ad': [1135], \"Ead~A'\": [1136, 1828], 'rawoDap': [1137], 'Hab~': [1139, 1573], 'naqoD': [1140], 'Hadiyqap': [1141], 'nakobap': [1142], 'riyH': [1144], 'ruwsiy~': [1145], 'ruxoSap': [1146], 'Ham~Am': [1147], 'Haraj': [1148], 'Harobap': [1149], 'naHow': [1150], 'naEot': [1151], 'sAbiqap': [1152], 'na$orap': [1153], 'na$iyT': [1154], 'nAziH': [1156], 'HayawAn': [1158], 'nA$ir': [1159], 'saToH': [1160], 'saboEiyn': [1162], 'Ha$od': [1163], 'ramol': [1164], 'muxad~ir': [1165], 'nuxobap': [1166], 'quboruSiy~': [1167], 'rAEiy': [1168, 1834], 'Earabap': [1169], 'EaraD': [1170], 'rAdAr': [1171], 'rAfidap': [1172], 'rAgib': [1173], 'Eaqol': [1174], 'Eaqiydap': [1175], 'qiS~ap': [1176], 'qatiyl': [1178], 'qariynap': [1179], 'EaqArib': [1180], 'Eu$ob': [1181], 'Eu*or': [1182], 'qabiylap': [1183], 'qaDiyb': [1184], 'Eunoq': [1185], 'qA}im': [1187], 'qAsim': [1188], 'HAj~': [1189], 'qAri}': [1190], 'HAmil': [1191], 'qAEap': [1192], 'HAris': [1193], 'muxal~af': [1194], 'HikAyap': [1195], 'tahoni}ap': [1196], 'musAEid': [1197, 1540, 2796, 2797], '>axolAqiy~': [1198], '>atoEAb': [1200], \">arojA'\": [1201, 2076], 'taHosiyn': [1202], 'murAfiq': [1203, 2841], 'muqotaDaY': [1205], 'muqaw~im': [1206], 'muqar~ab': [1207], 'Silap': [1209], 'muqAwim': [1210], 'taTobiyq': [1211], 'faHol': [1212], 'muqAranap': [1213], 'muqAbalap': [1214], 'Siygap': [1215], 'munotij': [1216, 1217], 'munotaqid': [1218, 1430], 'tadaf~uq': [1219], 'tadax~ul': [1220], 'munaZ~im': [1221, 2718, 2719], 'tafAEul': [1222], 'tafojiyr': [1223], 'tafosiyr': [1224, 1336], '>uToruwHap': [1225], 'musAfir': [1226, 2794, 2795], 'sam~': [1227], 'ta>o$iyr': [1228], 'EATifap': [1229], 'EA$iq': [1230, 1818, 1837], 'HizAm': [1231], 'Huforap': [1232], 'Huj~ap': [1233], 'sariqap': [1234], 'DiloE': [1236], 'mutanAfis': [1237], 'sijil~': [1238], 'DayoEap': [1239], 'Huwt': [1240], 'sik~iyn': [1241], 'mutaEav~ir': [1243], 'mutaEAqid': [1244], 'musotawodaE': [1245], 'suHub': [1246], 'SaHon': [1247], 'musotawoEib': [1248], 'suk~An': [1249], 'SadaY': [1250], 'musotaholik': [1251, 2816], 'tAbiE': [1252], 'musota$Ar': [1253, 1450], 'musin~': [1255, 1453, 2784], 'mahArap': [1256], 'Eatabap': [1257], '$ahowap': [1258], '$iy$Aniy~': [1259, 1936], 'madofuwE': [1261], 'kas~Arap': [1262], 'jaras': [1263], 'gariyzap': [1264], 'jAniy': [1265], 'lamosap': [1266], 'ziy~': [1267], 'junayoh': [1268], 'hAjis': [1269], 'maTAr': [1270], 'haziymap': [1271], '{irotibAT': [1272], 'jumuwE': [1273], 'jinosiy~ap': [1274], 'jasad': [1275], '{imotiyAz': [1277], 'laHom': [1278], '{isotifozAz': [1279], 'kaniys': [1280], '$uhuwd': [1281], 'had~Af': [1282, 1445], 'yanobuwE': [1283], 'jumolap': [1284], 'zaworaq': [1285], '$ilow': [1286, 1934], '$uguwr': [1287], 'yamaniy~': [1288], 'fuwTap': [1289], '{ixotilAf': [1290], 'madoxal': [1291], 'zuqAqiy~': [1292], '{inofiEAl': [1293], '{iEotiSAm': [1294], 'kiyluwmitr': [1295], 'kiyAn': [1296], 'liyf': [1297], 'kArivap': [1300], 'gAziy': [1301], '{ijotiyAH': [1303], 'maHoruwq': [1304], 'ziyAdap': [1305], 'xurAfap': [1306], 'mafoEuwl': [1307], 'ma*ohab': [1308], 'jinAyap': [1309], 'maTomaE': [1310], 'mAniE': [1311], 'fariyq': [1312, 1630], '$A}ibap': [1313], '{ibotisAmap': [1314], \"EaTA'\": [1315], 'EaDalap': [1316], 'Hamalap': [1317], 'naZiyr': [1318, 2553, 2554, 2555], '>adabiy~At': [1319], 'TaEAm': [1320], 'hawaY': [1321], 'EaSabap': [1322], 'kAmirA': [1323], 'gAz': [1324], '{isotijowAb': [1325], 'mujan~is': [1326], 'taman~iy': [1327], 'gAbap': [1328], 'liybiy~': [1329], 'mukav~if': [1330], 'tajAEiyd': [1331], 'muna$~iT': [1332], 'munAx': [1333, 2721], '$aEiyrap': [1334], 'nAziy~': [1335], 'liyrap': [1337], '>akAdiymiy~': [1338], 'Haroq': [1339], 'munAhiD': [1340, 2729, 2730], 'munAfis': [1341], 'munASir': [1342, 2732], 'lugap': [1343], 'munADil': [1344], 'takotiyk': [1346], 'mumay~izap': [1347], 'mumar~iD': [1349], '>aforiyqiy~': [1351], 'mA$iy': [1352], 'Talal': [1353], 'muloHaq': [1354, 2696], '$a*~': [1355], 'mA$iyap': [1356], 'sAHil': [1357], 'TAqim': [1358], 'mAlik': [1360, 2493, 2494, 2495], 'fuwh': [1361], 'mAliyziy~': [1362], 'Tay~Ar': [1363, 1372], 'muSoTalaH': [1364], '{isotinAbap': [1365], 'Hafiyd': [1366], 'riwAq': [1367], 'Tay~ap': [1368], 'muZAharap': [1369], 'mubAdalap': [1370], 'muhan~i}': [1371], 'tarobawiy~': [1374], 'muboEad': [1376], 'mubodiE': [1377], 'Tun~': [1378], '<iyjAr': [1379], 'muSan~iE': [1380], 'tarotiylap': [1381], 'naqiyb': [1382], 'Eabowap': [1383], 'hibap': [1384], 'muSAdamap': [1385], 'muHotawaY': [1386], 'Eadasap': [1387], 'tasoriyb': [1389], \"<iyHA'\": [1391], 'muHotajaz': [1392], 'tawag~ul': [1393], 'mubotadi}': [1395], 'tarad~ud': [1396], 'Taw~Afap': [1397], '>abora$iy~': [1399], 'rubuwE': [1400], 'rubuE': [1401], 'nabiy~': [1402, 2548], 'ru&aY': [1403, 1404], 'hawol': [1405], 'rizoq': [1406], 'mugAlaTap': [1408], 'mufotaraq': [1409], 'nafaq': [1411], 'kAfir': [1412], '$ar~': [1414], '{iHotiyAj': [1415], 'taqoniy~': [1418, 2130], 'Hakiym': [1421], 'frAnokuwfuwniy~': [1424], 'Hajom': [1425], 'nahor': [1426, 2608], 'kAbuws': [1427], 'mudar~aj': [1428], '{ijotihAd': [1431], 'muwak~il': [1432], 'kanoz': [1433], '{inosiHAb': [1434], 'muwdiE': [1435], 'muwal~id': [1436], 'musotaqobil': [1437, 2810], 'gulAp': [1439], '{inoqilAb': [1440], 'sud~': [1441], '{inotiSAr': [1442], 'SaHAriy': [1444], 'siy~': [1446], 'musotajad~': [1447], 'suwr': [1448], 'muxaT~iT': [1451, 2540], 'salaf': [1452], 'HiSon': [1455], 'ta$okiylap': [1456], 'kuwriy~': [1457, 2375], '>usoturAliy~': [1458], 'SafiyHap': [1459], 'muxaS~aS': [1460], 'musotaEomir': [1461], 'tAyolanodiy~': [1462], 'salobiy~ap': [1464], 'musalosal': [1467], 'kiyniy~': [1468], 'mutabAriy': [1469, 2571], 'mutadar~ij': [1470], 'mut~ajih': [1471], 'Huzon': [1472], 'hadiy~ap': [1473], 'Huromap': [1474], 'sariy~ap': [1475], 'SAlap': [1476], 'hAtif': [1477, 2361], 'saxAfap': [1478], 'sibAq': [1479], 'mutasAbiq': [1480], 'mutaxar~ij': [1481, 2180], 'kawomap': [1482], 'Damiyr': [1483], 'musotaxodim': [1485, 2691, 2692], 'DAHiyap': [1486], 'siykArap': [1487], 'mutAbiE': [1488, 1489], 'SaEiyd': [1490, 2693], 'muta>ax~ir': [1492], 'sitArap': [1493], 'mutaTal~ib': [1494], 'Hujorap': [1495], 'muwASalap': [1496], 'simap': [1497], 'simAk': [1498], 'silok': [1499], 'SAniE': [1500, 2579], 'musal~am': [1501], 'ta>okiyd': [1502], 'kafAlap': [1503], '>anoguwliy~': [1504], 'Hawozap': [1507], 'Sinof': [1508, 2833], 'taTomiyn': [1509], '{ilotimAs': [1510], 'garobiy~': [1511], 'muqArabap': [1512], 'garosap': [1513], 'Sihoriyj': [1514], 'taSoniyf': [1515], '{imotidAd': [1516], 'muqotaTaf': [1517], 'Sayodaliy~ap': [1518], 'nAfi*ap': [1519], 'garAmap': [1520], '{ino$iqAq': [1521], 'tabAyun': [1522], 'HawoD': [1524, 1525], 'tabiEap': [1526], 'nAqid': [1527], 'tabaE': [1528], 'munotadaY': [1529], 'layolap': [1530], 'munotafiE': [1531], 'tabAdul': [1532], 'munotajaE': [1533], 'libAs': [1534], 'muHib~': [1535, 2565, 2754], 'Siyniy~': [1536], 'taSomiym': [1537], 'murAbiT': [1538], 'muxal~iS': [1539], 'murotafaE': [1541], 'murotakaz': [1543], 'HiDon': [1544], '>uko*uwbap': [1546], '>umoniy~ap': [1547, 2061], '{inobiEAv': [1548], 'Saliyb': [1549], 'muxorij': [1550], 'Sak~': [1551], 'Sahoyuwniy~': [1552], '>uno$uwdap': [1553], '>unovaY': [1554], 'taEorifap': [1555], 'kamiyn': [1556], 'kaf~': [1557], 'nA$i}': [1558], 'murAdif': [1559], 'taSad~uE': [1560], 'gaw~ASap': [1561], 'nAHiyap': [1562, 2528], '$akoliy~ap': [1563], 'murAjaEap': [1564], 'muzAriE': [1566, 2523, 2531], 'haram': [1568], 'Saxor': [1569], \"giTA'\": [1570, 2390], 'taHar~iy': [1571], '{inoTilAq': [1572], 'muHar~ir': [1575, 2521], 'mas~ap': [1576], 'dafotar': [1577], 'Eiroq': [1578, 2613], 'dafoEap': [1579], 'masoraH': [1580], '<iSodAr': [1581], 'wayolap': [1583, 2039], 'matAhap': [1585], 'qasoTal': [1586], 'maTobuwE': [1587], 'EiyAr': [1589, 2617], '<iHosAs': [1591], 'masobaH': [1592], 'jaHofal': [1593], 'jawoEAn': [1594, 2407], 'xAl': [1595], 'xAdim': [1596], 'qiTAr': [1597], 'wuquwE': [1598], 'wuSolap': [1599], 'EiroD': [1600], 'daworiy~ap': [1601], 'rAsib': [1602], 'yawomiy~At': [1603], 'wisATap': [1604], 'daq~ap': [1605], \"<iEofA'\": [1607], 'fan~iy~At': [1608], 'rA}iHap': [1609], 'mawoj': [1611], 'miHonap': [1612], 'jabohap': [1613], 'mazomuwr': [1614], 'miDax~ap': [1616], 'maSAEib': [1617], 'zaH~Afap': [1618], 'faqorap': [1620], 'EuTol': [1621], 'miZal~ap': [1622], '$iyk': [1624], '<ilozAm': [1625], 'qadar': [1626], 'buqoEap': [1627], 'qamiyS': [1628], 'ra$owap': [1629, 1631, 1863], 'mayodAn': [1632], 'maxozan': [1633], 'maxoraj': [1634], 'jazA}iriy~': [1635], 'jad~': [1636], 'zaEAmap': [1637], 'Eiyd': [1638], 'busotAn': [1639], 'qaron': [1640], 'maTab~': [1643], 'maZolimap': [1644], 'marosaY': [1645], 'rAliy': [1646], 'mala*~ap': [1647, 2229], 'fA}iz': [1648], 'makosiykiy~': [1651], 'fAr~': [1652], 'makotabap': [1653], 'Earo$': [1654], 'jarid': [1655, 2411], 'malo>ak': [1656], 'fahom': [1657], 'qiyAdiy~': [1659], 'xanodaq': [1660], 'xamor': [1661], 'faZiyEap': [1663], 'faDiyHap': [1664], 'majohuwl': [1665], 'xiTAb': [1666], 'majariy~': [1667], 'majal~ap': [1668], 'faDiylap': [1669], 'madoyuwniy~ap': [1670], 'xuloq': [1671], 'qumA$': [1674], 'mafosadap': [1675], 'xuSuwSiy~ap': [1676], 'qunoSuliy~ap': [1677], 'mafoquwd': [1678], 'rAbiH': [1679], 'fAkihap': [1680], 'jawAz': [1681], 'diysk': [1682], 'maqoSid': [1683], '<i*on': [1685, 1990], 'maqolaE': [1687], 'xaSiySap': [1689], 'xaliy~ap': [1690], 'rAhib': [1691], 'xAsir': [1692, 1986], 'yasAriy~': [1693, 1988], 'dihAn': [1694], 'marojiEiy~ap': [1695], 'xArij': [1696], 'duhon': [1697], 'EibAd': [1698], '|hap': [1699], 'manotuwj': [1700], 'fal~': [1701], 'qinodiyl': [1703], 'mabonaY': [1704, 2467], 'manofaEap': [1705], 'janAH': [1708, 1713], 'fAEil': [1709], 'manobaE': [1710], 'manoZuwmap': [1711], 'fAjir': [1712], 'mihonap': [1714], '$abah': [1715], 'mu&as~is': [1716, 2282, 2283], 'jumohuwriy~ap': [1717], 'mu&ar~ix': [1718], 'hinodiy~': [1719], 'maEodin': [1720], 'mu&al~if': [1721, 2286, 2308], 'taxomiyn': [1722], 'vawob': [1723], 'maEoqil': [1724], 'mu$otariy': [1725, 2333], 'rasomAl': [1726], 'fax~Ariy~At': [1727], 'muEotadiy': [1728], 'mu$otaraY': [1729], 'rasuwl': [1730], 'viqap': [1731], 'vuEobAn': [1732], '{isotixodAm': [1733], 'mu$orif': [1734, 2338], 'HaZ~': [1735], 'baEovap': [1736], 'wADiE': [1737, 1925], 'bi$Arap': [1738], 'mu$ay~iE': [1739], 'qArib': [1740], 'bAxirap': [1741], 'wAdiy': [1742], 'vamiyn': [1743], '<ivArap': [1744], 'mu$aj~iE': [1745], 'maEolAp': [1746], 'HAs~ap': [1747], 'nusoxap': [1748], 'badawiy~': [1749], 'rakiyzap': [1750], 'rakol': [1751], 'nuwr': [1752], 'tuHofap': [1753], 'vAniyap': [1754, 1951], 'tisoEiyn': [1755], 'muDAyaqap': [1757], 'muDArib': [1758], 'vA}ir': [1759], \"barA'ap\": [1760], \"bariy'\": [1762], 'valoj': [1763], '<isotrAtiyjiy~ap': [1764], 'barolamAn': [1765], 'vamAniyn': [1767], 'mu&ay~id': [1768, 1769, 2281], 'vaman': [1770], 'junoHap': [1771], '<iro$Ad': [1772], '<ivoniy~ap': [1773], 'mirojal': [1775], 'waSol': [1776], 'muHArib': [1777], 'binAyap': [1778], 'jinos': [1779], 'maDojaE': [1782], 'raSad': [1783], \"qaDA'\": [1785], 'Eumuwmiy~ap': [1786], 'bin': [1787, 2347], 'miqolAd': [1788], 'muHaS~il': [1789], 'Eumuwlap': [1790], 'bAdirap': [1791], 'miqodAr': [1792], 'maDobuwT': [1793], 'tawoDiyH': [1794], 'qaSor': [1795], 'Habol': [1796], 'zalam': [1797], '$iroyAn': [1798], 'miyEAd': [1799], 'badiyhiy~ap': [1800], '<inokliyziy~': [1801], 'mi}o*anap': [1802], 'fitonap': [1803], 'rab~': [1804], 'miyzap': [1805], 'ratol': [1806], 'radomiy~': [1807], 'mu$Arakap': [1808], 'fawAt': [1809], 'jisom': [1810], 'wAliy': [1811], 'Habiyb': [1812, 2659], '$abaH': [1813], 'EatAd': [1814], '{irotiEA$': [1816], 'samAd': [1817], 'quronap': [1820], '{irotifAE': [1821], 'ribAT': [1822], '{isotiqAlap': [1823], 'rAdiykAliy~': [1824], 'saqaT': [1825], '|xi*': [1826], 'saqof': [1829], 'Eabod': [1830], 'sanotimitr': [1831], \"{isotiqoSA'\": [1832], 'sarab': [1833], 'saqoTap': [1836], '|nisap': [1838], '$a*orap': [1839], 'sayol': [1840], 'raqabap': [1841], 'ras~Am': [1842], 'ratiyb': [1843], 'rAbiyap': [1844], 'Eab~Asiy~': [1846], 'ramoyap': [1847], '$Akiy': [1848], 'EaTiy~ap': [1849], 'rawosam': [1850], '$Arap': [1851], 'rA}iEap': [1852], '{isotihodAf': [1854], 'saHob': [1855], 'EArif': [1857], 'rabowap': [1858], 'raSiyf': [1859, 1864], \"{isotidoEA'\": [1860], '$Agir': [1862], 'Ea*Ab': [1865], 'saHonap': [1866], '{isotiEomAl': [1867], '{isotiEolAm': [1868], '$Amiy~': [1869], '{it~ifAqiy~ap': [1870], 'Eanotariy~ap': [1871], '$aTor': [1872], 'Eanobar': [1873], 'Eam~': [1874], 'sAtir': [1875], 'sA}il': [1876], '$aHonap': [1877], 'raD~': [1878], 'raSASap': [1880], '{isotiko$Af': [1881], 'rAyap': [1882], '{isotimArap': [1883], '{i}otilAf': [1884], 'riyADap': [1885], 'EAdap': [1886], \"{isotivonA'\": [1887], 'saliyf': [1888], '|Sirap': [1889], 'Eaq~Ar': [1890], 'riyAl': [1891], '{irotikAb': [1892], 'rAmiy': [1894], 'EAhap': [1895], 'raHol': [1896], 'EAlam': [1897], 'saf~Ak': [1898], '$Aridap': [1899], '{ixotirAq': [1900], 'Eajalap': [1902], 'Eajiybap': [1903], 'raf~': [1905], 'Ealaf': [1906], 'sab~Aq': [1907], '{ixotiyAr': [1908], 'EAqid': [1909], 'EAriD': [1910], '$Arib': [1911], 'saTor': [1912], '$aZiy~ap': [1913], 'rutobap': [1914], '$ujayorap': [1916], 'Duruwb': [1917], '<isohAm': [1918], '<irosAliy~ap': [1919], 'vinoy': [1921], 'viqal': [1922], '<irohAS': [1924], '<irobAk': [1926], 'zay~AH': [1927], 'zayot': [1928], '<iqAmap': [1930], '<inotAj': [1931], 'zawojap': [1933], 'waTan': [1935], 'zaman': [1937], '<imokAniy~ap': [1940], 'wafAp': [1941], 'zal~ap': [1942], '<imodAd': [1943], 'zalozalap': [1944], 'wafodiy~': [1945], '<imobirATuwriy~ap': [1946], 'wajaE': [1947], 'vamor': [1948], '<imAm': [1950], 'tawAfuq': [1952], 'quroSAn': [1953], '<ixorAj': [1955], 'tawas~uE': [1956], \"<ixolA'\": [1957], '<ixofAq': [1958], '$iEob': [1959], '$iEor': [1960], 'tawoqiyE': [1962], 'tawosiyE': [1963], 'taxofiyD': [1964], 'taxom': [1965], 'zuqAq': [1966], '$ihAb': [1967], '<ivom': [1968], 'tilisokuwb': [1969], 'zuhuwr': [1970, 1972], 'tirob': [1973], 'tisoEiyniy~': [1974], '<isotrAtiyjiy~': [1975, 1977], 'turobap': [1976], 'ziyjap': [1978], '<isonAd': [1980], 'zahor': [1981], '{iEoti*Ar': [1983], 'xAm': [1984], 'xAnap': [1985], 'xAtam': [1987], \"<iDA'ap\": [1989], '<i$okAliy~ap': [1991], '<i$okAl': [1992], '*ayol': [1993], 'xafiy~ap': [1994], 'xaliyfap': [1995], 'xaliyq': [1996], 'xaloT': [1997], '*aqon': [1998], 'xamiyr': [1999], 'xurosAn': [2001], '*anob': [2002], 'xawAliy': [2003], 'xayoT': [2004], 'xayomap': [2005, 2007], 'xuroTuwm': [2006], 'xaz~An': [2008], '*abo*abap': [2009], '*abiyHap': [2010], '*Ahib': [2011], 'xuDorap': [2012], '$uyuwEiy~': [2013], 'yatiym': [2014, 2015], \"walA'\": [2016], 'xATirap': [2017], '<ikorAmiy~ap': [2018], 'waliymap': [2019], 'waliy~': [2020], 'wamoDap': [2021], '<ikoliyl': [2022], '$iymap': [2023], 'waraY': [2024], 'waral': [2025], 'warod': [2027], \"<igorA'\": [2028], 'wasax': [2029], '<ibodAE': [2030], 'wasiyTap': [2031], '$uEobap': [2032], 'zAruwb': [2033], 'watad': [2034], 'zAniy': [2035], 'watiyrap': [2036], 'yaxot': [2038], 'wazon': [2041], \"wiEA'\": [2042], '<iHodAviy~': [2043], 'wilAdap': [2044], '<iEodAm': [2045], '<iDAfap': [2046], '<iySAl': [2047], 'tasomiyap': [2048], 'DifAf': [2049], 'ta$aw~uh': [2050], '>usoTuwl': [2051], '{inofirAj': [2052], '>urodun~iy~': [2053], 'ta>am~ul': [2054], '{inofijAr': [2055], 'ta>omiyn': [2056], '>uqoHuwAn': [2057], 'taEAqud': [2058], '>umosiy~ap': [2060], '>uloEuwbap': [2062], 'taEomiym': [2064], '>azaj~': [2067], '>ayodiyuwluwjiyA': [2068], '>axawiy~ap': [2069], 'taHiy~ap': [2071], '{inoTibAE': [2072], '>asad': [2074], '{inoHirAf': [2075], '>arobaEiyn': [2077], '$al~Al': [2078], '>anoziym': [2079], 'ta$obiyh': [2080], 'ta$an~uj': [2081], 'taTowiyb': [2082], 'ta$aE~ub': [2083], 'Did~': [2084], 'sifor': [2086], 'Daruwriy~': [2087], '$afor': [2089], 'DarAwap': [2090], '{inozilAq': [2091], 'sin~': [2092], 'DaHokap': [2094], '{inotiqAl': [2095], 'siyAHap': [2096], 'siyjArap': [2098], 'siynAriyw': [2099, 2100], 'siyrofirz': [2101], '>uwtuwbiys': [2102], 'su&or': [2104], '{inotihAziy~': [2105], 'sunobul': [2107], 'sur~': [2108], 'suwdAniy~': [2109], 'suwfoyitiy~': [2110], '$ajan': [2111], '{inohimAk': [2112], '{ilotibAs': [2113], '{ikotitAb': [2114], 'tasoliyf': [2115], 'tamoriyr': [2116], 'tamowiyh': [2117], 'tanaq~ul': [2118], '$aq~ap': [2119], 'tanoZiyf': [2120], '>aboSAr': [2121], '$arak': [2122], 'tanoqiyb': [2123], 'taqATuE': [2124], '$ariyEap': [2125], '{iSoTilAH': [2127], '>aSalap': [2128], '$ariyHap': [2129], '>a$uwriy~': [2131], '>a$al~': [2132], 'taqoyiyd': [2133], '{iHotirAm': [2134], 'tarAkum': [2136], 'tarojamap': [2138], 'tarojiyH': [2139], 'taromiym': [2140], '$atolap': [2141], 'taroniymap': [2142], '{iEotiqAd': [2143], '<iydAE': [2144], '$ayoTAn': [2145], '{ibotikAr': [2146], 'tamodiyd': [2147], '$amoEadAn': [2148], '$aqiyqap': [2149], 'tabodiyl': [2151], 'tadAxul': [2153], '$amoEap': [2154], '{ihotizAz': [2155], '$amosiy~ap': [2156], 'tadoqiyq': [2157], '>amAnap': [2158], 'tafAwut': [2159], '>alomAniy~': [2160], '>akamap': [2161], 'tahaj~um': [2162], '>ajal': [2163], '{ifotirAD': [2164], 'tajodiyd': [2167], 'tajowiyf': [2168], 'takat~ul': [2169], '>afoEaY': [2170], '>adiyb': [2171], 'takowiyn': [2172], 'talAEub': [2173], 'talomiyH': [2174], 'taloziym': [2175], 'tal~': [2176], 'tamAyuz': [2177], 'tamar~ud': [2178], 'janobap': [2179], 'quroS': [2181], 'dayor': [2182, 2191], 'masokuwkap': [2183], 'masojuwn': [2184], 'daf~AE': [2185], 'dagal': [2186], 'daraj': [2189], 'maro&uws': [2192], 'diEAmap': [2193], 'masAfap': [2194], 'diEAyap': [2195], 'marotabap': [2196], 'maroqab': [2197], 'marokab': [2199], 'marobaE': [2200], 'masolax': [2201], 'masomaE': [2202], 'masoraHiy~ap': [2203], 'masoruwq': [2204], 'may~it': [2205, 2265], 'mayol': [2206, 2207], 'maxoluwq': [2208], 'maxobaz': [2209], 'maxoTuwT': [2210], 'burohAn': [2211], 'buroj': [2212], 'maworuwv': [2213], 'mawoluwd': [2214], 'mawolid': [2215], 'dAEim': [2216], 'maviyl': [2217], 'dAb~ap': [2218], 'dAjin': [2219], 'daEowaY': [2220], 'matAE': [2221], 'dimAg': [2222], 'diymuqrATiy~ap': [2223], 'Zufur': [2224], \"faDA'\": [2225], 'mal~AH': [2226, 2244], 'fAriq': [2227], 'fArisiy~': [2228], 'malAm': [2230], 'fAsiq': [2231], 'makoman': [2232], 'fa>os': [2233], 'majomuwE': [2234], 'mariH': [2235], 'majohuwd': [2236], 'faDol': [2237], 'mahojaE': [2238], 'faDolap': [2239], 'magoribiy~': [2240], 'magorib': [2241], 'magonam': [2242], 'magAr': [2243], 'mamar~': [2245], 'mano$a>': [2246], 'maquwlap': [2248], \"duEA'\": [2249], 'duEAbap': [2250], 'dumoyap': [2252], 'duroziy~': [2253], 'dusotuwr': [2254], 'manoquwl': [2255], 'manokuwb': [2256, 2257], 'manojam': [2258], 'duwayolap': [2259], 'duwnum': [2261], 'manoZar': [2262], 'manoHuwtap': [2263], 'manoEaY': [2264], 'mazoruwEap': [2266], 'miEoSarap': [2267], 'muDax~im': [2268], 'muEa*~ib': [2269], 'muEAwin': [2270], 'muEAraDap': [2272], 'badolap': [2273], 'muEAhadap': [2274], 'muEAdalap': [2275], 'muDiyf': [2276], 'baqiy~ap': [2277], 'bunoduq': [2278], 'barakap': [2279], 'barobariy~': [2280], 'baromajiy~': [2284], 'mu&am~ar': [2285], 'badan': [2287], 'muEak~ir': [2288], 'muEal~ab': [2289], 'muEal~il': [2290], 'muHAsib': [2291], 'bAkiy': [2292], 'bAluwn': [2293], 'ba*olap': [2294], 'baEoviy~': [2295], 'baHor': [2298], 'muEotamir': [2299], 'muEojizap': [2300], 'muEojam': [2301], 'muEiyn': [2302], 'muEiyd': [2303], 'baTorak': [2305, 2306], 'baT~Ariy~ap': [2307], 'baroqiy~ap': [2309], 'baw~Abap': [2310], 'miyl': [2311], 'miro|ap': [2313], 'miqolAE': [2316], 'birokap': [2317], 'mil~iymitr': [2318], 'biroqi$': [2319], 'migowAr': [2320], 'bruwtisotAnotiy~': [2321], 'mifak~': [2322], 'midorah': [2323], 'buHayorap': [2324], 'miSoyadap': [2325], 'bukolap': [2326], 'miSofAp': [2328], 'miykoruwb': [2329], 'miyzAniy~ap': [2330], 'bayoraq': [2331], 'mu$AHanap': [2332], 'mu$otagil': [2336], 'mu$orik': [2337], 'ba}iys': [2339], 'mu$ar~iE': [2340, 2341, 2342], 'mu$ak~ik': [2343], 'mu$AyiE': [2344], 'mu$Awar': [2345], 'mu$Agib': [2349], 'maforuw$': [2350], 'maforazap': [2351], 'mafoSil': [2352], 'ku$ok': [2353], 'gud~ap': [2354], 'gul~': [2355], 'kurosiy~': [2356, 2357], 'hA$imiy~': [2358], 'hArib': [2359], 'klAsiykiy~': [2362, 2364], 'lisAn': [2363, 2436], 'hAytiy~': [2365], 'kaviyb': [2366], 'katif': [2367], 'katA}ibiy~': [2368], 'kar~': [2369], 'karodinAl': [2370], 'hafowap': [2371], 'kuwliys': [2372], 'kuwluwmobiy~': [2373], 'kuwmAnoduwz': [2374], 'liS~': [2376], 'ganam': [2377], 'gariyb': [2378], 'laqoTap': [2379], 'laqaY': [2380], 'laf~ap': [2381], 'lafoZ': [2382], 'laban': [2383], 'laHon': [2384], 'laHod': [2385], 'laEonap': [2386], 'laEobap': [2387], \"gi*A'\": [2388], 'guSon': [2391, 2392], 'kam~A$ap': [2393], 'hanap': [2394], 'kahof': [2395], \"hurA'\": [2396], 'jiybuwtiy~': [2397], 'jinirAl': [2398], 'jinAzap': [2399], 'jAriyap': [2400], 'jAsuws': [2401], 'jab~Ar': [2402], 'jahoba*': [2403], 'jaliys': [2404], 'jamAliy~ap': [2406], 'jamal': [2408], 'jam~Al': [2409], 'jariydap': [2410], 'jan~ap': [2412, 2413], 'jAliyap': [2414], 'hunayohap': [2415], \"kafo'\": [2416], 'hirAwap': [2417], \"kafA'At\": [2418], 'kabosuwl': [2419], 'kabiyrap': [2420], 'hawA}iy~': [2421], 'kabid': [2422], 'ka>os': [2423], 'ka*~Ab': [2424], 'ka$~Af': [2425], 'ka$of': [2426], 'kAtidrA}iy~ap': [2427], 'kAnotuwn': [2428], 'kAbil': [2429], 'haz~ap': [2430], 'jurovuwm': [2431], 'him~ap': [2432], 'juroEap': [2433], 'jura*': [2434], 'gajariy~': [2435], 'mafAtin': [2437], 'maHofuwr': [2438], 'fariyDap': [2439], 'maSiyr': [2440], 'maSaf~': [2441], 'maHosuwb': [2442, 2443], 'maHoram': [2444], 'maHokuwm': [2445], 'fariysiy~': [2446], 'maHofil': [2447], 'gaDon': [2448], 'maHoZuwr': [2449], 'maHoSuwl': [2450], 'faroDiy~ap': [2451], 'faroHap': [2452], 'fatowaY': [2453, 2454], 'maEuwnap': [2455], 'maEozuwfap': [2456], 'faranojiy~': [2457], 'farA$ap': [2458], 'maSoyaf': [2459], 'faqiyh': [2460], 'madoraj': [2461], 'madoluwl': [2462], 'madofan': [2463], 'fajowap': [2465], 'madAr': [2466], 'maboHav': [2469], 'maboEuwv': [2470], 'mabar~ap': [2471], 'maZoruwf': [2472], 'maZoluwm': [2473], 'fan~iy~': [2474], 'maToraH': [2475], 'maTomaH': [2476], 'maTolaE': [2477], 'maEozil': [2478], 'fawoj': [2479], 'fiD~iy~At': [2480], 'fiyniyqiy~': [2481], 'ma$oraf': [2482], 'ma$orab': [2483], 'ma$ohuwr': [2484], 'ma$ogal': [2485], 'ma$aq~ap': [2486], 'mA}idap': [2487], 'mAwiy~': [2488], 'mAr~': [2489, 2490], 'mArok': [2491], 'mAniH': [2492], 'fuwhap': [2496], 'luwrod': [2497], 'lub~': [2498], 'ma$oriq': [2499], 'ma$oruwb': [2500], 'fidA}iy~': [2501], 'fiyl~A': [2502], 'filos': [2504], 'finizuwil~iy~': [2505], 'firoEawon': [2506], 'maEobar': [2507], 'maEoSiyap': [2508], 'maEidap': [2509], 'maEA$': [2510], 'maDomuwn': [2511], 'maDiyq': [2512], 'maDar~ap': [2513], 'ma>oxa*': [2514], 'ma>ovarap': [2515], 'fiyl': [2516], 'ma>onap': [2517], 'ma>omuwr': [2518, 2519], 'muHar~iD': [2520], 'quf~Az': [2522], 'nAjiH': [2524], 'HayAp': [2525], 'nAb': [2526], 'nATiq': [2527], \"Hi*A'\": [2529], 'muzAyadap': [2530], 'muxotalif': [2532], 'muwlodAfiy~': [2533], 'muxotabi}': [2534], 'HiSAn': [2536, 2538], 'muxiyl': [2537], 'muxar~ib': [2539], 'muxAlif': [2541], 'nArjiylap': [2542], 'nAvir': [2543], 'Has~Asiy~ap': [2544], 'nAziEap': [2545], 'nafal': [2546], 'naboDap': [2547], 'HamAm': [2549], 'nabAt': [2550], 'naZ~Arap': [2551], 'naZorap': [2552], 'naSiyr': [2556], 'naSiyb': [2557], 'naH~At': [2558], 'naEol': [2559], 'na*or': [2560], 'Hasanap': [2562], 'muwmisap': [2563], 'Hilof': [2564], 'mutaHam~is': [2566], 'Husayoniy~': [2568], 'mutafar~iqAt': [2569], 'mutafAwiD': [2570], 'SAEiqap': [2572], 'mutaSay~id': [2574], 'mutaHad~iv': [2575], 'muwfad': [2576, 2589], 'mutaHAlif': [2577], 'mutaEad~iy': [2578], 'mutaEATiy': [2580], 'mutaEATif': [2581], 'muta>al~iq': [2582], 'muta>ah~il': [2583], 'mutAbaEap': [2584], 'mutamar~is': [2585], 'mutamaw~il': [2586], 'mutanak~ir': [2587], 'mutasab~ib': [2588], 'muwaj~ih': [2590], 'Himol': [2591], 'muwa$~aH': [2592], 'Hubayobap': [2593], 'Huqob': [2595], 'mut~ahim': [2597], 'mutoEab': [2598], 'muta|mir': [2599], 'januwbiy~': [2600], 'mutaxal~if': [2601], 'mutawar~iT': [2602], 'mutawAjid': [2603], 'mutatab~iE': [2604], 'mutasal~il': [2605], 'nafoHap': [2606], 'naforap': [2607], 'qiT~': [2610], 'EilAwap': [2611], 'qi$or': [2612], 'qawom': [2614], 'EiyAl': [2615], 'qasAwisiy~': [2616], 'qariyb': [2618], 'najomap': [2619], 'qan~AS': [2620], 'Eu$~': [2621], 'qaloqalap': [2623], 'qaloEap': [2624], 'qafor': [2625], 'qafAF': [2626], 'EuTolap': [2627], 'EilAj': [2628], 'qid~iys': [2630, 2631], 'qufol': [2632], 'qud~As': [2633], 'qub~aEap': [2634], 'quTon': [2636], 'Eay~inap': [2637], 'Eaziymap': [2638], 'qiyAs': [2639], 'Ei$oriyn': [2640], 'qis~iys': [2641], 'EiTof': [2642], 'EiZap': [2643], 'qiron': [2644], 'qiro$': [2645], \"qirA'ap\": [2646], 'qinoE': [2647], 'Eulobap': [2649], 'qaTiyE': [2650], 'qaTariy~': [2651], 'niyAbap': [2652], 'HaSAnap': [2654], 'HaSoriy~': [2656], 'niqA$': [2657], 'nihAyap': [2658], 'niSof': [2660], 'nazol': [2661], 'naziyl': [2662], 'naxob': [2663], 'nawoEiy~ap': [2664], 'Hadaqap': [2665], 'nasor': [2666], 'naqo$': [2667], 'namol': [2668], 'nakosap': [2669], 'nisowap': [2670], 'Ha$AF': [2671], 'qa$iyb': [2672], 'HA}iT': [2673], 'HADinap': [2674], 'qA}il': [2675], 'HADir': [2677], 'HASil': [2678], 'qAruwrap': [2680], 'qAlib': [2681], 'qAfiyap': [2682], 'qAfilap': [2683], 'qASir': [2684, 2685], 'HAmiy': [2686], 'nuzohap': [2687], 'nuwbiy~': [2688], 'HAwiy': [2689], 'nuTofap': [2690], 'mukas~arAt': [2694], 'muloHaqAt': [2695], 'mulim~ap': [2697], 'TAmiH': [2698], 'mulAHiZ': [2699], 'mulAHaqap': [2700], 'mukota$if': [2701], 'TAwilap': [2702], 'mukAfa>ap': [2703], 'munaw~ih': [2704], 'Tabaq': [2706], 'mujas~am': [2708], 'mujanozir': [2709], 'mujad~id': [2710], 'mujAnasap': [2711], 'mujAmalap': [2712], 'mulotaqaY': [2713], 'mumATalap': [2714], 'munaZ~ir': [2717], 'SuwmAliy~': [2720, 2776], 'munAwi}': [2722], 'TAEin': [2723], 'munAwa$ap': [2724], 'TAbiq': [2725], 'munAqalap': [2726], 'munAqaSap': [2727], 'TAbuwr': [2728], 'TAgiy': [2731], 'munA$adap': [2733], 'mujAbahap': [2736], 'mubAlagap': [2737], 'muTAradap': [2738], 'muTAlabap': [2739], 'muSan~af': [2741], 'Turoqap': [2742], 'muSaf~aHap': [2743], 'muSAlaHap': [2744], 'muSAfaHap': [2745], 'muSAb': [2746], 'muHotasib': [2747], 'muHotariS': [2748], 'muHotaram': [2749], 'muHotal~': [2750], 'muHotaj~': [2751], 'muHotafil': [2752], 'muHosin': [2753], 'muTArid': [2755], 'Tayor': [2756], 'Tayof': [2758], 'muhad~i}': [2759], 'TaliyEap': [2761], 'mugoriyAt': [2763], 'mugan~iy': [2764], 'mufosid': [2765], 'mufaw~aD': [2766], 'mufak~irap': [2767], 'Taluwqap': [2768], 'mufAraqap': [2769], 'mud~axar': [2770], 'mudomin': [2771], 'mudax~in': [2773], 'mubotakar': [2775], 'Sufuwf': [2777], 'musaj~il': [2779, 2788], 'musotaDoEaf': [2780], 'musota>omin': [2781], 'musota>ojir': [2782], 'SafoEap': [2783], 'musam~aY': [2785], 'Sagiyr': [2786], 'musak~in': [2787], 'muno$aq~': [2789], 'musad~asap': [2790], 'musab~ib': [2791], 'musab~ab': [2792], 'musotaEomarap': [2798], 'musotaHoDar': [2799], 'musotabiyH': [2800], 'musotadoEaY': [2801], 'Sabiy~': [2807], 'Sabiy~ap': [2809], 'musotanoqaE': [2811], 'musotanoTiq': [2812], 'musotamir~': [2813], 'musotamiE': [2814], 'Safad': [2815], 'musotafiyd': [2817], 'musotadoEiy': [2818], 'Saliybiy~': [2819], 'Saroxap': [2821], 'murAfaEap': [2822], 'muqotariE': [2823, 2824], 'muqar~ir': [2825], 'muqal~id': [2826], 'muqad~im': [2827], 'muqad~ar': [2829], 'SinAEiy~': [2830], 'muqAwamap': [2831], 'Sirobiy~': [2834], 'Sudofap': [2835], 'munojaz': [2836], 'munoTalaq': [2837], 'munoHadar': [2838], 'munoEaTaf': [2839], 'murAbiy': [2840], 'murotahin': [2842], 'murAhanap': [2843], 'murosil': [2844, 2845], 'muriyd': [2846], 'muraw~ij': [2847, 2848], 'murat~ab': [2849], 'murad~id': [2850], 'murab~aE': [2851], 'SawomaEap': [2853], 'SayoHap': [2856], 'Sayodaliy~': [2858], 'murAjiE': [2859], 'murAhiq': [2860], 'mibo$arap': [2861]}\n",
            "Report Error Analysis on duplicates has been saved in /content/drive/MyDrive/AI Projects/Arabic Broken Plural/Datasets analysis path\n"
          ]
        }
      ],
      "source": [
        "# find duplicates and create dictionaries\n",
        "\n",
        "def getDuplicateIndexes(data):\n",
        "  dupindex={}\n",
        "  f=False\n",
        "  for i in range(len(data[0])):\n",
        "    if f: break\n",
        "    lemma = data[0][i]\n",
        "    if dupindex.get(lemma)==None:\n",
        "      dupindex[lemma]=[]\n",
        "      dupindex[lemma].append(i)\n",
        "    else:\n",
        "      f=False\n",
        "      for k in range(len(dupindex[lemma])):\n",
        "        if data[8][i] > data[8][dupindex[lemma][k]]:\n",
        "          dupindex[lemma].insert(0,i)\n",
        "          f=True\n",
        "      if not f : dupindex[lemma].append(i)\n",
        "\n",
        "\n",
        "  return dupindex\n",
        "\n",
        "def reportErrorAnalysis_duplicates(dataframe,dicDup,path):\n",
        "  df=dataframe.loc[[]]\n",
        "  \n",
        "  indexes=[]\n",
        "  for key, value in dicDup.items():\n",
        "    if len(value)>1 :\n",
        "      for x in value:\n",
        "        n=len(df)\n",
        "        indexes.append(x)\n",
        "        df.loc[n]=dataframe.loc[x]\n",
        "  df.insert(0, \"index\", indexes, True)\n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "\n",
        "if is_dataOrginal:\n",
        "  #Save similar lemmas indexes in dictionary (key->lemma | value->list of indexes)\n",
        "  trainDupIndex=getDuplicateIndexes(trainData)\n",
        "  devDupIndex=getDuplicateIndexes(devData)\n",
        "  testDupIndex=getDuplicateIndexes(testData)\n",
        "  print(\"duplicate indexes has been updated\")\n",
        "  print(trainDupIndex)\n",
        "\n",
        "if is_dataOrginal:\n",
        "  #Save Duplicate report on data in csv\n",
        "  trainDuplicateCsv=reportErrorAnalysis_duplicates(train_csv,trainDupIndex,data_analysis_path+\"/duplicateAnalyssis_train.csv\")\n",
        "  devDuplicateCsv=reportErrorAnalysis_duplicates(dev_csv,devDupIndex,data_analysis_path+\"/duplicateAnalyssis_dev.csv\")\n",
        "  testDuplicateCsv=reportErrorAnalysis_duplicates(test_csv,testDupIndex,data_analysis_path+\"/duplicateAnalyssis_test.csv\")\n",
        "  print(\"Report Error Analysis on duplicates has been saved in /content/drive/MyDrive/AI Projects/Arabic Broken Plural/Datasets analysis path\")\n",
        "\n",
        "#Generate lemma-inflection refrence\n",
        "dic_lemmaInflection={}\n",
        "def updateDic_lemmaInflection(Data,dupIndex):\n",
        "  global dic_lemmaInflection\n",
        "  for key, value in dupIndex.items():\n",
        "    if dic_lemmaInflection.get(key)==None:\n",
        "      dic_lemmaInflection[key]=[]\n",
        "    for x in value : \n",
        "      if not Data[3][x] in dic_lemmaInflection[key]: dic_lemmaInflection[key].append(Data[3][x])\n",
        "\n",
        "if is_dataOrginal:\n",
        "  updateDic_lemmaInflection(trainData,trainDupIndex)\n",
        "  updateDic_lemmaInflection(testData,testDupIndex)\n",
        "  updateDic_lemmaInflection(devData,devDupIndex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TIS2Q8bFLHE",
        "outputId": "7b49e507-0523-493b-f247-62137a50e810"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number Of Lemmas before Dropping duplicates in Train Set:  2862\n",
            "Number Of Lemmas before Dropping duplicates in Test Set:  1103\n",
            "Number Of Lemmas before Dropping duplicates in Dev Set:  1151\n",
            "=============================================================\n",
            "Number Of Lemmas After Dropping duplicates in Train Set:  2475\n",
            "Number Of Lemmas After Dropping duplicates in Test Set:  1028\n",
            "Number Of Lemmas After Dropping duplicates in Dev Set:  1060\n"
          ]
        }
      ],
      "source": [
        "#Drop unnecessary duplicates\n",
        "def getUniqueData(data,dupIndex):\n",
        "  out=[]\n",
        "  #init nested lists\n",
        "  for x in data: out.append([])\n",
        "  #fill out with most frequent lemma-inflection pairs\n",
        "  for key, value in dupIndex.items():\n",
        "    for k in range(len(data)):\n",
        "      out[k].append(data[k][value[0]])\n",
        "  return out\n",
        "\n",
        "\n",
        "trainDataUnique=getUniqueData(trainData,trainDupIndex)\n",
        "devDataUnique=getUniqueData(devData,devDupIndex)\n",
        "testDataUnique=getUniqueData(testData,testDupIndex)\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Train Set: \", len(trainData[0]))\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Test Set: \",len(testData[0]))\n",
        "print(\"Number Of Lemmas before Dropping duplicates in Dev Set: \",len(devData[0]))\n",
        "print(\"=============================================================\")\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Train Set: \", len(trainDataUnique[0]))\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Test Set: \",len(testDataUnique[0]))\n",
        "print(\"Number Of Lemmas After Dropping duplicates in Dev Set: \",len(devDataUnique[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "LodNC4wSsL0s"
      },
      "outputs": [],
      "source": [
        "#######Risky Implementation!!! Only Run This Once\n",
        "if is_dataOrginal:\n",
        "  trainData=trainDataUnique\n",
        "  devData=devDataUnique\n",
        "  testData=testDataUnique\n",
        "  is_dataOrginal=False\n",
        "else:\n",
        "  print(\"Warning!!! duplicate rows has already been dropped from data.(skipped this step)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRilqxawClaF"
      },
      "source": [
        "## **Encoding Datasets (Character-based)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8UL3rofClaF",
        "outputId": "22df14a5-0227-45dd-b0bf-72212577bfbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "{'not available char': 0, 'E': 1, 'a': 2, 'm': 3, 'l': 4, '1': 5, '2': 6, '3': 7, '>': 8, 'o': 9, 'A': 10, 'h': 11, 'd': 12, 'f': 13, 'u': 14, 'D': 15, 'w': 16, \"'\": 17, 'j': 18, 'i': 19, 'z': 20, 'p': 21, 'H': 22, 'k': 23, 'n': 24, 'S': 25, 'r': 26, '4': 27, 'q': 28, '~': 29, 'y': 30, 't': 31, 's': 32, '<': 33, 'b': 34, 'v': 35, '|': 36, 'T': 37, '}': 38, 'Z': 39, '{': 40, '&': 41, '$': 42, 'x': 43, 'N': 44, 'W': 45, '*': 46, 'g': 47, 'Y': 48, 'F': 49}\n"
          ]
        }
      ],
      "source": [
        "# generate character encoding\n",
        "oov_token = 'not available char'\n",
        "char_index = {oov_token: 0}\n",
        "\n",
        "def updateCharIndex(data):\n",
        "  global char_index\n",
        "  # encode input with encoding character set\n",
        "  for i in range(len(data[0])):\n",
        "      chars = data[0][i] + data[1][i] + data[3][i] + data[4][i]\n",
        "      for c in chars:\n",
        "          if c not in char_index:\n",
        "              char_index[c] = len(char_index)\n",
        "\n",
        "updateCharIndex(trainData)\n",
        "print(len(char_index))\n",
        "print(char_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3aR6noZClaF",
        "outputId": "4230f944-4ea1-4029-bc97-3e72c2df647e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma shape train:  2475\n",
            "lemma shape dev:  1060\n",
            "lemma shape test:  1028\n",
            "max length in lemma elements:  17\n",
            "max length in root elements:  4\n",
            "max length in inflection elements:  18\n"
          ]
        }
      ],
      "source": [
        "# encode words with character encoder\n",
        "def encodeWord(word, dic=char_index, oov=oov_token):\n",
        "    return [dic[c] if c in dic else dic[oov] for c in list(word)]\n",
        "\n",
        "# encode data and get maximum length of features\n",
        "def getEncodedData(data):\n",
        "  '''\n",
        "  Output type->List : 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:number of root\n",
        "  '''\n",
        "\n",
        "  data_encoded = data.copy()\n",
        "  data_encoded[0] = [encodeWord(each) for each in data[0]]\n",
        "  data_encoded[1] = [encodeWord(each) for each in data[1]]\n",
        "  data_encoded[2] = [encodeWord(each) for each in data[2]]\n",
        "  data_encoded[3] = [encodeWord(each) for each in data[3]]\n",
        "  data_encoded[4] = [encodeWord(each) for each in data[4]]\n",
        "\n",
        "  lemma_max_len = max([len(each) for each in data_encoded[0]])\n",
        "  root_max_len = max([len(each) for each in data_encoded[2]])\n",
        "  inflection_max_len = max([len(each) for each in data_encoded[3]])\n",
        "\n",
        "  return data_encoded, lemma_max_len, root_max_len, inflection_max_len\n",
        "\n",
        "\n",
        "trainData_encoded, lemma_max_len, root_max_len, inflection_max_len = getEncodedData(trainData)\n",
        "devData_encoded, _, _, _  = getEncodedData(devData)\n",
        "testData_encoded, _, _, _ = getEncodedData(testData)\n",
        "\n",
        "print('lemma shape train: ', len(trainData_encoded[0]))\n",
        "print('lemma shape dev: ', len(devData_encoded[0]))\n",
        "print('lemma shape test: ', len(testData_encoded[0]))\n",
        "print('max length in lemma elements: ', lemma_max_len)\n",
        "print('max length in root elements: ', root_max_len)\n",
        "print('max length in inflection elements: ', inflection_max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDYp2LuClaF",
        "outputId": "1da601a9-12b1-4635-dcb8-8af71dd74174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma with pad shape train:  (2475, 17)\n",
            "lemma with pad shape dev:  (1060, 17)\n",
            "lemma with pad shape test:  (1028, 17)\n"
          ]
        }
      ],
      "source": [
        "# ADD padding to sample\n",
        "# 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational \n",
        "def getPaddedData(encodedData, lemma_max_len, root_max_len, inflection_max_len):\n",
        "  data_pad = []\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[0], maxlen=lemma_max_len, padding='post'))) \n",
        "  data_pad.append(np.array(pad_sequences(encodedData[1], maxlen=lemma_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[2], maxlen=root_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[3], maxlen=inflection_max_len, padding='post')))\n",
        "  data_pad.append(np.array(pad_sequences(encodedData[4], maxlen=inflection_max_len, padding='post')))\n",
        "  data_pad.append(np.array(encodedData[5]))\n",
        "  data_pad.append(np.array(encodedData[6]))\n",
        "  data_pad.append(np.array(encodedData[7]))\n",
        "  data_pad.append(np.array(encodedData[8]))\n",
        "\n",
        "  return data_pad\n",
        "\n",
        "trainData_pad = getPaddedData(trainData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "devData_pad = getPaddedData(devData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "testData_pad = getPaddedData(testData_encoded, lemma_max_len, root_max_len, inflection_max_len)\n",
        "\n",
        "print('lemma with pad shape train: ', trainData_pad[0].shape)\n",
        "print('lemma with pad shape dev: ', devData_pad[0].shape)\n",
        "print('lemma with pad shape test: ', testData_pad[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O45BUvM0ClaF"
      },
      "source": [
        "### **Create inputs of neural network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm__BnNyClaF",
        "outputId": "f1c74fd6-e13d-440a-c896-5b28b1a74cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_lemma shape:  (2475, 17)\n",
            "X_train_singularPattern shape:  (2475, 17)\n",
            "X_train_root shape:  (2475, 4)\n",
            "X_train_genRat shape:  (2475, 2)\n",
            "X_train_numOfRoot shape:  (2475, 1)\n",
            "y_train_class shape:  (2475, 1)\n",
            "y_train_plPattern shape:  (2475, 18)\n",
            "y_train_unflection shape:  (2475, 18)\n"
          ]
        }
      ],
      "source": [
        "# 0:lamma | 1:singular pattern | 2:root |3:inflection | 4:plural pattern | 5:plural type(B/S) | 6:gender | 7:rational | 8:number of root\n",
        "# create train set\n",
        "X_train_lemma = trainData_pad[0]  # lemma feature\n",
        "X_train_singularPattern = trainData_pad[1]  # singular pattern feature\n",
        "X_train_root = trainData_pad[2]  # root feature\n",
        "X_train_genRat = np.stack((trainData_pad[6], trainData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_train_numOfRoot = trainData_pad[8].reshape((trainData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_train_class = trainData_pad[5].reshape((trainData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_train_plPattern = trainData_pad[4]  # plural pattern\n",
        "y_train_inflection = trainData_pad[3]  # inflection\n",
        "\n",
        "# create dev set\n",
        "X_dev_lemma = devData_pad[0]  # lemma feature\n",
        "X_dev_singularPattern = devData_pad[1]  # singular pattern feature\n",
        "X_dev_root = devData_pad[2]  # root feature\n",
        "X_dev_genRat = np.stack((devData_pad[6], devData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_dev_numOfRoot = devData_pad[8].reshape((devData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_dev_class = devData_pad[5].reshape((devData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_dev_plPattern = devData_pad[4]  # plural pattern\n",
        "y_dev_inflection = devData_pad[3]  # inflection\n",
        "\n",
        "# create test set\n",
        "X_test_lemma = testData_pad[0]  # lemma feature\n",
        "X_test_singularPattern = testData_pad[1]  # singular pattern feature\n",
        "X_test_root = testData_pad[2]  # root feature\n",
        "X_test_genRat = np.stack((testData_pad[6], testData_pad[7]), axis=-1)  # gender & rational features\n",
        "X_test_numOfRoot = testData_pad[8].reshape((testData_pad[8].shape[0], -1))  # number of root\n",
        "\n",
        "y_test_class = testData_pad[5].reshape((testData_pad[5].shape[0], -1))  # broken or sound classes\n",
        "y_test_plPattern = testData_pad[4]  # plural pattern\n",
        "y_test_inflection = testData_pad[3]  # inflection\n",
        "\n",
        "print('X_train_lemma shape: ', X_train_lemma.shape)\n",
        "print('X_train_singularPattern shape: ', X_train_singularPattern.shape)\n",
        "print('X_train_root shape: ', X_train_root.shape)\n",
        "print('X_train_genRat shape: ', X_train_genRat.shape)\n",
        "print('X_train_numOfRoot shape: ', X_train_numOfRoot.shape)\n",
        "print('y_train_class shape: ', y_train_class.shape)\n",
        "print('y_train_plPattern shape: ', y_train_plPattern.shape)\n",
        "print('y_train_unflection shape: ', y_train_inflection.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5tEprqGClaG",
        "outputId": "a1bc294e-88c0-4e81-9c4e-6acff34b74e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2475, 17, 50)\n",
            "(2475, 17, 50)\n",
            "(2475, 4, 50)\n",
            "(2475, 18, 50)\n",
            "(2475, 18, 50)\n"
          ]
        }
      ],
      "source": [
        "# Convert to ONE-HOT encoding\n",
        "X_train_lemma_OH = to_categorical(X_train_lemma, len(char_index))\n",
        "X_train_singularPattern_OH = to_categorical(X_train_singularPattern, len(char_index))\n",
        "X_train_root_OH = to_categorical(X_train_root, len(char_index))\n",
        "\n",
        "X_dev_lemma_OH = to_categorical(X_dev_lemma, len(char_index))\n",
        "X_dev_singularPattern_OH = to_categorical(X_dev_singularPattern, len(char_index))\n",
        "X_dev_root_OH = to_categorical(X_dev_root, len(char_index))\n",
        "\n",
        "X_test_lemma_OH = to_categorical(X_test_lemma, len(char_index))\n",
        "X_test_singularPattern_OH = to_categorical(X_test_singularPattern, len(char_index))\n",
        "X_test_root_OH = to_categorical(X_test_root, len(char_index))\n",
        "\n",
        "y_train_plPattern_OH = to_categorical(y_train_plPattern, len(char_index))\n",
        "y_dev_plPattern_OH = to_categorical(y_dev_plPattern, len(char_index))\n",
        "y_test_plPattern_OH = to_categorical(y_test_plPattern, len(char_index))\n",
        "\n",
        "y_train_inflection_OH = to_categorical(y_train_inflection, len(char_index))\n",
        "y_dev_inflection_OH = to_categorical(y_dev_inflection, len(char_index))\n",
        "y_test_inflection_OH = to_categorical(y_test_inflection, len(char_index))\n",
        "\n",
        "print(X_train_lemma_OH.shape)\n",
        "print(X_train_singularPattern_OH.shape)\n",
        "print(X_train_root_OH.shape)\n",
        "print(y_train_plPattern_OH.shape)\n",
        "print(y_train_inflection_OH.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "IxUhzb3nClaG"
      },
      "outputs": [],
      "source": [
        "# covern numerical inputs to int32\n",
        "X_train_genRat = np.asarray(X_train_genRat).astype('int32')\n",
        "X_train_numOfRoot = np.asarray(X_train_numOfRoot).astype('int32')\n",
        "X_dev_genRat = np.asarray(X_dev_genRat).astype('int32')\n",
        "X_dev_numOfRoot = np.asarray(X_dev_numOfRoot).astype('int32')\n",
        "X_test_genRat = np.asarray(X_test_genRat).astype('int32')\n",
        "X_test_numOfRoot = np.asarray(X_test_numOfRoot).astype('int32')\n",
        "\n",
        "y_train_class = np.asarray(y_train_class).astype('int32')\n",
        "y_dev_class = np.asarray(y_dev_class).astype('int32')\n",
        "y_test_class = np.asarray(y_test_class).astype('int32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4MC1JT3TSec"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PtI4-1PCuFcB"
      },
      "outputs": [],
      "source": [
        "def getDuplicateIndexes(data):\n",
        "  dupindex={}\n",
        "  for i in range(len(data[0])):\n",
        "    if dupindex.get(data[0][i])==None:\n",
        "      dupindex[data[0][i]]=[]\n",
        "    dupindex[data[0][i]].append(i)\n",
        "\n",
        "  return dupindex\n",
        "\n",
        "def reportErrorAnalysis_duplicates(dataframe,dicDup,path):\n",
        "  df=dataframe.loc[[]]\n",
        "  \n",
        "  indexes=[]\n",
        "  for key, value in dicDup.items():\n",
        "    for x in value:\n",
        "      n=len(df)\n",
        "      indexes.append(x)\n",
        "      df.loc[n]=dataframe.loc[x]\n",
        "  df.insert(0, \"index\", indexes, True)\n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "\n",
        "#Save similar lemmas indexes in dictionary (key->lemma | value->list of indexes)\n",
        "trainDupIndex=getDuplicateIndexes(trainData)\n",
        "devDupIndex=getDuplicateIndexes(devData)\n",
        "testDupIndex=getDuplicateIndexes(testData)\n",
        "\n",
        "\n",
        "#Save Duplicate report on data in csv\n",
        "trainDuplicateCsv=reportErrorAnalysis_duplicates(train_csv,trainDupIndex,dataPath+\"/duplicateAnalyssis_train.csv\")\n",
        "devDuplicateCsv=reportErrorAnalysis_duplicates(dev_csv,devDupIndex,dataPath+\"/duplicateAnalyssis_dev.csv\")\n",
        "testDuplicateCsv=reportErrorAnalysis_duplicates(test_csv,testDupIndex,dataPath+\"/duplicateAnalyssis_test.csv\")\n",
        "\n",
        "#Generate lemma-inflection refrence\n",
        "dic_lemmaInflection={}\n",
        "def updateDic_lemmaInflection(Data,dupIndex):\n",
        "  global dic_lemmaInflection\n",
        "  for key, value in dupIndex.items():\n",
        "    if dic_lemmaInflection.get(key)==None:\n",
        "      dic_lemmaInflection[key]=[]\n",
        "      for x in value : \n",
        "        if not Data[3][x] in dic_lemmaInflection[key]: dic_lemmaInflection[key].append(Data[3][x])\n",
        "\n",
        "updateDic_lemmaInflection(trainData,trainDupIndex)\n",
        "updateDic_lemmaInflection(testData,testDupIndex)\n",
        "updateDic_lemmaInflection(devData,devDupIndex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXiNUVV7zFqX",
        "outputId": "3b06ef1a-1d23-494c-9171-545e0dfaf710"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.updateDic_lemmaInflection(Data, dupIndex)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "updateDic_lemmaInflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PYqxULkbTSed"
      },
      "outputs": [],
      "source": [
        "def oneHot2D(arr):\n",
        "    tmp = np.zeros_like(arr)\n",
        "    tmp[np.arange(len(arr)), arr.argmax(1)] = 1\n",
        "    return tmp\n",
        "\n",
        "def oneHot3D(arr):\n",
        "    tmp = np.array([oneHot2D(x) for x in arr])\n",
        "    return tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lR89g_k_7dYp"
      },
      "outputs": [],
      "source": [
        "char_index_key_list = list(char_index.keys())\n",
        "char_index_val_list = list(char_index.values())\n",
        "def getCharFromIdx(idx):\n",
        "  position = char_index_val_list.index(idx)\n",
        "  return char_index_key_list[position]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "M6wNFevTTSee"
      },
      "outputs": [],
      "source": [
        "def getWordFromOnehot(onehot):\n",
        "  encoded=np.argmax(onehot, axis=1)\n",
        "  word=[]\n",
        "  for x in encoded:\n",
        "    if x==0:break\n",
        "    word.append(getCharFromIdx(x))\n",
        "  return ''.join(word)\n",
        "\n",
        "def binaryConversion(arr, threshold=0.5):\n",
        "  tmp = np.zeros_like(arr)\n",
        "  tmp[arr > threshold] = 1\n",
        "  return tmp\n",
        "\n",
        "def reportResult(model, history, X_test, y_test):\n",
        "\n",
        "    # best models based on acc or loss in tarin set or test set\n",
        "    testHistory = list(\n",
        "        map(lambda x, y: [x, y], history['val_accuracy'], history['val_loss']))\n",
        "    print(\n",
        "        f\"best model based on min test set loss:  acc= {min(testHistory, key = lambda k: k[1])[0]}  loss= {min(testHistory, key = lambda k: k[1])[1]}\")\n",
        "    print(\n",
        "        f\"best model based on max test set accuracy:  acc= {max(testHistory, key = lambda k: k[0])[0]}  loss= {max(testHistory, key = lambda k: k[0])[1]}\")\n",
        "\n",
        "    print(\"\\nevaluate dataset with best model based on maximum test set accuracy\")\n",
        "    print(\"evaluate test set = \", model.evaluate(X_test, y_test, verbose=0))\n",
        "\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_test_pred = binaryConversion(y_test_pred)\n",
        "\n",
        "    # confusion matrix and precision, recall and f1 report\n",
        "    print('-'*30, 'metrics for test set', '-'*30)\n",
        "    print(\"confusion matrix: \\n\", metrics.confusion_matrix(y_test, y_test_pred))\n",
        "    print(metrics.classification_report(y_test,\n",
        "          y_test_pred, digits=3, target_names=['Broken', 'Sound']))\n",
        "    \n",
        "def argmaxKeepDimensions(arr):\n",
        "  tmp = np.zeros_like(arr)\n",
        "  tmp[np.arange(len(arr)), arr.argmax(1)] = 1\n",
        "  return tmp\n",
        "\n",
        "def checkAccuracy(pred, true):\n",
        "  size = pred.shape[0]\n",
        "  numOfTrue = 0\n",
        "  for (x, y) in zip(pred, true):\n",
        "    if np.array_equal(x, y):\n",
        "      numOfTrue += 1\n",
        "  \n",
        "  return size-numOfTrue, numOfTrue/size\n",
        "\n",
        "def checkAccuracy_anyAcceptableInflectionInDataset(lemma, pred, dic_refrence):\n",
        "  size = pred.shape[0]\n",
        "  numOfTrue = 0\n",
        "  for i in range (len(pred)):\n",
        "    w=getWordFromOnehot(pred[i])\n",
        "    if w in dic_refrence[lemma[i]]:\n",
        "      numOfTrue += 1\n",
        "  \n",
        "  return size-numOfTrue, numOfTrue/size\n",
        "\n",
        "def reportErrorAnalysis(lemma, bs, pred_OH, inflection_OH, path):\n",
        "  size = pred_OH.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'b/s':[], 'inflection':[], 'predict':[]}\n",
        "  i=0\n",
        "  for (x, y) in zip(pred_OH, inflection_OH):\n",
        "    if not np.array_equal(x, y):\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(bs[i])\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['predict'].append(getWordFromOnehot(pred_OH[i]))\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "def reportErrorAnalysis_inflectionWithBS(lemma, bs,bs_pred, pred_OH, inflection_OH, path):\n",
        "  size = pred_OH.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'b/s':[], 'b/s predict':[], 'inflection':[], 'predict':[]}\n",
        "  bs_pred = binaryConversion(bs_pred)\n",
        "  i=0\n",
        "  for (x, y) in zip(pred_OH, inflection_OH):\n",
        "    if not np.array_equal(x, y):\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(bs[i])\n",
        "      report['b/s predict'].append(bs_pred[i])\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['predict'].append(getWordFromOnehot(pred_OH[i]))\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df\n",
        "\n",
        "def reportErrorAnalysis_classification(lemma, inflection_OH, bs, bs_pred, path):\n",
        "  size = bs.shape[0]\n",
        "  report={'index':[], 'lemma':[], 'inflection':[],'b/s':[], 'b/s predict':[] }\n",
        "  bs_pred = binaryConversion(bs_pred, 0.5)\n",
        "  i=0\n",
        "  for (x, y) in zip(bs, bs_pred):\n",
        "    if not x==y:\n",
        "      report['index'].append(i)\n",
        "      report['lemma'].append(lemma[i])\n",
        "      report['b/s'].append(x)\n",
        "      report['inflection'].append(getWordFromOnehot(inflection_OH[i]))\n",
        "      report['b/s predict'].append(y)\n",
        "    i+=1\n",
        "  \n",
        "  df = pd.DataFrame(report) \n",
        "  df.to_csv(path)\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jPbJ_pHqmsyV"
      },
      "outputs": [],
      "source": [
        "def reportPercentageOfBrokenSoundErrors(dataset_errorAnalysis):\n",
        "  total_errors_num = dataset_errorAnalysis.shape[0]\n",
        "  train_sound_error = np.sum(dataset_errorAnalysis['b/s'])\n",
        "  train_broken_error = total_errors_num - train_sound_error\n",
        "  return train_broken_error/total_errors_num * 100, train_sound_error/total_errors_num * 100\n",
        "\n",
        "def reportPercentageOfUnseenErrors(errorIndices, unseenIndices):\n",
        "  isInUnseen = np.array([index in unseenIndices for index in errorIndices])\n",
        "  return np.count_nonzero(isInUnseen==True) / len(errorIndices) * 100, np.count_nonzero(isInUnseen==True) / len(unseenIndices) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aRDIUaOvvJv"
      },
      "source": [
        "# **Classification Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2WmPwVwV7z-"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "# path = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/Results/Classification Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caFMHfjbiMQT"
      },
      "outputs": [],
      "source": [
        "lemma_length = X_train_lemma_OH.shape[1] #17\n",
        "encode_size = X_train_lemma_OH.shape[2] #50\n",
        "genRat_length = X_train_genRat.shape[1] #2\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYae4z1hhH4t"
      },
      "source": [
        "## **Model 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUCsnXkThH4z"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length,), name='Gender-Rational')\n",
        "\n",
        "\n",
        "lstm = Bidirectional(LSTM(256, name='Lstm'), name='Bidirectional')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm, input_genRat])\n",
        "\n",
        "d = Dense(256, activation='relu', name='Dense1')(c)\n",
        "d = Dense(64, activation='relu', name='Dense2')(d)\n",
        "\n",
        "output = Dense(1, activation='sigmoid', name='Class')(d)\n",
        "model = Model(inputs=[input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "model.save(path + \"/model 1/structure.h5\")\n",
        "\n",
        "checkpoint_filepath = path + '/model 1/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd9ygt4yhH4-"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  history = model.fit([X_train_lemma_OH, X_train_genRat], y_train_class, batch_size=batch_size, epochs=epochs, \n",
        "                      verbose=1, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], y_dev_class)).history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB-ixvAghH5E"
      },
      "outputs": [],
      "source": [
        "print(model.summary())\n",
        "plot_model(model, to_file=path+'/model 1/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDj9zmJqhH5J"
      },
      "outputs": [],
      "source": [
        "model = load_model(checkpoint_filepath)\n",
        "model.evaluate([X_test_lemma_OH, X_test_genRat], y_test_class)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reportResult(model, history, [X_test_lemma_OH, X_test_genRat], y_test_class)"
      ],
      "metadata": {
        "id": "BPWyu0gjgiHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Error Analysis**"
      ],
      "metadata": {
        "id": "DBYWYsIYgR4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train set"
      ],
      "metadata": {
        "id": "2WMhXUKOgYzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_class_p=model.predict([X_train_lemma_OH, X_train_genRat])\n",
        "reportErrorAnalysis_classification(trainData[0], y_train_inflection_OH, y_train_class, train_class_p, path + \"/model 1/train_errorAnalysis.csv\")"
      ],
      "metadata": {
        "id": "WxnbG5hDtWlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dev set"
      ],
      "metadata": {
        "id": "YBgk1fKxgain"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_class_p=model.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "reportErrorAnalysis_classification(devData[0], y_dev_inflection_OH, y_dev_class, dev_class_p, path + \"/model 1/dev_errorAnalysis.csv\")"
      ],
      "metadata": {
        "id": "_nD8ybG73xFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test set"
      ],
      "metadata": {
        "id": "I7wyRP-agdO9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IP3NKsfhH5N"
      },
      "outputs": [],
      "source": [
        "test_class_p=model.predict([X_test_lemma_OH, X_test_genRat])\n",
        "reportErrorAnalysis_classification(testData[0], y_test_inflection_OH, y_test_class, test_class_p, path + \"/model 1/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB0fawJa66PY"
      },
      "source": [
        "# **Machine Translation Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjirN8TtdNqu"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models'\n",
        "# path = '/content/drive/MyDrive/Deep Learning/Datasets/Arabic Broken Plural/Results/Machine Translation Models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52n_VZ40dNqy"
      },
      "outputs": [],
      "source": [
        "lemma_length = X_train_lemma_OH.shape[1] #17\n",
        "singularPattern_length = X_train_singularPattern_OH.shape[1] #17\n",
        "root_length = X_train_root_OH.shape[1] #4\n",
        "genRat_length = X_train_genRat.shape[1] #2\n",
        "numOfRoot_length = X_train_numOfRoot.shape[1] #1\n",
        "plPattern_length = y_train_plPattern_OH.shape[1] #18\n",
        "inflection_length = y_train_inflection_OH.shape[1] #18\n",
        "encode_size = X_train_lemma_OH.shape[2] #50\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K87j_k_oEVh3"
      },
      "source": [
        "## **Model 1**\n",
        "lemma - inflection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRB1n7PQknbY"
      },
      "outputs": [],
      "source": [
        "model1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Model 1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-3oRhRlEVh4"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat])\n",
        "\n",
        "d = Dense(256, activation='relu', name='Dense1')(c)\n",
        "\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "model1 = Model(inputs=[input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "checkpoint_filepath = model1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k64r76HEVh4"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  model1.fit([X_train_lemma_OH, X_train_genRat], y_train_inflection_OH, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], y_dev_inflection_OH))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF__oNPxEVh4"
      },
      "outputs": [],
      "source": [
        "model1 = load_model(checkpoint_filepath)\n",
        "model1.evaluate([X_test_lemma_OH, X_test_genRat], y_test_inflection_OH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-_uAugdEVh4"
      },
      "outputs": [],
      "source": [
        "print(model1.summary())\n",
        "plot_model(model1, to_file=model1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAoL0KSoEVh4"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq30qNbbEVh5"
      },
      "outputs": [],
      "source": [
        "train_pred = model1.predict([X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lktzh8o5HNsn"
      },
      "outputs": [],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK3xq6x0EVh5"
      },
      "outputs": [],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, model1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzOAAD4jEVh5"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86i08EoppWIi"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybXFriUqEVh5"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s-l01ipEVh5"
      },
      "outputs": [],
      "source": [
        "dev_pred = model1.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPCOBCrEEVh5"
      },
      "outputs": [],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis(devData[0], devData[5], dev_pred_OH, y_dev_inflection_OH, model1_path + \"/dev_errorAnalysis.csv\")\n",
        "dev_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb3-t4ehEVh5"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q8CzzBqpMAR"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0],dev_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOswiP7Fqhdp"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7R3KZnxEVh5"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55GGksBBEVh6"
      },
      "outputs": [],
      "source": [
        "test_pred = model1.predict([X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i57C2rVDEVh6"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis(testData[0], testData[5], test_pred_OH, y_test_inflection_OH, model1_path + \"/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6v7_vY1EVh6"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2NUckr-pPAf"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0],test_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HL3bbXgzGck"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdCz16FjpUjU"
      },
      "source": [
        "## **Mix Model (2 Networks: Classification + Machine Translation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQR4WH4wnbPX"
      },
      "outputs": [],
      "source": [
        "mixModel1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Mix Model 1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU_KhzdDpTiO"
      },
      "outputs": [],
      "source": [
        "BSClassification_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "BSClassification_model_path = BSClassification_path + '/model 1/weights.hdf5'\n",
        "BSClassification_model_structure_path = BSClassification_path + \"/model 1/structure.h5\"\n",
        "\n",
        "BSC_model = load_model(BSClassification_model_path)\n",
        "BSC_model_struct = load_model(BSClassification_model_structure_path)\n",
        "\n",
        "BSC_model_struct.set_weights(BSC_model.get_weights())\n",
        "BSC_model_struct.trainable = False\n",
        "# print(BSC_model.layers[1].get_weights()[0][0])\n",
        "# print(BSC_model_struct.layers[1].get_weights()[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0ko_Jsbr3Gs"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "cls = BSC_model_struct([input_lemma, input_genRat])\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat, cls])\n",
        "\n",
        "d = Dense(200, activation='relu', name='Dense1')(c)\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "mix_model = Model(inputs=[input_lemma, input_genRat], outputs=output)\n",
        "\n",
        "checkpoint_filepath = mixModel1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "mix_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i56qrPBBVh4j"
      },
      "outputs": [],
      "source": [
        "mix_model.layers[3].layers[1].get_weights()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJjSxEPFUUx_"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  mix_model.fit([X_train_lemma_OH, X_train_genRat], y_train_inflection_OH, batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], y_dev_inflection_OH))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2s1v375Um5l"
      },
      "outputs": [],
      "source": [
        "mix_model = load_model(checkpoint_filepath)\n",
        "mix_model.evaluate([X_test_lemma_OH, X_test_genRat], y_test_inflection_OH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIWe1psZ3dZ4"
      },
      "outputs": [],
      "source": [
        "print(mix_model.summary())\n",
        "plot_model(mix_model, to_file=mixModel1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgfj5lhjU6z3"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_IHpXM1U6z9"
      },
      "outputs": [],
      "source": [
        "train_pred = mix_model.predict([X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYvcpoH7U60B"
      },
      "outputs": [],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niUWd_7tU60E"
      },
      "outputs": [],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkGc9jELU60H"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5l_gwk2U60K"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHCsxDc9U60N"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA-xaxEZU60P"
      },
      "outputs": [],
      "source": [
        "dev_pred = mix_model.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "758ZYt8YU60S"
      },
      "outputs": [],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis(devData[0], devData[5], dev_pred_OH, y_dev_inflection_OH, mixModel1_path + \"/dev_errorAnalysis.csv\")\n",
        "dev_errorAnalysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Kn0v0qU60X"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2SBpLd4U60a"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0], dev_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E1WV0QxU60c"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVg1pBydU60g"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqA9bxlFU60i"
      },
      "outputs": [],
      "source": [
        "test_pred = mix_model.predict([X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEn_8FwpU60k"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis(testData[0], testData[5], test_pred_OH, y_test_inflection_OH, mixModel1_path + \"/test_errorAnalysis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UuTiZ52U60m"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CitdRhOKU60p"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0], test_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpR-Yp-rU60q"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_lrUYcHGakD"
      },
      "source": [
        "## **Mix Model (2 Networks: Classification + Machine Translation)**\n",
        "with 2 outputs(inflection + BS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsMLo7It11GR"
      },
      "outputs": [],
      "source": [
        "mixModel1_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Machine Translation Models/Mix Model 2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr7OxTgqGakD"
      },
      "outputs": [],
      "source": [
        "BSClassification_path = '/content/drive/MyDrive/AI Projects/Arabic Broken Plural/Results/Classification Models'\n",
        "BSClassification_model_path = BSClassification_path + '/model 1/weights.hdf5'\n",
        "BSClassification_model_structure_path = BSClassification_path + \"/model 1/structure.h5\"\n",
        "\n",
        "BSC_model = load_model(BSClassification_model_path)\n",
        "BSC_model_struct = load_model(BSClassification_model_structure_path)\n",
        "\n",
        "BSC_model_struct.set_weights(BSC_model.get_weights())\n",
        "BSC_model_struct.trainable = False\n",
        "# print(BSC_model.layers[1].get_weights()[0][0])\n",
        "# print(BSC_model_struct.layers[1].get_weights()[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOmmQjYDGakE"
      },
      "outputs": [],
      "source": [
        "input_lemma = Input(shape=(lemma_length, encode_size), name='Lemma')\n",
        "input_genRat = Input(shape=(genRat_length, ), name='Gender-Rational')\n",
        "\n",
        "cls = BSC_model_struct([input_lemma, input_genRat])\n",
        "lstm1 = Bidirectional(LSTM(256, name='Lstm1'), name='Encoder')(input_lemma)\n",
        "\n",
        "c = Concatenate(axis=1, name='Concatenate')([lstm1, input_genRat, cls])\n",
        "\n",
        "d = Dense(200, activation='relu', name='Dense1')(c)\n",
        "r = RepeatVector(inflection_length, name='RepeatVector')(d)\n",
        "\n",
        "lstm2 = Bidirectional(LSTM(256, return_sequences=True, name='Lstm2'), name='Decoder')(r)\n",
        "output = TimeDistributed(Dense(encode_size, activation='softmax', name='Dense2'), name='Inflection')(lstm2)\n",
        "\n",
        "mix_model = Model(inputs=[input_lemma, input_genRat], outputs=[output,cls])\n",
        "\n",
        "checkpoint_filepath = mixModel1_path + '/weights.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_Inflection_accuracy', mode='max', save_best_only=True, verbose=0)\n",
        "\n",
        "mix_model.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKPaRds2GakE"
      },
      "outputs": [],
      "source": [
        "mix_model.layers[3].layers[1].get_weights()[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwpAW-QpGakE"
      },
      "outputs": [],
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  mix_model.fit([X_train_lemma_OH, X_train_genRat], [y_train_inflection_OH, y_train_class], batch_size=batch_size, epochs=epochs, callbacks=[checkpoint], validation_data=([X_dev_lemma_OH, X_dev_genRat], [y_dev_inflection_OH,y_dev_class]))  # starts training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VO4Kj_1ZGakE"
      },
      "outputs": [],
      "source": [
        "mix_model = load_model(checkpoint_filepath)\n",
        "mix_model.evaluate([X_test_lemma_OH, X_test_genRat], [y_test_inflection_OH, y_test_class])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTslpQJQGakE"
      },
      "outputs": [],
      "source": [
        "print(mix_model.summary())\n",
        "plot_model(mix_model, to_file=mixModel1_path+'/architecture.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED9U383gGakE"
      },
      "source": [
        "### **Train analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f73zoNs4GakF"
      },
      "outputs": [],
      "source": [
        "train_pred,bs_pred = mix_model.predict([X_train_lemma_OH, X_train_genRat])\n",
        "train_pred_OH = oneHot3D(train_pred)\n",
        "train_error_num, train_acc_num = checkAccuracy(train_pred_OH, y_train_inflection_OH)\n",
        "train_error_num, train_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28tmraM3GakF"
      },
      "outputs": [],
      "source": [
        "y_train_inflection_OH.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gphy8bpaGakF"
      },
      "outputs": [],
      "source": [
        "train_errorAnalysis = reportErrorAnalysis(trainData[0], trainData[5], train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis.csv\")\n",
        "train_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reportErrorAnalysis_inflectionWithBS(trainData[0], trainData[5],bs_pred, train_pred_OH, y_train_inflection_OH, mixModel1_path + \"/train_errorAnalysis_with_bs.csv\")"
      ],
      "metadata": {
        "id": "W4mXyqHAHeT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMPj_yGSGakF"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(train_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhF3rJ8ZGakF"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(trainData[0],train_pred_OH,dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQ5EblGGakF"
      },
      "source": [
        "### **Dev analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljzLZIbvGakF"
      },
      "outputs": [],
      "source": [
        "dev_pred,bs_pred = mix_model.predict([X_dev_lemma_OH, X_dev_genRat])\n",
        "dev_pred_OH = oneHot3D(dev_pred)\n",
        "dev_error_num, dev_acc_num = checkAccuracy(dev_pred_OH, y_dev_inflection_OH)\n",
        "dev_error_num, dev_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHXxon8XGakF"
      },
      "outputs": [],
      "source": [
        "dev_errorAnalysis = reportErrorAnalysis_inflectionWithBS(devData[0], devData[5],bs_pred, dev_pred_OH, y_dev_inflection_OH, mixModel1_path + \"/dev_errorAnalysis_with_bs.csv\")\n",
        "dev_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bstuple = [dev_errorAnalysis['b/s'], dev_errorAnalysis['b/s predict']]\n",
        "c = 0\n",
        "n = len(bstuple[0])\n",
        "for i in range(n):\n",
        "  if not bstuple[0][i] == bstuple[1][i]: c+=1\n",
        "\n",
        "c/n"
      ],
      "metadata": {
        "id": "CDY9PrfHcuR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lXonFHHGakG"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(dev_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDrX1fdMGakG"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(devData[0], dev_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74SuAUc9GakG"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Dev set\n",
        "errorIndices_dev = dev_errorAnalysis['index'].tolist()\n",
        "unseenIndices_dev = unseenLemInfIndices_dev_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_dev, unseenIndices_dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZl-0dRpGakG"
      },
      "source": [
        "### **Test analyze**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YQAHhxJGakG"
      },
      "outputs": [],
      "source": [
        "test_pred,bs_pred = mix_model.predict([X_test_lemma_OH, X_test_genRat])\n",
        "test_pred_OH = oneHot3D(test_pred)\n",
        "test_error_num, test_acc_num = checkAccuracy(test_pred_OH, y_test_inflection_OH)\n",
        "test_error_num, test_acc_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4ejjMmuGakG"
      },
      "outputs": [],
      "source": [
        "test_errorAnalysis = reportErrorAnalysis_inflectionWithBS(testData[0], testData[5],bs_pred, test_pred_OH, y_test_inflection_OH, mixModel1_path + \"/test_errorAnalysis_with_bs.csv\")\n",
        "test_errorAnalysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bstuple = [test_errorAnalysis['b/s'], test_errorAnalysis['b/s predict']]\n",
        "c = 0\n",
        "n = len(bstuple[0])\n",
        "for i in range(n):\n",
        "  if not bstuple[0][i] == bstuple[1][i]: c+=1\n",
        "\n",
        "c/n"
      ],
      "metadata": {
        "id": "U80Tr2o3hLFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1aOEbV_GakG"
      },
      "outputs": [],
      "source": [
        "print('(Broken error %, Sound error %): ', reportPercentageOfBrokenSoundErrors(test_errorAnalysis))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upu85AtSGakH"
      },
      "outputs": [],
      "source": [
        "checkAccuracy_anyAcceptableInflectionInDataset(testData[0], test_pred_OH, dic_lemmaInflection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcIeOUM9GakH"
      },
      "outputs": [],
      "source": [
        "# Report Percentage of Unseen Errors in Test set\n",
        "errorIndices_test = test_errorAnalysis['index'].tolist()\n",
        "unseenIndices_test = unseenLemInfIndices_test_df['index'].tolist()\n",
        "\n",
        "print('Percentage of Unseen Errors with respect to Total Errors, Percentage of Unseen Errors with respect to Total Unseen Samples')\n",
        "print(reportPercentageOfUnseenErrors(errorIndices_test, unseenIndices_test))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rgbi7F8b_x30",
        "dU09qVXA9kp0",
        "4MFDQIHuClaE",
        "u_hpLQfwE5B2",
        "JRilqxawClaF",
        "g4MC1JT3TSec",
        "5aRDIUaOvvJv",
        "wYae4z1hhH4t",
        "DBYWYsIYgR4S",
        "UB0fawJa66PY",
        "K87j_k_oEVh3",
        "XAoL0KSoEVh4",
        "ybXFriUqEVh5",
        "i7R3KZnxEVh5",
        "fdCz16FjpUjU",
        "jgfj5lhjU6z3",
        "WHCsxDc9U60N",
        "gVg1pBydU60g",
        "s_lrUYcHGakD",
        "ED9U383gGakE",
        "RHQ5EblGGakF",
        "sZl-0dRpGakG"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}